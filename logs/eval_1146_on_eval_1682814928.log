04/29 08:35:29 PM The args: Namespace(aug_train=False, cache_dir='', data_dir='./_data/glue_data/RTE', data_url='', do_eval=True, do_lower_case=True, eval_batch_size=32, eval_step=50, gradient_accumulation_steps=1, learning_rate=5e-05, max_seq_length=128, no_cuda=False, num_train_epochs=3.0, output_dir='./eval_results/1146_on_eval', pred_distill=False, seed=42, student_model='./models_train/TinyBERT_6L_768D_1146_stg2_RTE', task_name='RTE', teacher_model=None, temperature=1.0, train_batch_size=32, warmup_proportion=0.1, weight_decay=0.0001)
04/29 08:35:29 PM device: cuda n_gpu: 1
04/29 08:35:29 PM ******** num_labels=2
04/29 08:35:29 PM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 6,
  "pre_trained": "",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}

04/29 08:35:29 PM Loading model ./models_train/TinyBERT_6L_768D_1146_stg2_RTE/pytorch_model.bin
04/29 08:35:29 PM loading model...
04/29 08:35:29 PM done!
04/29 08:35:30 PM ***** Running evaluation *****
04/29 08:35:30 PM   Num examples = 277
04/29 08:35:30 PM   Batch size = 32
04/29 08:35:31 PM preds.shape (277, 2)
04/29 08:35:31 PM ***** Eval results *****
04/29 08:35:31 PM   acc = 0.4729241877256318
04/29 08:35:31 PM   eval_loss = 0.93866984711753
04/29 08:35:31 PM --- preds.shape: (277,), probs_0 len: = 277, probs_1 len: 277, eval_labels.shape: (277,) ---
