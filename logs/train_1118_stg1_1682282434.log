04/23 04:40:34 PM The args: Namespace(aug_train=True, cache_dir='', data_dir='./_data/glue_data/CoLA', data_url='', do_eval=False, do_lower_case=True, eval_batch_size=32, eval_step=50, gradient_accumulation_steps=1, learning_rate=5e-05, max_seq_length=128, no_cuda=False, num_train_epochs=3.0, output_dir='./models_train/TinyBERT_6L_768D_1118_stg1_CoLA', pred_distill=False, seed=42, student_model='./_models/TinyBERT_General_6L_768D', task_name='CoLA', teacher_model='./_models/bert-base-uncased-cola', temperature=1.0, train_batch_size=32, warmup_proportion=0.1, weight_decay=0.0001)
04/23 04:40:34 PM device: cuda n_gpu: 1
04/23 04:40:34 PM ******** num_labels=2
04/23 04:40:47 PM Model config {
  "_name_or_path": "/mnt/lustre/weixiuying/transformer/pretrain_models/bert-base-uncased",
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "cola",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "unacceptable",
    "1": "acceptable"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "acceptable": 1,
    "unacceptable": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pre_trained": "",
  "problem_type": "single_label_classification",
  "torch_dtype": "float32",
  "training": "",
  "transformers_version": "4.13.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

04/23 04:40:47 PM Loading model ./_models/bert-base-uncased-cola/pytorch_model.bin
04/23 04:40:48 PM loading model...
04/23 04:40:48 PM done!
04/23 04:40:48 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']
04/23 04:40:48 PM Weights from pretrained model not used in TinyBertForSequenceClassification: ['bert.embeddings.position_ids']
04/23 04:40:48 PM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 6,
  "pre_trained": "",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}

04/23 04:40:49 PM Loading model ./_models/TinyBERT_General_6L_768D/pytorch_model.bin
04/23 04:40:49 PM loading model...
04/23 04:40:49 PM done!
04/23 04:40:49 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'fit_dense.weight', 'fit_dense.bias']
04/23 04:40:49 PM Weights from pretrained model not used in TinyBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'fit_denses.0.weight', 'fit_denses.0.bias', 'fit_denses.1.weight', 'fit_denses.1.bias', 'fit_denses.2.weight', 'fit_denses.2.bias', 'fit_denses.3.weight', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.4.bias', 'fit_denses.5.weight', 'fit_denses.5.bias', 'fit_denses.6.weight', 'fit_denses.6.bias']
04/23 04:40:49 PM ***** Running training *****
04/23 04:40:49 PM   Num examples = 212100
04/23 04:40:49 PM   Batch size = 32
04/23 04:40:49 PM   Num steps = 19884
04/23 04:40:49 PM n: bert.embeddings.word_embeddings.weight
04/23 04:40:49 PM n: bert.embeddings.position_embeddings.weight
04/23 04:40:49 PM n: bert.embeddings.token_type_embeddings.weight
04/23 04:40:49 PM n: bert.embeddings.LayerNorm.weight
04/23 04:40:49 PM n: bert.embeddings.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.0.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.0.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.1.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.1.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.2.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.2.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.3.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.3.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.4.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.4.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.query.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.query.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.key.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.key.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.value.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.self.value.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.attention.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.intermediate.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.intermediate.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.output.dense.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.output.dense.bias
04/23 04:40:49 PM n: bert.encoder.layer.5.output.LayerNorm.weight
04/23 04:40:49 PM n: bert.encoder.layer.5.output.LayerNorm.bias
04/23 04:40:49 PM n: bert.pooler.dense.weight
04/23 04:40:49 PM n: bert.pooler.dense.bias
04/23 04:40:49 PM n: classifier.weight
04/23 04:40:49 PM n: classifier.bias
04/23 04:40:49 PM n: fit_dense.weight
04/23 04:40:49 PM n: fit_dense.bias
04/23 04:40:49 PM Total parameters: 67547138
04/23 04:40:57 PM ***** Running evaluation *****
04/23 04:40:57 PM   Epoch = 0 iter 49 step
04/23 04:40:57 PM   Num examples = 1043
04/23 04:40:57 PM   Batch size = 32
04/23 04:40:57 PM ***** Eval results *****
04/23 04:40:57 PM   att_loss = 0.7430818774262253
04/23 04:40:57 PM   cls_loss = 0.0
04/23 04:40:57 PM   global_step = 49
04/23 04:40:57 PM   loss = 2.4354460507023092
04/23 04:40:57 PM   rep_loss = 1.6923641720596625
04/23 04:40:57 PM ***** Save model *****
04/23 04:41:05 PM ***** Running evaluation *****
04/23 04:41:05 PM   Epoch = 0 iter 99 step
04/23 04:41:05 PM   Num examples = 1043
04/23 04:41:05 PM   Batch size = 32
04/23 04:41:05 PM ***** Eval results *****
04/23 04:41:05 PM   att_loss = 0.6758659370619842
04/23 04:41:05 PM   cls_loss = 0.0
04/23 04:41:05 PM   global_step = 99
04/23 04:41:05 PM   loss = 2.107313142882453
04/23 04:41:05 PM   rep_loss = 1.4314472073256368
04/23 04:41:05 PM ***** Save model *****
04/23 04:41:13 PM ***** Running evaluation *****
04/23 04:41:13 PM   Epoch = 0 iter 149 step
04/23 04:41:13 PM   Num examples = 1043
04/23 04:41:13 PM   Batch size = 32
04/23 04:41:13 PM ***** Eval results *****
04/23 04:41:13 PM   att_loss = 0.6424503890459969
04/23 04:41:13 PM   cls_loss = 0.0
04/23 04:41:13 PM   global_step = 149
04/23 04:41:13 PM   loss = 1.9600764641025723
04/23 04:41:13 PM   rep_loss = 1.3176260730564193
04/23 04:41:13 PM ***** Save model *****
04/23 04:41:21 PM ***** Running evaluation *****
04/23 04:41:21 PM   Epoch = 0 iter 199 step
04/23 04:41:21 PM   Num examples = 1043
04/23 04:41:21 PM   Batch size = 32
04/23 04:41:21 PM ***** Eval results *****
04/23 04:41:21 PM   att_loss = 0.6257416313916595
04/23 04:41:21 PM   cls_loss = 0.0
04/23 04:41:21 PM   global_step = 199
04/23 04:41:21 PM   loss = 1.8801131991285776
04/23 04:41:21 PM   rep_loss = 1.254371566988116
04/23 04:41:21 PM ***** Save model *****
04/23 04:41:29 PM ***** Running evaluation *****
04/23 04:41:29 PM   Epoch = 0 iter 249 step
04/23 04:41:29 PM   Num examples = 1043
04/23 04:41:29 PM   Batch size = 32
04/23 04:41:29 PM ***** Eval results *****
04/23 04:41:29 PM   att_loss = 0.6121385389542484
04/23 04:41:29 PM   cls_loss = 0.0
04/23 04:41:29 PM   global_step = 249
04/23 04:41:29 PM   loss = 1.8227750915121361
04/23 04:41:29 PM   rep_loss = 1.2106365513610073
04/23 04:41:29 PM ***** Save model *****
04/23 04:41:37 PM ***** Running evaluation *****
04/23 04:41:37 PM   Epoch = 0 iter 299 step
04/23 04:41:37 PM   Num examples = 1043
04/23 04:41:37 PM   Batch size = 32
04/23 04:41:37 PM ***** Eval results *****
04/23 04:41:37 PM   att_loss = 0.6010454796429063
04/23 04:41:37 PM   cls_loss = 0.0
04/23 04:41:37 PM   global_step = 299
04/23 04:41:37 PM   loss = 1.779930518223689
04/23 04:41:37 PM   rep_loss = 1.178885038879803
04/23 04:41:37 PM ***** Save model *****
04/23 04:41:45 PM ***** Running evaluation *****
04/23 04:41:45 PM   Epoch = 0 iter 349 step
04/23 04:41:45 PM   Num examples = 1043
04/23 04:41:45 PM   Batch size = 32
04/23 04:41:45 PM ***** Eval results *****
04/23 04:41:45 PM   att_loss = 0.5921719338969037
04/23 04:41:45 PM   cls_loss = 0.0
04/23 04:41:45 PM   global_step = 349
04/23 04:41:45 PM   loss = 1.7458358418975655
04/23 04:41:45 PM   rep_loss = 1.1536639095377443
04/23 04:41:45 PM ***** Save model *****
04/23 04:41:53 PM ***** Running evaluation *****
04/23 04:41:53 PM   Epoch = 0 iter 399 step
04/23 04:41:53 PM   Num examples = 1043
04/23 04:41:53 PM   Batch size = 32
04/23 04:41:53 PM ***** Eval results *****
04/23 04:41:53 PM   att_loss = 0.5838061335092798
04/23 04:41:53 PM   cls_loss = 0.0
04/23 04:41:53 PM   global_step = 399
04/23 04:41:53 PM   loss = 1.7165031185126245
04/23 04:41:53 PM   rep_loss = 1.13269698575027
04/23 04:41:53 PM ***** Save model *****
04/23 04:42:01 PM ***** Running evaluation *****
04/23 04:42:01 PM   Epoch = 0 iter 449 step
04/23 04:42:01 PM   Num examples = 1043
04/23 04:42:01 PM   Batch size = 32
04/23 04:42:01 PM ***** Eval results *****
04/23 04:42:01 PM   att_loss = 0.5773327137553081
04/23 04:42:01 PM   cls_loss = 0.0
04/23 04:42:01 PM   global_step = 449
04/23 04:42:01 PM   loss = 1.6919730537983781
04/23 04:42:01 PM   rep_loss = 1.1146403421006914
04/23 04:42:01 PM ***** Save model *****
04/23 04:42:09 PM ***** Running evaluation *****
04/23 04:42:09 PM   Epoch = 0 iter 499 step
04/23 04:42:09 PM   Num examples = 1043
04/23 04:42:09 PM   Batch size = 32
04/23 04:42:09 PM ***** Eval results *****
04/23 04:42:09 PM   att_loss = 0.5712413882803105
04/23 04:42:09 PM   cls_loss = 0.0
04/23 04:42:09 PM   global_step = 499
04/23 04:42:09 PM   loss = 1.670642903429234
04/23 04:42:09 PM   rep_loss = 1.0994015170003704
04/23 04:42:09 PM ***** Save model *****
04/23 04:42:17 PM ***** Running evaluation *****
04/23 04:42:17 PM   Epoch = 0 iter 549 step
04/23 04:42:17 PM   Num examples = 1043
04/23 04:42:17 PM   Batch size = 32
04/23 04:42:17 PM ***** Eval results *****
04/23 04:42:17 PM   att_loss = 0.5665382386231032
04/23 04:42:17 PM   cls_loss = 0.0
04/23 04:42:17 PM   global_step = 549
04/23 04:42:17 PM   loss = 1.6524792822766607
04/23 04:42:17 PM   rep_loss = 1.0859410447935371
04/23 04:42:17 PM ***** Save model *****
04/23 04:42:25 PM ***** Running evaluation *****
04/23 04:42:25 PM   Epoch = 0 iter 599 step
04/23 04:42:25 PM   Num examples = 1043
04/23 04:42:25 PM   Batch size = 32
04/23 04:42:25 PM ***** Eval results *****
04/23 04:42:25 PM   att_loss = 0.5616240602900866
04/23 04:42:25 PM   cls_loss = 0.0
04/23 04:42:25 PM   global_step = 599
04/23 04:42:25 PM   loss = 1.6353829014480412
04/23 04:42:25 PM   rep_loss = 1.0737588423520377
04/23 04:42:25 PM ***** Save model *****
04/23 04:42:34 PM ***** Running evaluation *****
04/23 04:42:34 PM   Epoch = 0 iter 649 step
04/23 04:42:34 PM   Num examples = 1043
04/23 04:42:34 PM   Batch size = 32
04/23 04:42:34 PM ***** Eval results *****
04/23 04:42:34 PM   att_loss = 0.5586086596564629
04/23 04:42:34 PM   cls_loss = 0.0
04/23 04:42:34 PM   global_step = 649
04/23 04:42:34 PM   loss = 1.6223668104327515
04/23 04:42:34 PM   rep_loss = 1.0637581524753423
04/23 04:42:34 PM ***** Save model *****
04/23 04:42:42 PM ***** Running evaluation *****
04/23 04:42:42 PM   Epoch = 0 iter 699 step
04/23 04:42:42 PM   Num examples = 1043
04/23 04:42:42 PM   Batch size = 32
04/23 04:42:42 PM ***** Eval results *****
04/23 04:42:42 PM   att_loss = 0.5547040460873741
04/23 04:42:42 PM   cls_loss = 0.0
04/23 04:42:42 PM   global_step = 699
04/23 04:42:42 PM   loss = 1.6091092668036706
04/23 04:42:42 PM   rep_loss = 1.0544052217821878
04/23 04:42:42 PM ***** Save model *****
04/23 04:42:50 PM ***** Running evaluation *****
04/23 04:42:50 PM   Epoch = 0 iter 749 step
04/23 04:42:50 PM   Num examples = 1043
04/23 04:42:50 PM   Batch size = 32
04/23 04:42:50 PM ***** Eval results *****
04/23 04:42:50 PM   att_loss = 0.551412858417101
04/23 04:42:50 PM   cls_loss = 0.0
04/23 04:42:50 PM   global_step = 749
04/23 04:42:50 PM   loss = 1.5973147426014431
04/23 04:42:50 PM   rep_loss = 1.045901885656553
04/23 04:42:50 PM ***** Save model *****
04/23 04:42:58 PM ***** Running evaluation *****
04/23 04:42:58 PM   Epoch = 0 iter 799 step
04/23 04:42:58 PM   Num examples = 1043
04/23 04:42:58 PM   Batch size = 32
04/23 04:42:58 PM ***** Eval results *****
04/23 04:42:58 PM   att_loss = 0.5477879589728927
04/23 04:42:58 PM   cls_loss = 0.0
04/23 04:42:58 PM   global_step = 799
04/23 04:42:58 PM   loss = 1.585294088821984
04/23 04:42:58 PM   rep_loss = 1.0375061310426763
04/23 04:42:58 PM ***** Save model *****
04/23 04:43:06 PM ***** Running evaluation *****
04/23 04:43:06 PM   Epoch = 0 iter 849 step
04/23 04:43:06 PM   Num examples = 1043
04/23 04:43:06 PM   Batch size = 32
04/23 04:43:06 PM ***** Eval results *****
04/23 04:43:06 PM   att_loss = 0.5448513486991923
04/23 04:43:06 PM   cls_loss = 0.0
04/23 04:43:06 PM   global_step = 849
04/23 04:43:06 PM   loss = 1.5748352848598899
04/23 04:43:06 PM   rep_loss = 1.0299839373190918
04/23 04:43:06 PM ***** Save model *****
04/23 04:43:14 PM ***** Running evaluation *****
04/23 04:43:14 PM   Epoch = 0 iter 899 step
04/23 04:43:14 PM   Num examples = 1043
04/23 04:43:14 PM   Batch size = 32
04/23 04:43:14 PM ***** Eval results *****
04/23 04:43:14 PM   att_loss = 0.5420577577475844
04/23 04:43:14 PM   cls_loss = 0.0
04/23 04:43:14 PM   global_step = 899
04/23 04:43:14 PM   loss = 1.564972006041428
04/23 04:43:14 PM   rep_loss = 1.022914249056306
04/23 04:43:14 PM ***** Save model *****
04/23 04:43:22 PM ***** Running evaluation *****
04/23 04:43:22 PM   Epoch = 0 iter 949 step
04/23 04:43:22 PM   Num examples = 1043
04/23 04:43:22 PM   Batch size = 32
04/23 04:43:22 PM ***** Eval results *****
04/23 04:43:22 PM   att_loss = 0.5399065640754016
04/23 04:43:22 PM   cls_loss = 0.0
04/23 04:43:22 PM   global_step = 949
04/23 04:43:22 PM   loss = 1.556695635502155
04/23 04:43:22 PM   rep_loss = 1.0167890726201023
04/23 04:43:22 PM ***** Save model *****
04/23 04:43:30 PM ***** Running evaluation *****
04/23 04:43:30 PM   Epoch = 0 iter 999 step
04/23 04:43:30 PM   Num examples = 1043
04/23 04:43:30 PM   Batch size = 32
04/23 04:43:30 PM ***** Eval results *****
04/23 04:43:30 PM   att_loss = 0.537715281541641
04/23 04:43:30 PM   cls_loss = 0.0
04/23 04:43:30 PM   global_step = 999
04/23 04:43:30 PM   loss = 1.5485113326970998
04/23 04:43:30 PM   rep_loss = 1.01079605255757
04/23 04:43:30 PM ***** Save model *****
04/23 04:43:38 PM ***** Running evaluation *****
04/23 04:43:38 PM   Epoch = 0 iter 1049 step
04/23 04:43:38 PM   Num examples = 1043
04/23 04:43:38 PM   Batch size = 32
04/23 04:43:38 PM ***** Eval results *****
04/23 04:43:38 PM   att_loss = 0.5357072930942841
04/23 04:43:38 PM   cls_loss = 0.0
04/23 04:43:38 PM   global_step = 1049
04/23 04:43:38 PM   loss = 1.5408484951670223
04/23 04:43:38 PM   rep_loss = 1.0051412032943776
04/23 04:43:38 PM ***** Save model *****
04/23 04:43:47 PM ***** Running evaluation *****
04/23 04:43:47 PM   Epoch = 0 iter 1099 step
04/23 04:43:47 PM   Num examples = 1043
04/23 04:43:47 PM   Batch size = 32
04/23 04:43:47 PM ***** Eval results *****
04/23 04:43:47 PM   att_loss = 0.5333045553738036
04/23 04:43:47 PM   cls_loss = 0.0
04/23 04:43:47 PM   global_step = 1099
04/23 04:43:47 PM   loss = 1.5328039138071965
04/23 04:43:47 PM   rep_loss = 0.9994993599248648
04/23 04:43:47 PM ***** Save model *****
04/23 04:43:55 PM ***** Running evaluation *****
04/23 04:43:55 PM   Epoch = 0 iter 1149 step
04/23 04:43:55 PM   Num examples = 1043
04/23 04:43:55 PM   Batch size = 32
04/23 04:43:55 PM ***** Eval results *****
04/23 04:43:55 PM   att_loss = 0.531243357168684
04/23 04:43:55 PM   cls_loss = 0.0
04/23 04:43:55 PM   global_step = 1149
04/23 04:43:55 PM   loss = 1.5254856333512654
04/23 04:43:55 PM   rep_loss = 0.9942422777388384
04/23 04:43:55 PM ***** Save model *****
04/23 04:44:03 PM ***** Running evaluation *****
04/23 04:44:03 PM   Epoch = 0 iter 1199 step
04/23 04:44:03 PM   Num examples = 1043
04/23 04:44:03 PM   Batch size = 32
04/23 04:44:03 PM ***** Eval results *****
04/23 04:44:03 PM   att_loss = 0.5294759161180014
04/23 04:44:03 PM   cls_loss = 0.0
04/23 04:44:03 PM   global_step = 1199
04/23 04:44:03 PM   loss = 1.5189811965641724
04/23 04:44:03 PM   rep_loss = 0.9895052822855137
04/23 04:44:03 PM ***** Save model *****
04/23 04:44:11 PM ***** Running evaluation *****
04/23 04:44:11 PM   Epoch = 0 iter 1249 step
04/23 04:44:11 PM   Num examples = 1043
04/23 04:44:11 PM   Batch size = 32
04/23 04:44:11 PM ***** Eval results *****
04/23 04:44:11 PM   att_loss = 0.5279624190590112
04/23 04:44:11 PM   cls_loss = 0.0
04/23 04:44:11 PM   global_step = 1249
04/23 04:44:11 PM   loss = 1.5130253058609913
04/23 04:44:11 PM   rep_loss = 0.9850628887585776
04/23 04:44:11 PM ***** Save model *****
04/23 04:44:19 PM ***** Running evaluation *****
04/23 04:44:19 PM   Epoch = 0 iter 1299 step
04/23 04:44:19 PM   Num examples = 1043
04/23 04:44:19 PM   Batch size = 32
04/23 04:44:19 PM ***** Eval results *****
04/23 04:44:19 PM   att_loss = 0.5266079577094688
04/23 04:44:19 PM   cls_loss = 0.0
04/23 04:44:19 PM   global_step = 1299
04/23 04:44:19 PM   loss = 1.5074318885069062
04/23 04:44:19 PM   rep_loss = 0.980823933022861
04/23 04:44:19 PM ***** Save model *****
04/23 04:44:27 PM ***** Running evaluation *****
04/23 04:44:27 PM   Epoch = 0 iter 1349 step
04/23 04:44:27 PM   Num examples = 1043
04/23 04:44:27 PM   Batch size = 32
04/23 04:44:27 PM ***** Eval results *****
04/23 04:44:27 PM   att_loss = 0.5252860991313247
04/23 04:44:27 PM   cls_loss = 0.0
04/23 04:44:27 PM   global_step = 1349
04/23 04:44:27 PM   loss = 1.5022384509764573
04/23 04:44:27 PM   rep_loss = 0.9769523541427171
04/23 04:44:27 PM ***** Save model *****
04/23 04:44:35 PM ***** Running evaluation *****
04/23 04:44:35 PM   Epoch = 0 iter 1399 step
04/23 04:44:35 PM   Num examples = 1043
04/23 04:44:35 PM   Batch size = 32
04/23 04:44:35 PM ***** Eval results *****
04/23 04:44:35 PM   att_loss = 0.5237263126872623
04/23 04:44:35 PM   cls_loss = 0.0
04/23 04:44:35 PM   global_step = 1399
04/23 04:44:35 PM   loss = 1.496619084036461
04/23 04:44:35 PM   rep_loss = 0.9728927732025239
04/23 04:44:35 PM ***** Save model *****
04/23 04:44:43 PM ***** Running evaluation *****
04/23 04:44:43 PM   Epoch = 0 iter 1449 step
04/23 04:44:43 PM   Num examples = 1043
04/23 04:44:43 PM   Batch size = 32
04/23 04:44:43 PM ***** Eval results *****
04/23 04:44:43 PM   att_loss = 0.5226740319618609
04/23 04:44:43 PM   cls_loss = 0.0
04/23 04:44:43 PM   global_step = 1449
04/23 04:44:43 PM   loss = 1.4918740902216867
04/23 04:44:43 PM   rep_loss = 0.9692000599463616
04/23 04:44:43 PM ***** Save model *****
04/23 04:44:52 PM ***** Running evaluation *****
04/23 04:44:52 PM   Epoch = 0 iter 1499 step
04/23 04:44:52 PM   Num examples = 1043
04/23 04:44:52 PM   Batch size = 32
04/23 04:44:52 PM ***** Eval results *****
04/23 04:44:52 PM   att_loss = 0.5209250828279822
04/23 04:44:52 PM   cls_loss = 0.0
04/23 04:44:52 PM   global_step = 1499
04/23 04:44:52 PM   loss = 1.486272889825008
04/23 04:44:52 PM   rep_loss = 0.9653478086273061
04/23 04:44:52 PM ***** Save model *****
04/23 04:45:00 PM ***** Running evaluation *****
04/23 04:45:00 PM   Epoch = 0 iter 1549 step
04/23 04:45:00 PM   Num examples = 1043
04/23 04:45:00 PM   Batch size = 32
04/23 04:45:00 PM ***** Eval results *****
04/23 04:45:00 PM   att_loss = 0.519505442978106
04/23 04:45:00 PM   cls_loss = 0.0
04/23 04:45:00 PM   global_step = 1549
04/23 04:45:00 PM   loss = 1.4813720875205034
04/23 04:45:00 PM   rep_loss = 0.9618666460623351
04/23 04:45:00 PM ***** Save model *****
04/23 04:45:08 PM ***** Running evaluation *****
04/23 04:45:08 PM   Epoch = 0 iter 1599 step
04/23 04:45:08 PM   Num examples = 1043
04/23 04:45:08 PM   Batch size = 32
04/23 04:45:08 PM ***** Eval results *****
04/23 04:45:08 PM   att_loss = 0.51825028954259
04/23 04:45:08 PM   cls_loss = 0.0
04/23 04:45:08 PM   global_step = 1599
04/23 04:45:08 PM   loss = 1.476669780234384
04/23 04:45:08 PM   rep_loss = 0.9584194924996897
04/23 04:45:08 PM ***** Save model *****
04/23 04:45:16 PM ***** Running evaluation *****
04/23 04:45:16 PM   Epoch = 0 iter 1649 step
04/23 04:45:16 PM   Num examples = 1043
04/23 04:45:16 PM   Batch size = 32
04/23 04:45:16 PM ***** Eval results *****
04/23 04:45:16 PM   att_loss = 0.5172173856351504
04/23 04:45:16 PM   cls_loss = 0.0
04/23 04:45:16 PM   global_step = 1649
04/23 04:45:16 PM   loss = 1.4724957501982254
04/23 04:45:16 PM   rep_loss = 0.955278366207715
04/23 04:45:16 PM ***** Save model *****
04/23 04:45:24 PM ***** Running evaluation *****
04/23 04:45:24 PM   Epoch = 0 iter 1699 step
04/23 04:45:24 PM   Num examples = 1043
04/23 04:45:24 PM   Batch size = 32
04/23 04:45:24 PM ***** Eval results *****
04/23 04:45:24 PM   att_loss = 0.5156381329485358
04/23 04:45:24 PM   cls_loss = 0.0
04/23 04:45:24 PM   global_step = 1699
04/23 04:45:24 PM   loss = 1.4676543881852462
04/23 04:45:24 PM   rep_loss = 0.9520162567101625
04/23 04:45:24 PM ***** Save model *****
04/23 04:45:32 PM ***** Running evaluation *****
04/23 04:45:32 PM   Epoch = 0 iter 1749 step
04/23 04:45:32 PM   Num examples = 1043
04/23 04:45:32 PM   Batch size = 32
04/23 04:45:32 PM ***** Eval results *****
04/23 04:45:32 PM   att_loss = 0.5144388611450271
04/23 04:45:32 PM   cls_loss = 0.0
04/23 04:45:32 PM   global_step = 1749
04/23 04:45:32 PM   loss = 1.4633684168548977
04/23 04:45:32 PM   rep_loss = 0.9489295574308737
04/23 04:45:32 PM ***** Save model *****
04/23 04:45:40 PM ***** Running evaluation *****
04/23 04:45:40 PM   Epoch = 0 iter 1799 step
04/23 04:45:40 PM   Num examples = 1043
04/23 04:45:40 PM   Batch size = 32
04/23 04:45:40 PM ***** Eval results *****
04/23 04:45:40 PM   att_loss = 0.5134793587728896
04/23 04:45:40 PM   cls_loss = 0.0
04/23 04:45:40 PM   global_step = 1799
04/23 04:45:40 PM   loss = 1.4596004016933473
04/23 04:45:40 PM   rep_loss = 0.9461210445273645
04/23 04:45:40 PM ***** Save model *****
04/23 04:45:48 PM ***** Running evaluation *****
04/23 04:45:48 PM   Epoch = 0 iter 1849 step
04/23 04:45:48 PM   Num examples = 1043
04/23 04:45:48 PM   Batch size = 32
04/23 04:45:48 PM ***** Eval results *****
04/23 04:45:48 PM   att_loss = 0.512291349708357
04/23 04:45:48 PM   cls_loss = 0.0
04/23 04:45:48 PM   global_step = 1849
04/23 04:45:48 PM   loss = 1.4554595666811103
04/23 04:45:48 PM   rep_loss = 0.9431682184556164
04/23 04:45:48 PM ***** Save model *****
04/23 04:45:57 PM ***** Running evaluation *****
04/23 04:45:57 PM   Epoch = 0 iter 1899 step
04/23 04:45:57 PM   Num examples = 1043
04/23 04:45:57 PM   Batch size = 32
04/23 04:45:57 PM ***** Eval results *****
04/23 04:45:57 PM   att_loss = 0.5112683809764013
04/23 04:45:57 PM   cls_loss = 0.0
04/23 04:45:57 PM   global_step = 1899
04/23 04:45:57 PM   loss = 1.4516289883252507
04/23 04:45:57 PM   rep_loss = 0.9403606085729573
04/23 04:45:57 PM ***** Save model *****
04/23 04:46:05 PM ***** Running evaluation *****
04/23 04:46:05 PM   Epoch = 0 iter 1949 step
04/23 04:46:05 PM   Num examples = 1043
04/23 04:46:05 PM   Batch size = 32
04/23 04:46:05 PM ***** Eval results *****
04/23 04:46:05 PM   att_loss = 0.5104440859246095
04/23 04:46:05 PM   cls_loss = 0.0
04/23 04:46:05 PM   global_step = 1949
04/23 04:46:05 PM   loss = 1.4482678101575333
04/23 04:46:05 PM   rep_loss = 0.9378237251503887
04/23 04:46:05 PM ***** Save model *****
04/23 04:46:13 PM ***** Running evaluation *****
04/23 04:46:13 PM   Epoch = 0 iter 1999 step
04/23 04:46:13 PM   Num examples = 1043
04/23 04:46:13 PM   Batch size = 32
04/23 04:46:13 PM ***** Eval results *****
04/23 04:46:13 PM   att_loss = 0.5094815276007821
04/23 04:46:13 PM   cls_loss = 0.0
04/23 04:46:13 PM   global_step = 1999
04/23 04:46:13 PM   loss = 1.4447870894990724
04/23 04:46:13 PM   rep_loss = 0.9353055625989951
04/23 04:46:13 PM ***** Save model *****
04/23 04:46:21 PM ***** Running evaluation *****
04/23 04:46:21 PM   Epoch = 0 iter 2049 step
04/23 04:46:21 PM   Num examples = 1043
04/23 04:46:21 PM   Batch size = 32
04/23 04:46:21 PM ***** Eval results *****
04/23 04:46:21 PM   att_loss = 0.5085577262268234
04/23 04:46:21 PM   cls_loss = 0.0
04/23 04:46:21 PM   global_step = 2049
04/23 04:46:21 PM   loss = 1.4413283867856943
04/23 04:46:21 PM   rep_loss = 0.9327706613152013
04/23 04:46:21 PM ***** Save model *****
04/23 04:46:29 PM ***** Running evaluation *****
04/23 04:46:29 PM   Epoch = 0 iter 2099 step
04/23 04:46:29 PM   Num examples = 1043
04/23 04:46:29 PM   Batch size = 32
04/23 04:46:29 PM ***** Eval results *****
04/23 04:46:29 PM   att_loss = 0.5079781682988812
04/23 04:46:29 PM   cls_loss = 0.0
04/23 04:46:29 PM   global_step = 2099
04/23 04:46:29 PM   loss = 1.4383500869527437
04/23 04:46:29 PM   rep_loss = 0.930371919377978
04/23 04:46:29 PM ***** Save model *****
04/23 04:46:37 PM ***** Running evaluation *****
04/23 04:46:37 PM   Epoch = 0 iter 2149 step
04/23 04:46:37 PM   Num examples = 1043
04/23 04:46:37 PM   Batch size = 32
04/23 04:46:37 PM ***** Eval results *****
04/23 04:46:37 PM   att_loss = 0.5070300478333926
04/23 04:46:37 PM   cls_loss = 0.0
04/23 04:46:37 PM   global_step = 2149
04/23 04:46:37 PM   loss = 1.4349409535409352
04/23 04:46:37 PM   rep_loss = 0.9279109063732064
04/23 04:46:37 PM ***** Save model *****
04/23 04:46:45 PM ***** Running evaluation *****
04/23 04:46:45 PM   Epoch = 0 iter 2199 step
04/23 04:46:45 PM   Num examples = 1043
04/23 04:46:45 PM   Batch size = 32
04/23 04:46:45 PM ***** Eval results *****
04/23 04:46:45 PM   att_loss = 0.5061458316294916
04/23 04:46:45 PM   cls_loss = 0.0
04/23 04:46:45 PM   global_step = 2199
04/23 04:46:45 PM   loss = 1.4317639062165022
04/23 04:46:45 PM   rep_loss = 0.9256180750884594
04/23 04:46:45 PM ***** Save model *****
04/23 04:46:53 PM ***** Running evaluation *****
04/23 04:46:53 PM   Epoch = 0 iter 2249 step
04/23 04:46:53 PM   Num examples = 1043
04/23 04:46:53 PM   Batch size = 32
04/23 04:46:53 PM ***** Eval results *****
04/23 04:46:53 PM   att_loss = 0.5054114753005239
04/23 04:46:53 PM   cls_loss = 0.0
04/23 04:46:53 PM   global_step = 2249
04/23 04:46:53 PM   loss = 1.4288211432283537
04/23 04:46:53 PM   rep_loss = 0.9234096684313817
04/23 04:46:53 PM ***** Save model *****
04/23 04:47:02 PM ***** Running evaluation *****
04/23 04:47:02 PM   Epoch = 0 iter 2299 step
04/23 04:47:02 PM   Num examples = 1043
04/23 04:47:02 PM   Batch size = 32
04/23 04:47:02 PM ***** Eval results *****
04/23 04:47:02 PM   att_loss = 0.5046933958482721
04/23 04:47:02 PM   cls_loss = 0.0
04/23 04:47:02 PM   global_step = 2299
04/23 04:47:02 PM   loss = 1.4259800864282304
04/23 04:47:02 PM   rep_loss = 0.9212866910855217
04/23 04:47:02 PM ***** Save model *****
04/23 04:47:10 PM ***** Running evaluation *****
04/23 04:47:10 PM   Epoch = 0 iter 2349 step
04/23 04:47:10 PM   Num examples = 1043
04/23 04:47:10 PM   Batch size = 32
04/23 04:47:10 PM ***** Eval results *****
04/23 04:47:10 PM   att_loss = 0.503983806579252
04/23 04:47:10 PM   cls_loss = 0.0
04/23 04:47:10 PM   global_step = 2349
04/23 04:47:10 PM   loss = 1.423177511400748
04/23 04:47:10 PM   rep_loss = 0.9191937053036111
04/23 04:47:10 PM ***** Save model *****
04/23 04:47:18 PM ***** Running evaluation *****
04/23 04:47:18 PM   Epoch = 0 iter 2399 step
04/23 04:47:18 PM   Num examples = 1043
04/23 04:47:18 PM   Batch size = 32
04/23 04:47:18 PM ***** Eval results *****
04/23 04:47:18 PM   att_loss = 0.5032012577899648
04/23 04:47:18 PM   cls_loss = 0.0
04/23 04:47:18 PM   global_step = 2399
04/23 04:47:18 PM   loss = 1.4202576445857402
04/23 04:47:18 PM   rep_loss = 0.9170563872678422
04/23 04:47:18 PM ***** Save model *****
04/23 04:47:26 PM ***** Running evaluation *****
04/23 04:47:26 PM   Epoch = 0 iter 2449 step
04/23 04:47:26 PM   Num examples = 1043
04/23 04:47:26 PM   Batch size = 32
04/23 04:47:26 PM ***** Eval results *****
04/23 04:47:26 PM   att_loss = 0.5024992646904272
04/23 04:47:26 PM   cls_loss = 0.0
04/23 04:47:26 PM   global_step = 2449
04/23 04:47:26 PM   loss = 1.417576151655469
04/23 04:47:26 PM   rep_loss = 0.9150768873544555
04/23 04:47:26 PM ***** Save model *****
04/23 04:47:34 PM ***** Running evaluation *****
04/23 04:47:34 PM   Epoch = 0 iter 2499 step
04/23 04:47:34 PM   Num examples = 1043
04/23 04:47:34 PM   Batch size = 32
04/23 04:47:34 PM ***** Eval results *****
04/23 04:47:34 PM   att_loss = 0.5017349174281224
04/23 04:47:34 PM   cls_loss = 0.0
04/23 04:47:34 PM   global_step = 2499
04/23 04:47:34 PM   loss = 1.4147467879401823
04/23 04:47:34 PM   rep_loss = 0.9130118710844933
04/23 04:47:34 PM ***** Save model *****
04/23 04:47:42 PM ***** Running evaluation *****
04/23 04:47:42 PM   Epoch = 0 iter 2549 step
04/23 04:47:42 PM   Num examples = 1043
04/23 04:47:42 PM   Batch size = 32
04/23 04:47:42 PM ***** Eval results *****
04/23 04:47:42 PM   att_loss = 0.5011888354864715
04/23 04:47:42 PM   cls_loss = 0.0
04/23 04:47:42 PM   global_step = 2549
04/23 04:47:42 PM   loss = 1.4122899426530977
04/23 04:47:42 PM   rep_loss = 0.911101107739523
04/23 04:47:42 PM ***** Save model *****
04/23 04:47:50 PM ***** Running evaluation *****
04/23 04:47:50 PM   Epoch = 0 iter 2599 step
04/23 04:47:50 PM   Num examples = 1043
04/23 04:47:50 PM   Batch size = 32
04/23 04:47:50 PM ***** Eval results *****
04/23 04:47:50 PM   att_loss = 0.5006957682635794
04/23 04:47:50 PM   cls_loss = 0.0
04/23 04:47:50 PM   global_step = 2599
04/23 04:47:50 PM   loss = 1.4099007335797142
04/23 04:47:50 PM   rep_loss = 0.909204965809209
04/23 04:47:50 PM ***** Save model *****
04/23 04:47:58 PM ***** Running evaluation *****
04/23 04:47:58 PM   Epoch = 0 iter 2649 step
04/23 04:47:58 PM   Num examples = 1043
04/23 04:47:58 PM   Batch size = 32
04/23 04:47:58 PM ***** Eval results *****
04/23 04:47:58 PM   att_loss = 0.5000467955638617
04/23 04:47:58 PM   cls_loss = 0.0
04/23 04:47:58 PM   global_step = 2649
04/23 04:47:58 PM   loss = 1.4073978785795282
04/23 04:47:58 PM   rep_loss = 0.9073510834206812
04/23 04:47:58 PM ***** Save model *****
04/23 04:48:06 PM ***** Running evaluation *****
04/23 04:48:06 PM   Epoch = 0 iter 2699 step
04/23 04:48:06 PM   Num examples = 1043
04/23 04:48:06 PM   Batch size = 32
04/23 04:48:06 PM ***** Eval results *****
04/23 04:48:06 PM   att_loss = 0.49938726002262807
04/23 04:48:06 PM   cls_loss = 0.0
04/23 04:48:06 PM   global_step = 2699
04/23 04:48:06 PM   loss = 1.404941402130014
04/23 04:48:06 PM   rep_loss = 0.9055541426926111
04/23 04:48:06 PM ***** Save model *****
04/23 04:48:15 PM ***** Running evaluation *****
04/23 04:48:15 PM   Epoch = 0 iter 2749 step
04/23 04:48:15 PM   Num examples = 1043
04/23 04:48:15 PM   Batch size = 32
04/23 04:48:15 PM ***** Eval results *****
04/23 04:48:15 PM   att_loss = 0.49893945913047694
04/23 04:48:15 PM   cls_loss = 0.0
04/23 04:48:15 PM   global_step = 2749
04/23 04:48:15 PM   loss = 1.4028480359969377
04/23 04:48:15 PM   rep_loss = 0.9039085774085183
04/23 04:48:15 PM ***** Save model *****
04/23 04:48:23 PM ***** Running evaluation *****
04/23 04:48:23 PM   Epoch = 0 iter 2799 step
04/23 04:48:23 PM   Num examples = 1043
04/23 04:48:23 PM   Batch size = 32
04/23 04:48:23 PM ***** Eval results *****
04/23 04:48:23 PM   att_loss = 0.49834766969079414
04/23 04:48:23 PM   cls_loss = 0.0
04/23 04:48:23 PM   global_step = 2799
04/23 04:48:23 PM   loss = 1.4005369418175913
04/23 04:48:23 PM   rep_loss = 0.902189272733704
04/23 04:48:23 PM ***** Save model *****
04/23 04:48:31 PM ***** Running evaluation *****
04/23 04:48:31 PM   Epoch = 0 iter 2849 step
04/23 04:48:31 PM   Num examples = 1043
04/23 04:48:31 PM   Batch size = 32
04/23 04:48:31 PM ***** Eval results *****
04/23 04:48:31 PM   att_loss = 0.49785811527020557
04/23 04:48:31 PM   cls_loss = 0.0
04/23 04:48:31 PM   global_step = 2849
04/23 04:48:31 PM   loss = 1.3983851076218488
04/23 04:48:31 PM   rep_loss = 0.9005269929374381
04/23 04:48:31 PM ***** Save model *****
04/23 04:48:39 PM ***** Running evaluation *****
04/23 04:48:39 PM   Epoch = 0 iter 2899 step
04/23 04:48:39 PM   Num examples = 1043
04/23 04:48:39 PM   Batch size = 32
04/23 04:48:39 PM ***** Eval results *****
04/23 04:48:39 PM   att_loss = 0.49717336382155336
04/23 04:48:39 PM   cls_loss = 0.0
04/23 04:48:39 PM   global_step = 2899
04/23 04:48:39 PM   loss = 1.3959620772003511
04/23 04:48:39 PM   rep_loss = 0.8987887138825279
04/23 04:48:39 PM ***** Save model *****
04/23 04:48:47 PM ***** Running evaluation *****
04/23 04:48:47 PM   Epoch = 0 iter 2949 step
04/23 04:48:47 PM   Num examples = 1043
04/23 04:48:47 PM   Batch size = 32
04/23 04:48:47 PM ***** Eval results *****
04/23 04:48:47 PM   att_loss = 0.4966477267355707
04/23 04:48:47 PM   cls_loss = 0.0
04/23 04:48:47 PM   global_step = 2949
04/23 04:48:47 PM   loss = 1.3938191222433076
04/23 04:48:47 PM   rep_loss = 0.8971713958816554
04/23 04:48:47 PM ***** Save model *****
04/23 04:48:55 PM ***** Running evaluation *****
04/23 04:48:55 PM   Epoch = 0 iter 2999 step
04/23 04:48:55 PM   Num examples = 1043
04/23 04:48:55 PM   Batch size = 32
04/23 04:48:55 PM ***** Eval results *****
04/23 04:48:55 PM   att_loss = 0.4961193519240421
04/23 04:48:55 PM   cls_loss = 0.0
04/23 04:48:55 PM   global_step = 2999
04/23 04:48:55 PM   loss = 1.391657650172611
04/23 04:48:55 PM   rep_loss = 0.8955382986162534
04/23 04:48:55 PM ***** Save model *****
04/23 04:49:03 PM ***** Running evaluation *****
04/23 04:49:03 PM   Epoch = 0 iter 3049 step
04/23 04:49:03 PM   Num examples = 1043
04/23 04:49:03 PM   Batch size = 32
04/23 04:49:03 PM ***** Eval results *****
04/23 04:49:03 PM   att_loss = 0.49543987069414575
04/23 04:49:03 PM   cls_loss = 0.0
04/23 04:49:03 PM   global_step = 3049
04/23 04:49:03 PM   loss = 1.3893559950615548
04/23 04:49:03 PM   rep_loss = 0.8939161248659063
04/23 04:49:03 PM ***** Save model *****
04/23 04:49:11 PM ***** Running evaluation *****
04/23 04:49:11 PM   Epoch = 0 iter 3099 step
04/23 04:49:11 PM   Num examples = 1043
04/23 04:49:11 PM   Batch size = 32
04/23 04:49:11 PM ***** Eval results *****
04/23 04:49:11 PM   att_loss = 0.49502956861447966
04/23 04:49:11 PM   cls_loss = 0.0
04/23 04:49:11 PM   global_step = 3099
04/23 04:49:11 PM   loss = 1.387458193682978
04/23 04:49:11 PM   rep_loss = 0.8924286255493361
04/23 04:49:11 PM ***** Save model *****
04/23 04:49:20 PM ***** Running evaluation *****
04/23 04:49:20 PM   Epoch = 0 iter 3149 step
04/23 04:49:20 PM   Num examples = 1043
04/23 04:49:20 PM   Batch size = 32
04/23 04:49:20 PM ***** Eval results *****
04/23 04:49:20 PM   att_loss = 0.49427158774251445
04/23 04:49:20 PM   cls_loss = 0.0
04/23 04:49:20 PM   global_step = 3149
04/23 04:49:20 PM   loss = 1.3850989836138292
04/23 04:49:20 PM   rep_loss = 0.8908273963634459
04/23 04:49:20 PM ***** Save model *****
04/23 04:49:28 PM ***** Running evaluation *****
04/23 04:49:28 PM   Epoch = 0 iter 3199 step
04/23 04:49:28 PM   Num examples = 1043
04/23 04:49:28 PM   Batch size = 32
04/23 04:49:28 PM ***** Eval results *****
04/23 04:49:28 PM   att_loss = 0.49371000130350196
04/23 04:49:28 PM   cls_loss = 0.0
04/23 04:49:28 PM   global_step = 3199
04/23 04:49:28 PM   loss = 1.383049374746136
04/23 04:49:28 PM   rep_loss = 0.8893393738339118
04/23 04:49:28 PM ***** Save model *****
04/23 04:49:36 PM ***** Running evaluation *****
04/23 04:49:36 PM   Epoch = 0 iter 3249 step
04/23 04:49:36 PM   Num examples = 1043
04/23 04:49:36 PM   Batch size = 32
04/23 04:49:36 PM ***** Eval results *****
04/23 04:49:36 PM   att_loss = 0.49329618142362225
04/23 04:49:36 PM   cls_loss = 0.0
04/23 04:49:36 PM   global_step = 3249
04/23 04:49:36 PM   loss = 1.3812203971229358
04/23 04:49:36 PM   rep_loss = 0.8879242160937426
04/23 04:49:36 PM ***** Save model *****
04/23 04:49:44 PM ***** Running evaluation *****
04/23 04:49:44 PM   Epoch = 0 iter 3299 step
04/23 04:49:44 PM   Num examples = 1043
04/23 04:49:44 PM   Batch size = 32
04/23 04:49:44 PM ***** Eval results *****
04/23 04:49:44 PM   att_loss = 0.4927860422544893
04/23 04:49:44 PM   cls_loss = 0.0
04/23 04:49:44 PM   global_step = 3299
04/23 04:49:44 PM   loss = 1.3793070794741795
04/23 04:49:44 PM   rep_loss = 0.8865210377797823
04/23 04:49:44 PM ***** Save model *****
04/23 04:49:52 PM ***** Running evaluation *****
04/23 04:49:52 PM   Epoch = 0 iter 3349 step
04/23 04:49:52 PM   Num examples = 1043
04/23 04:49:52 PM   Batch size = 32
04/23 04:49:52 PM ***** Eval results *****
04/23 04:49:52 PM   att_loss = 0.49232428997230016
04/23 04:49:52 PM   cls_loss = 0.0
04/23 04:49:52 PM   global_step = 3349
04/23 04:49:52 PM   loss = 1.3775437783041653
04/23 04:49:52 PM   rep_loss = 0.8852194888657974
04/23 04:49:52 PM ***** Save model *****
04/23 04:50:00 PM ***** Running evaluation *****
04/23 04:50:00 PM   Epoch = 0 iter 3399 step
04/23 04:50:00 PM   Num examples = 1043
04/23 04:50:00 PM   Batch size = 32
04/23 04:50:00 PM ***** Eval results *****
04/23 04:50:00 PM   att_loss = 0.4919586522013133
04/23 04:50:00 PM   cls_loss = 0.0
04/23 04:50:00 PM   global_step = 3399
04/23 04:50:00 PM   loss = 1.375814779325947
04/23 04:50:00 PM   rep_loss = 0.8838561276857837
04/23 04:50:00 PM ***** Save model *****
04/23 04:50:08 PM ***** Running evaluation *****
04/23 04:50:08 PM   Epoch = 0 iter 3449 step
04/23 04:50:08 PM   Num examples = 1043
04/23 04:50:08 PM   Batch size = 32
04/23 04:50:08 PM ***** Eval results *****
04/23 04:50:08 PM   att_loss = 0.4916099039548789
04/23 04:50:08 PM   cls_loss = 0.0
04/23 04:50:08 PM   global_step = 3449
04/23 04:50:08 PM   loss = 1.3740735562789885
04/23 04:50:08 PM   rep_loss = 0.8824636529203289
04/23 04:50:08 PM ***** Save model *****
04/23 04:50:16 PM ***** Running evaluation *****
04/23 04:50:16 PM   Epoch = 0 iter 3499 step
04/23 04:50:16 PM   Num examples = 1043
04/23 04:50:16 PM   Batch size = 32
04/23 04:50:16 PM ***** Eval results *****
04/23 04:50:16 PM   att_loss = 0.4909867847364403
04/23 04:50:16 PM   cls_loss = 0.0
04/23 04:50:16 PM   global_step = 3499
04/23 04:50:16 PM   loss = 1.372075335643536
04/23 04:50:16 PM   rep_loss = 0.8810885514351735
04/23 04:50:16 PM ***** Save model *****
04/23 04:50:24 PM ***** Running evaluation *****
04/23 04:50:24 PM   Epoch = 0 iter 3549 step
04/23 04:50:24 PM   Num examples = 1043
04/23 04:50:24 PM   Batch size = 32
04/23 04:50:24 PM ***** Eval results *****
04/23 04:50:24 PM   att_loss = 0.4905031336616818
04/23 04:50:24 PM   cls_loss = 0.0
04/23 04:50:24 PM   global_step = 3549
04/23 04:50:24 PM   loss = 1.3702534536604614
04/23 04:50:24 PM   rep_loss = 0.8797503205278149
04/23 04:50:24 PM ***** Save model *****
04/23 04:50:33 PM ***** Running evaluation *****
04/23 04:50:33 PM   Epoch = 0 iter 3599 step
04/23 04:50:33 PM   Num examples = 1043
04/23 04:50:33 PM   Batch size = 32
04/23 04:50:33 PM ***** Eval results *****
04/23 04:50:33 PM   att_loss = 0.4900807726379897
04/23 04:50:33 PM   cls_loss = 0.0
04/23 04:50:33 PM   global_step = 3599
04/23 04:50:33 PM   loss = 1.3685657811449712
04/23 04:50:33 PM   rep_loss = 0.8784850089044562
04/23 04:50:33 PM ***** Save model *****
04/23 04:50:41 PM ***** Running evaluation *****
04/23 04:50:41 PM   Epoch = 0 iter 3649 step
04/23 04:50:41 PM   Num examples = 1043
04/23 04:50:41 PM   Batch size = 32
04/23 04:50:41 PM ***** Eval results *****
04/23 04:50:41 PM   att_loss = 0.489599498413007
04/23 04:50:41 PM   cls_loss = 0.0
04/23 04:50:41 PM   global_step = 3649
04/23 04:50:41 PM   loss = 1.3668065565061687
04/23 04:50:41 PM   rep_loss = 0.8772070583953502
04/23 04:50:41 PM ***** Save model *****
04/23 04:50:49 PM ***** Running evaluation *****
04/23 04:50:49 PM   Epoch = 0 iter 3699 step
04/23 04:50:49 PM   Num examples = 1043
04/23 04:50:49 PM   Batch size = 32
04/23 04:50:49 PM ***** Eval results *****
04/23 04:50:49 PM   att_loss = 0.489105174463483
04/23 04:50:49 PM   cls_loss = 0.0
04/23 04:50:49 PM   global_step = 3699
04/23 04:50:49 PM   loss = 1.365049253028288
04/23 04:50:49 PM   rep_loss = 0.8759440786292598
04/23 04:50:49 PM ***** Save model *****
04/23 04:50:57 PM ***** Running evaluation *****
04/23 04:50:57 PM   Epoch = 0 iter 3749 step
04/23 04:50:57 PM   Num examples = 1043
04/23 04:50:57 PM   Batch size = 32
04/23 04:50:57 PM ***** Eval results *****
04/23 04:50:57 PM   att_loss = 0.4887798364304263
04/23 04:50:57 PM   cls_loss = 0.0
04/23 04:50:57 PM   global_step = 3749
04/23 04:50:57 PM   loss = 1.363527840727264
04/23 04:50:57 PM   rep_loss = 0.8747480042650402
04/23 04:50:57 PM ***** Save model *****
04/23 04:51:05 PM ***** Running evaluation *****
04/23 04:51:05 PM   Epoch = 0 iter 3799 step
04/23 04:51:05 PM   Num examples = 1043
04/23 04:51:05 PM   Batch size = 32
04/23 04:51:05 PM ***** Eval results *****
04/23 04:51:05 PM   att_loss = 0.48828662655390576
04/23 04:51:05 PM   cls_loss = 0.0
04/23 04:51:05 PM   global_step = 3799
04/23 04:51:05 PM   loss = 1.3618121649849317
04/23 04:51:05 PM   rep_loss = 0.8735255383290439
04/23 04:51:05 PM ***** Save model *****
04/23 04:51:13 PM ***** Running evaluation *****
04/23 04:51:13 PM   Epoch = 0 iter 3849 step
04/23 04:51:13 PM   Num examples = 1043
04/23 04:51:13 PM   Batch size = 32
04/23 04:51:13 PM ***** Eval results *****
04/23 04:51:13 PM   att_loss = 0.4878282335616608
04/23 04:51:13 PM   cls_loss = 0.0
04/23 04:51:13 PM   global_step = 3849
04/23 04:51:13 PM   loss = 1.3600715431927952
04/23 04:51:13 PM   rep_loss = 0.8722433095537059
04/23 04:51:13 PM ***** Save model *****
04/23 04:51:21 PM ***** Running evaluation *****
04/23 04:51:21 PM   Epoch = 0 iter 3899 step
04/23 04:51:21 PM   Num examples = 1043
04/23 04:51:21 PM   Batch size = 32
04/23 04:51:21 PM ***** Eval results *****
04/23 04:51:21 PM   att_loss = 0.4873047750801513
04/23 04:51:21 PM   cls_loss = 0.0
04/23 04:51:21 PM   global_step = 3899
04/23 04:51:21 PM   loss = 1.3583863536404719
04/23 04:51:21 PM   rep_loss = 0.8710815784533105
04/23 04:51:21 PM ***** Save model *****
04/23 04:51:29 PM ***** Running evaluation *****
04/23 04:51:29 PM   Epoch = 0 iter 3949 step
04/23 04:51:29 PM   Num examples = 1043
04/23 04:51:29 PM   Batch size = 32
04/23 04:51:29 PM ***** Eval results *****
04/23 04:51:29 PM   att_loss = 0.48682779746889976
04/23 04:51:29 PM   cls_loss = 0.0
04/23 04:51:29 PM   global_step = 3949
04/23 04:51:29 PM   loss = 1.356723344425637
04/23 04:51:29 PM   rep_loss = 0.8698955468963628
04/23 04:51:29 PM ***** Save model *****
04/23 04:51:37 PM ***** Running evaluation *****
04/23 04:51:37 PM   Epoch = 0 iter 3999 step
04/23 04:51:37 PM   Num examples = 1043
04/23 04:51:37 PM   Batch size = 32
04/23 04:51:37 PM ***** Eval results *****
04/23 04:51:37 PM   att_loss = 0.486394489994941
04/23 04:51:37 PM   cls_loss = 0.0
04/23 04:51:37 PM   global_step = 3999
04/23 04:51:37 PM   loss = 1.355141908265734
04/23 04:51:37 PM   rep_loss = 0.8687474181068394
04/23 04:51:37 PM ***** Save model *****
04/23 04:51:46 PM ***** Running evaluation *****
04/23 04:51:46 PM   Epoch = 0 iter 4049 step
04/23 04:51:46 PM   Num examples = 1043
04/23 04:51:46 PM   Batch size = 32
04/23 04:51:46 PM ***** Eval results *****
04/23 04:51:46 PM   att_loss = 0.4860028927783726
04/23 04:51:46 PM   cls_loss = 0.0
04/23 04:51:46 PM   global_step = 4049
04/23 04:51:46 PM   loss = 1.3536072329669329
04/23 04:51:46 PM   rep_loss = 0.8676043399971896
04/23 04:51:46 PM ***** Save model *****
04/23 04:51:54 PM ***** Running evaluation *****
04/23 04:51:54 PM   Epoch = 0 iter 4099 step
04/23 04:51:54 PM   Num examples = 1043
04/23 04:51:54 PM   Batch size = 32
04/23 04:51:54 PM ***** Eval results *****
04/23 04:51:54 PM   att_loss = 0.48563178016314074
04/23 04:51:54 PM   cls_loss = 0.0
04/23 04:51:54 PM   global_step = 4099
04/23 04:51:54 PM   loss = 1.3521114297249341
04/23 04:51:54 PM   rep_loss = 0.8664796493872982
04/23 04:51:54 PM ***** Save model *****
04/23 04:52:02 PM ***** Running evaluation *****
04/23 04:52:02 PM   Epoch = 0 iter 4149 step
04/23 04:52:02 PM   Num examples = 1043
04/23 04:52:02 PM   Batch size = 32
04/23 04:52:02 PM ***** Eval results *****
04/23 04:52:02 PM   att_loss = 0.4853153165549248
04/23 04:52:02 PM   cls_loss = 0.0
04/23 04:52:02 PM   global_step = 4149
04/23 04:52:02 PM   loss = 1.3507266526165915
04/23 04:52:02 PM   rep_loss = 0.8654113358174441
04/23 04:52:02 PM ***** Save model *****
04/23 04:52:10 PM ***** Running evaluation *****
04/23 04:52:10 PM   Epoch = 0 iter 4199 step
04/23 04:52:10 PM   Num examples = 1043
04/23 04:52:10 PM   Batch size = 32
04/23 04:52:10 PM ***** Eval results *****
04/23 04:52:10 PM   att_loss = 0.4850091627167077
04/23 04:52:10 PM   cls_loss = 0.0
04/23 04:52:10 PM   global_step = 4199
04/23 04:52:10 PM   loss = 1.3493500097106257
04/23 04:52:10 PM   rep_loss = 0.8643408467951886
04/23 04:52:10 PM ***** Save model *****
04/23 04:52:18 PM ***** Running evaluation *****
04/23 04:52:18 PM   Epoch = 0 iter 4249 step
04/23 04:52:18 PM   Num examples = 1043
04/23 04:52:18 PM   Batch size = 32
04/23 04:52:18 PM ***** Eval results *****
04/23 04:52:18 PM   att_loss = 0.4847813516988505
04/23 04:52:18 PM   cls_loss = 0.0
04/23 04:52:18 PM   global_step = 4249
04/23 04:52:18 PM   loss = 1.3481063520692325
04/23 04:52:18 PM   rep_loss = 0.8633250002020469
04/23 04:52:18 PM ***** Save model *****
04/23 04:52:26 PM ***** Running evaluation *****
04/23 04:52:26 PM   Epoch = 0 iter 4299 step
04/23 04:52:26 PM   Num examples = 1043
04/23 04:52:26 PM   Batch size = 32
04/23 04:52:26 PM ***** Eval results *****
04/23 04:52:26 PM   att_loss = 0.48435960069842937
04/23 04:52:26 PM   cls_loss = 0.0
04/23 04:52:26 PM   global_step = 4299
04/23 04:52:26 PM   loss = 1.3466288216808946
04/23 04:52:26 PM   rep_loss = 0.8622692208646148
04/23 04:52:26 PM ***** Save model *****
04/23 04:52:34 PM ***** Running evaluation *****
04/23 04:52:34 PM   Epoch = 0 iter 4349 step
04/23 04:52:34 PM   Num examples = 1043
04/23 04:52:34 PM   Batch size = 32
04/23 04:52:34 PM ***** Eval results *****
04/23 04:52:34 PM   att_loss = 0.48396469345995136
04/23 04:52:34 PM   cls_loss = 0.0
04/23 04:52:34 PM   global_step = 4349
04/23 04:52:34 PM   loss = 1.3452144653447937
04/23 04:52:34 PM   rep_loss = 0.8612497718368736
04/23 04:52:34 PM ***** Save model *****
04/23 04:52:42 PM ***** Running evaluation *****
04/23 04:52:42 PM   Epoch = 0 iter 4399 step
04/23 04:52:42 PM   Num examples = 1043
04/23 04:52:42 PM   Batch size = 32
04/23 04:52:42 PM ***** Eval results *****
04/23 04:52:42 PM   att_loss = 0.4835098154654853
04/23 04:52:42 PM   cls_loss = 0.0
04/23 04:52:42 PM   global_step = 4399
04/23 04:52:42 PM   loss = 1.3436775419164122
04/23 04:52:42 PM   rep_loss = 0.8601677263560797
04/23 04:52:42 PM ***** Save model *****
04/23 04:52:51 PM ***** Running evaluation *****
04/23 04:52:51 PM   Epoch = 0 iter 4449 step
04/23 04:52:51 PM   Num examples = 1043
04/23 04:52:51 PM   Batch size = 32
04/23 04:52:51 PM ***** Eval results *****
04/23 04:52:51 PM   att_loss = 0.48322119404557423
04/23 04:52:51 PM   cls_loss = 0.0
04/23 04:52:51 PM   global_step = 4449
04/23 04:52:51 PM   loss = 1.3424518210187497
04/23 04:52:51 PM   rep_loss = 0.8592306269530795
04/23 04:52:51 PM ***** Save model *****
04/23 04:52:59 PM ***** Running evaluation *****
04/23 04:52:59 PM   Epoch = 0 iter 4499 step
04/23 04:52:59 PM   Num examples = 1043
04/23 04:52:59 PM   Batch size = 32
04/23 04:52:59 PM ***** Eval results *****
04/23 04:52:59 PM   att_loss = 0.4828072219431255
04/23 04:52:59 PM   cls_loss = 0.0
04/23 04:52:59 PM   global_step = 4499
04/23 04:52:59 PM   loss = 1.3410476830885871
04/23 04:52:59 PM   rep_loss = 0.8582404611057164
04/23 04:52:59 PM ***** Save model *****
04/23 04:53:07 PM ***** Running evaluation *****
04/23 04:53:07 PM   Epoch = 0 iter 4549 step
04/23 04:53:07 PM   Num examples = 1043
04/23 04:53:07 PM   Batch size = 32
04/23 04:53:07 PM ***** Eval results *****
04/23 04:53:07 PM   att_loss = 0.4824644623418042
04/23 04:53:07 PM   cls_loss = 0.0
04/23 04:53:07 PM   global_step = 4549
04/23 04:53:07 PM   loss = 1.3397041210160725
04/23 04:53:07 PM   rep_loss = 0.8572396585694458
04/23 04:53:07 PM ***** Save model *****
04/23 04:53:15 PM ***** Running evaluation *****
04/23 04:53:15 PM   Epoch = 0 iter 4599 step
04/23 04:53:15 PM   Num examples = 1043
04/23 04:53:15 PM   Batch size = 32
04/23 04:53:15 PM ***** Eval results *****
04/23 04:53:15 PM   att_loss = 0.482099829523116
04/23 04:53:15 PM   cls_loss = 0.0
04/23 04:53:15 PM   global_step = 4599
04/23 04:53:15 PM   loss = 1.3383729460965708
04/23 04:53:15 PM   rep_loss = 0.8562731164568117
04/23 04:53:15 PM ***** Save model *****
04/23 04:53:23 PM ***** Running evaluation *****
04/23 04:53:23 PM   Epoch = 0 iter 4649 step
04/23 04:53:23 PM   Num examples = 1043
04/23 04:53:23 PM   Batch size = 32
04/23 04:53:23 PM ***** Eval results *****
04/23 04:53:23 PM   att_loss = 0.48169943381955893
04/23 04:53:23 PM   cls_loss = 0.0
04/23 04:53:23 PM   global_step = 4649
04/23 04:53:23 PM   loss = 1.336973291285501
04/23 04:53:23 PM   rep_loss = 0.8552738572736278
04/23 04:53:23 PM ***** Save model *****
04/23 04:53:31 PM ***** Running evaluation *****
04/23 04:53:31 PM   Epoch = 0 iter 4699 step
04/23 04:53:31 PM   Num examples = 1043
04/23 04:53:31 PM   Batch size = 32
04/23 04:53:31 PM ***** Eval results *****
04/23 04:53:31 PM   att_loss = 0.48133337320127645
04/23 04:53:31 PM   cls_loss = 0.0
04/23 04:53:31 PM   global_step = 4699
04/23 04:53:31 PM   loss = 1.3356302720126916
04/23 04:53:31 PM   rep_loss = 0.8542968986338315
04/23 04:53:31 PM ***** Save model *****
04/23 04:53:39 PM ***** Running evaluation *****
04/23 04:53:39 PM   Epoch = 0 iter 4749 step
04/23 04:53:39 PM   Num examples = 1043
04/23 04:53:39 PM   Batch size = 32
04/23 04:53:39 PM ***** Eval results *****
04/23 04:53:39 PM   att_loss = 0.4809528968602287
04/23 04:53:39 PM   cls_loss = 0.0
04/23 04:53:39 PM   global_step = 4749
04/23 04:53:39 PM   loss = 1.334334157019772
04/23 04:53:39 PM   rep_loss = 0.85338125992735
04/23 04:53:39 PM ***** Save model *****
04/23 04:53:47 PM ***** Running evaluation *****
04/23 04:53:47 PM   Epoch = 0 iter 4799 step
04/23 04:53:47 PM   Num examples = 1043
04/23 04:53:47 PM   Batch size = 32
04/23 04:53:47 PM ***** Eval results *****
04/23 04:53:47 PM   att_loss = 0.48061037128804796
04/23 04:53:47 PM   cls_loss = 0.0
04/23 04:53:47 PM   global_step = 4799
04/23 04:53:47 PM   loss = 1.3330712220549061
04/23 04:53:47 PM   rep_loss = 0.8524608505246639
04/23 04:53:47 PM ***** Save model *****
04/23 04:53:55 PM ***** Running evaluation *****
04/23 04:53:55 PM   Epoch = 0 iter 4849 step
04/23 04:53:55 PM   Num examples = 1043
04/23 04:53:55 PM   Batch size = 32
04/23 04:53:55 PM ***** Eval results *****
04/23 04:53:55 PM   att_loss = 0.4802100488108983
04/23 04:53:55 PM   cls_loss = 0.0
04/23 04:53:55 PM   global_step = 4849
04/23 04:53:55 PM   loss = 1.3317379853385678
04/23 04:53:55 PM   rep_loss = 0.8515279363125569
04/23 04:53:55 PM ***** Save model *****
04/23 04:54:04 PM ***** Running evaluation *****
04/23 04:54:04 PM   Epoch = 0 iter 4899 step
04/23 04:54:04 PM   Num examples = 1043
04/23 04:54:04 PM   Batch size = 32
04/23 04:54:04 PM ***** Eval results *****
04/23 04:54:04 PM   att_loss = 0.47997553005683763
04/23 04:54:04 PM   cls_loss = 0.0
04/23 04:54:04 PM   global_step = 4899
04/23 04:54:04 PM   loss = 1.330612221404615
04/23 04:54:04 PM   rep_loss = 0.8506366911409436
04/23 04:54:04 PM ***** Save model *****
04/23 04:54:12 PM ***** Running evaluation *****
04/23 04:54:12 PM   Epoch = 0 iter 4949 step
04/23 04:54:12 PM   Num examples = 1043
04/23 04:54:12 PM   Batch size = 32
04/23 04:54:12 PM ***** Eval results *****
04/23 04:54:12 PM   att_loss = 0.4796306488549596
04/23 04:54:12 PM   cls_loss = 0.0
04/23 04:54:12 PM   global_step = 4949
04/23 04:54:12 PM   loss = 1.3293610800394122
04/23 04:54:12 PM   rep_loss = 0.8497304310459493
04/23 04:54:12 PM ***** Save model *****
04/23 04:54:20 PM ***** Running evaluation *****
04/23 04:54:20 PM   Epoch = 0 iter 4999 step
04/23 04:54:20 PM   Num examples = 1043
04/23 04:54:20 PM   Batch size = 32
04/23 04:54:20 PM ***** Eval results *****
04/23 04:54:20 PM   att_loss = 0.4793883522144912
04/23 04:54:20 PM   cls_loss = 0.0
04/23 04:54:20 PM   global_step = 4999
04/23 04:54:20 PM   loss = 1.328288744678257
04/23 04:54:20 PM   rep_loss = 0.8489003921895295
04/23 04:54:20 PM ***** Save model *****
04/23 04:54:28 PM ***** Running evaluation *****
04/23 04:54:28 PM   Epoch = 0 iter 5049 step
04/23 04:54:28 PM   Num examples = 1043
04/23 04:54:28 PM   Batch size = 32
04/23 04:54:28 PM ***** Eval results *****
04/23 04:54:28 PM   att_loss = 0.479039116386471
04/23 04:54:28 PM   cls_loss = 0.0
04/23 04:54:28 PM   global_step = 5049
04/23 04:54:28 PM   loss = 1.3270639059779241
04/23 04:54:28 PM   rep_loss = 0.8480247892609065
04/23 04:54:28 PM ***** Save model *****
04/23 04:54:36 PM ***** Running evaluation *****
04/23 04:54:36 PM   Epoch = 0 iter 5099 step
04/23 04:54:36 PM   Num examples = 1043
04/23 04:54:36 PM   Batch size = 32
04/23 04:54:36 PM ***** Eval results *****
04/23 04:54:36 PM   att_loss = 0.47889622587693814
04/23 04:54:36 PM   cls_loss = 0.0
04/23 04:54:36 PM   global_step = 5099
04/23 04:54:36 PM   loss = 1.3261280744584034
04/23 04:54:36 PM   rep_loss = 0.8472318481898677
04/23 04:54:36 PM ***** Save model *****
04/23 04:54:44 PM ***** Running evaluation *****
04/23 04:54:44 PM   Epoch = 0 iter 5149 step
04/23 04:54:44 PM   Num examples = 1043
04/23 04:54:44 PM   Batch size = 32
04/23 04:54:44 PM ***** Eval results *****
04/23 04:54:44 PM   att_loss = 0.4786240338792984
04/23 04:54:44 PM   cls_loss = 0.0
04/23 04:54:44 PM   global_step = 5149
04/23 04:54:44 PM   loss = 1.3250184930350206
04/23 04:54:44 PM   rep_loss = 0.8463944588315953
04/23 04:54:44 PM ***** Save model *****
04/23 04:54:52 PM ***** Running evaluation *****
04/23 04:54:52 PM   Epoch = 0 iter 5199 step
04/23 04:54:52 PM   Num examples = 1043
04/23 04:54:52 PM   Batch size = 32
04/23 04:54:52 PM ***** Eval results *****
04/23 04:54:52 PM   att_loss = 0.4783055792922904
04/23 04:54:52 PM   cls_loss = 0.0
04/23 04:54:52 PM   global_step = 5199
04/23 04:54:52 PM   loss = 1.3238483829254324
04/23 04:54:52 PM   rep_loss = 0.8455428032834705
04/23 04:54:52 PM ***** Save model *****
04/23 04:55:00 PM ***** Running evaluation *****
04/23 04:55:00 PM   Epoch = 0 iter 5249 step
04/23 04:55:00 PM   Num examples = 1043
04/23 04:55:00 PM   Batch size = 32
04/23 04:55:00 PM ***** Eval results *****
04/23 04:55:00 PM   att_loss = 0.47808343533743763
04/23 04:55:00 PM   cls_loss = 0.0
04/23 04:55:00 PM   global_step = 5249
04/23 04:55:00 PM   loss = 1.3228546602427562
04/23 04:55:00 PM   rep_loss = 0.844771224638466
04/23 04:55:00 PM ***** Save model *****
04/23 04:55:09 PM ***** Running evaluation *****
04/23 04:55:09 PM   Epoch = 0 iter 5299 step
04/23 04:55:09 PM   Num examples = 1043
04/23 04:55:09 PM   Batch size = 32
04/23 04:55:09 PM ***** Eval results *****
04/23 04:55:09 PM   att_loss = 0.47778868154998905
04/23 04:55:09 PM   cls_loss = 0.0
04/23 04:55:09 PM   global_step = 5299
04/23 04:55:09 PM   loss = 1.3217562899811806
04/23 04:55:09 PM   rep_loss = 0.8439676081668568
04/23 04:55:09 PM ***** Save model *****
04/23 04:55:17 PM ***** Running evaluation *****
04/23 04:55:17 PM   Epoch = 0 iter 5349 step
04/23 04:55:17 PM   Num examples = 1043
04/23 04:55:17 PM   Batch size = 32
04/23 04:55:17 PM ***** Eval results *****
04/23 04:55:17 PM   att_loss = 0.4774774351806858
04/23 04:55:17 PM   cls_loss = 0.0
04/23 04:55:17 PM   global_step = 5349
04/23 04:55:17 PM   loss = 1.320648963372492
04/23 04:55:17 PM   rep_loss = 0.8431715280636601
04/23 04:55:17 PM ***** Save model *****
04/23 04:55:25 PM ***** Running evaluation *****
04/23 04:55:25 PM   Epoch = 0 iter 5399 step
04/23 04:55:25 PM   Num examples = 1043
04/23 04:55:25 PM   Batch size = 32
04/23 04:55:25 PM ***** Eval results *****
04/23 04:55:25 PM   att_loss = 0.47717393551364745
04/23 04:55:25 PM   cls_loss = 0.0
04/23 04:55:25 PM   global_step = 5399
04/23 04:55:25 PM   loss = 1.3195434166206477
04/23 04:55:25 PM   rep_loss = 0.8423694809027614
04/23 04:55:25 PM ***** Save model *****
04/23 04:55:33 PM ***** Running evaluation *****
04/23 04:55:33 PM   Epoch = 0 iter 5449 step
04/23 04:55:33 PM   Num examples = 1043
04/23 04:55:33 PM   Batch size = 32
04/23 04:55:33 PM ***** Eval results *****
04/23 04:55:33 PM   att_loss = 0.4769345274713635
04/23 04:55:33 PM   cls_loss = 0.0
04/23 04:55:33 PM   global_step = 5449
04/23 04:55:33 PM   loss = 1.3185334357674525
04/23 04:55:33 PM   rep_loss = 0.8415989080991936
04/23 04:55:33 PM ***** Save model *****
04/23 04:55:41 PM ***** Running evaluation *****
04/23 04:55:41 PM   Epoch = 0 iter 5499 step
04/23 04:55:41 PM   Num examples = 1043
04/23 04:55:41 PM   Batch size = 32
04/23 04:55:41 PM ***** Eval results *****
04/23 04:55:41 PM   att_loss = 0.47659600814552083
04/23 04:55:41 PM   cls_loss = 0.0
04/23 04:55:41 PM   global_step = 5499
04/23 04:55:41 PM   loss = 1.317413385639756
04/23 04:55:41 PM   rep_loss = 0.8408173773153887
04/23 04:55:41 PM ***** Save model *****
04/23 04:55:49 PM ***** Running evaluation *****
04/23 04:55:49 PM   Epoch = 0 iter 5549 step
04/23 04:55:49 PM   Num examples = 1043
04/23 04:55:49 PM   Batch size = 32
04/23 04:55:49 PM ***** Eval results *****
04/23 04:55:49 PM   att_loss = 0.47633498362494625
04/23 04:55:49 PM   cls_loss = 0.0
04/23 04:55:49 PM   global_step = 5549
04/23 04:55:49 PM   loss = 1.3164030047102346
04/23 04:55:49 PM   rep_loss = 0.8400680208274922
04/23 04:55:49 PM ***** Save model *****
04/23 04:55:57 PM ***** Running evaluation *****
04/23 04:55:57 PM   Epoch = 0 iter 5599 step
04/23 04:55:57 PM   Num examples = 1043
04/23 04:55:57 PM   Batch size = 32
04/23 04:55:57 PM ***** Eval results *****
04/23 04:55:57 PM   att_loss = 0.47594495758262567
04/23 04:55:57 PM   cls_loss = 0.0
04/23 04:55:57 PM   global_step = 5599
04/23 04:55:57 PM   loss = 1.3152236980207266
04/23 04:55:57 PM   rep_loss = 0.8392787401666384
04/23 04:55:57 PM ***** Save model *****
04/23 04:56:05 PM ***** Running evaluation *****
04/23 04:56:05 PM   Epoch = 0 iter 5649 step
04/23 04:56:05 PM   Num examples = 1043
04/23 04:56:05 PM   Batch size = 32
04/23 04:56:05 PM ***** Eval results *****
04/23 04:56:05 PM   att_loss = 0.4756852989704087
04/23 04:56:05 PM   cls_loss = 0.0
04/23 04:56:05 PM   global_step = 5649
04/23 04:56:05 PM   loss = 1.3141843178648298
04/23 04:56:05 PM   rep_loss = 0.8384990186939453
04/23 04:56:05 PM ***** Save model *****
04/23 04:56:14 PM ***** Running evaluation *****
04/23 04:56:14 PM   Epoch = 0 iter 5699 step
04/23 04:56:14 PM   Num examples = 1043
04/23 04:56:14 PM   Batch size = 32
04/23 04:56:14 PM ***** Eval results *****
04/23 04:56:14 PM   att_loss = 0.4754779054723637
04/23 04:56:14 PM   cls_loss = 0.0
04/23 04:56:14 PM   global_step = 5699
04/23 04:56:14 PM   loss = 1.3132372156823595
04/23 04:56:14 PM   rep_loss = 0.8377593099955907
04/23 04:56:14 PM ***** Save model *****
04/23 04:56:22 PM ***** Running evaluation *****
04/23 04:56:22 PM   Epoch = 0 iter 5749 step
04/23 04:56:22 PM   Num examples = 1043
04/23 04:56:22 PM   Batch size = 32
04/23 04:56:22 PM ***** Eval results *****
04/23 04:56:22 PM   att_loss = 0.4751635008707194
04/23 04:56:22 PM   cls_loss = 0.0
04/23 04:56:22 PM   global_step = 5749
04/23 04:56:22 PM   loss = 1.3121599218994249
04/23 04:56:22 PM   rep_loss = 0.8369964208680042
04/23 04:56:22 PM ***** Save model *****
04/23 04:56:30 PM ***** Running evaluation *****
04/23 04:56:30 PM   Epoch = 0 iter 5799 step
04/23 04:56:30 PM   Num examples = 1043
04/23 04:56:30 PM   Batch size = 32
04/23 04:56:30 PM ***** Eval results *****
04/23 04:56:30 PM   att_loss = 0.4749089529553782
04/23 04:56:30 PM   cls_loss = 0.0
04/23 04:56:30 PM   global_step = 5799
04/23 04:56:30 PM   loss = 1.31120769419245
04/23 04:56:30 PM   rep_loss = 0.8362987410366423
04/23 04:56:30 PM ***** Save model *****
04/23 04:56:38 PM ***** Running evaluation *****
04/23 04:56:38 PM   Epoch = 0 iter 5849 step
04/23 04:56:38 PM   Num examples = 1043
04/23 04:56:38 PM   Batch size = 32
04/23 04:56:38 PM ***** Eval results *****
04/23 04:56:38 PM   att_loss = 0.4746722336161094
04/23 04:56:38 PM   cls_loss = 0.0
04/23 04:56:38 PM   global_step = 5849
04/23 04:56:38 PM   loss = 1.310286867086613
04/23 04:56:38 PM   rep_loss = 0.8356146332565016
04/23 04:56:38 PM ***** Save model *****
04/23 04:56:46 PM ***** Running evaluation *****
04/23 04:56:46 PM   Epoch = 0 iter 5899 step
04/23 04:56:46 PM   Num examples = 1043
04/23 04:56:46 PM   Batch size = 32
04/23 04:56:46 PM ***** Eval results *****
04/23 04:56:46 PM   att_loss = 0.4744481975485822
04/23 04:56:46 PM   cls_loss = 0.0
04/23 04:56:46 PM   global_step = 5899
04/23 04:56:46 PM   loss = 1.3093544735223848
04/23 04:56:46 PM   rep_loss = 0.8349062758070833
04/23 04:56:46 PM ***** Save model *****
04/23 04:56:54 PM ***** Running evaluation *****
04/23 04:56:54 PM   Epoch = 0 iter 5949 step
04/23 04:56:54 PM   Num examples = 1043
04/23 04:56:54 PM   Batch size = 32
04/23 04:56:54 PM ***** Eval results *****
04/23 04:56:54 PM   att_loss = 0.47425247611849625
04/23 04:56:54 PM   cls_loss = 0.0
04/23 04:56:54 PM   global_step = 5949
04/23 04:56:54 PM   loss = 1.308444273874607
04/23 04:56:54 PM   rep_loss = 0.8341917976609277
04/23 04:56:54 PM ***** Save model *****
04/23 04:57:02 PM ***** Running evaluation *****
04/23 04:57:02 PM   Epoch = 0 iter 5999 step
04/23 04:57:02 PM   Num examples = 1043
04/23 04:57:02 PM   Batch size = 32
04/23 04:57:02 PM ***** Eval results *****
04/23 04:57:02 PM   att_loss = 0.47401592686367466
04/23 04:57:02 PM   cls_loss = 0.0
04/23 04:57:02 PM   global_step = 5999
04/23 04:57:02 PM   loss = 1.3075240475671612
04/23 04:57:02 PM   rep_loss = 0.8335081206637435
04/23 04:57:02 PM ***** Save model *****
04/23 04:57:10 PM ***** Running evaluation *****
04/23 04:57:10 PM   Epoch = 0 iter 6049 step
04/23 04:57:10 PM   Num examples = 1043
04/23 04:57:10 PM   Batch size = 32
04/23 04:57:10 PM ***** Eval results *****
04/23 04:57:10 PM   att_loss = 0.4738096667973734
04/23 04:57:10 PM   cls_loss = 0.0
04/23 04:57:10 PM   global_step = 6049
04/23 04:57:10 PM   loss = 1.3066399045218355
04/23 04:57:10 PM   rep_loss = 0.8328302377096817
04/23 04:57:10 PM ***** Save model *****
04/23 04:57:18 PM ***** Running evaluation *****
04/23 04:57:18 PM   Epoch = 0 iter 6099 step
04/23 04:57:18 PM   Num examples = 1043
04/23 04:57:18 PM   Batch size = 32
04/23 04:57:18 PM ***** Eval results *****
04/23 04:57:18 PM   att_loss = 0.47353892227453687
04/23 04:57:18 PM   cls_loss = 0.0
04/23 04:57:18 PM   global_step = 6099
04/23 04:57:18 PM   loss = 1.3056797072582116
04/23 04:57:18 PM   rep_loss = 0.8321407849836748
04/23 04:57:18 PM ***** Save model *****
04/23 04:57:27 PM ***** Running evaluation *****
04/23 04:57:27 PM   Epoch = 0 iter 6149 step
04/23 04:57:27 PM   Num examples = 1043
04/23 04:57:27 PM   Batch size = 32
04/23 04:57:27 PM ***** Eval results *****
04/23 04:57:27 PM   att_loss = 0.47325644155385377
04/23 04:57:27 PM   cls_loss = 0.0
04/23 04:57:27 PM   global_step = 6149
04/23 04:57:27 PM   loss = 1.3047025353176882
04/23 04:57:27 PM   rep_loss = 0.8314460937832212
04/23 04:57:27 PM ***** Save model *****
04/23 04:57:35 PM ***** Running evaluation *****
04/23 04:57:35 PM   Epoch = 0 iter 6199 step
04/23 04:57:35 PM   Num examples = 1043
04/23 04:57:35 PM   Batch size = 32
04/23 04:57:35 PM ***** Eval results *****
04/23 04:57:35 PM   att_loss = 0.4731241187552787
04/23 04:57:35 PM   cls_loss = 0.0
04/23 04:57:35 PM   global_step = 6199
04/23 04:57:35 PM   loss = 1.3039326301254097
04/23 04:57:35 PM   rep_loss = 0.8308085113364778
04/23 04:57:35 PM ***** Save model *****
04/23 04:57:43 PM ***** Running evaluation *****
04/23 04:57:43 PM   Epoch = 0 iter 6249 step
04/23 04:57:43 PM   Num examples = 1043
04/23 04:57:43 PM   Batch size = 32
04/23 04:57:43 PM ***** Eval results *****
04/23 04:57:43 PM   att_loss = 0.4728736435581081
04/23 04:57:43 PM   cls_loss = 0.0
04/23 04:57:43 PM   global_step = 6249
04/23 04:57:43 PM   loss = 1.3029947711059733
04/23 04:57:43 PM   rep_loss = 0.8301211275526343
04/23 04:57:43 PM ***** Save model *****
04/23 04:57:51 PM ***** Running evaluation *****
04/23 04:57:51 PM   Epoch = 0 iter 6299 step
04/23 04:57:51 PM   Num examples = 1043
04/23 04:57:51 PM   Batch size = 32
04/23 04:57:51 PM ***** Eval results *****
04/23 04:57:51 PM   att_loss = 0.4726506357089662
04/23 04:57:51 PM   cls_loss = 0.0
04/23 04:57:51 PM   global_step = 6299
04/23 04:57:51 PM   loss = 1.3021221041660458
04/23 04:57:51 PM   rep_loss = 0.8294714684901985
04/23 04:57:51 PM ***** Save model *****
04/23 04:57:59 PM ***** Running evaluation *****
04/23 04:57:59 PM   Epoch = 0 iter 6349 step
04/23 04:57:59 PM   Num examples = 1043
04/23 04:57:59 PM   Batch size = 32
04/23 04:57:59 PM ***** Eval results *****
04/23 04:57:59 PM   att_loss = 0.47250366281817174
04/23 04:57:59 PM   cls_loss = 0.0
04/23 04:57:59 PM   global_step = 6349
04/23 04:57:59 PM   loss = 1.3013324311519725
04/23 04:57:59 PM   rep_loss = 0.8288287683572707
04/23 04:57:59 PM ***** Save model *****
04/23 04:58:07 PM ***** Running evaluation *****
04/23 04:58:07 PM   Epoch = 0 iter 6399 step
04/23 04:58:07 PM   Num examples = 1043
04/23 04:58:07 PM   Batch size = 32
04/23 04:58:07 PM ***** Eval results *****
04/23 04:58:07 PM   att_loss = 0.47220550424643914
04/23 04:58:07 PM   cls_loss = 0.0
04/23 04:58:07 PM   global_step = 6399
04/23 04:58:07 PM   loss = 1.3003907862222275
04/23 04:58:07 PM   rep_loss = 0.8281852820642778
04/23 04:58:07 PM ***** Save model *****
04/23 04:58:15 PM ***** Running evaluation *****
04/23 04:58:15 PM   Epoch = 0 iter 6449 step
04/23 04:58:15 PM   Num examples = 1043
04/23 04:58:15 PM   Batch size = 32
04/23 04:58:15 PM ***** Eval results *****
04/23 04:58:15 PM   att_loss = 0.4719424633291049
04/23 04:58:15 PM   cls_loss = 0.0
04/23 04:58:15 PM   global_step = 6449
04/23 04:58:15 PM   loss = 1.2994740775877753
04/23 04:58:15 PM   rep_loss = 0.8275316143834438
04/23 04:58:15 PM ***** Save model *****
04/23 04:58:23 PM ***** Running evaluation *****
04/23 04:58:23 PM   Epoch = 0 iter 6499 step
04/23 04:58:23 PM   Num examples = 1043
04/23 04:58:23 PM   Batch size = 32
04/23 04:58:23 PM ***** Eval results *****
04/23 04:58:23 PM   att_loss = 0.4717375522054953
04/23 04:58:23 PM   cls_loss = 0.0
04/23 04:58:23 PM   global_step = 6499
04/23 04:58:23 PM   loss = 1.2986522798704025
04/23 04:58:23 PM   rep_loss = 0.826914727797892
04/23 04:58:23 PM ***** Save model *****
04/23 04:58:32 PM ***** Running evaluation *****
04/23 04:58:32 PM   Epoch = 0 iter 6549 step
04/23 04:58:32 PM   Num examples = 1043
04/23 04:58:32 PM   Batch size = 32
04/23 04:58:32 PM ***** Eval results *****
04/23 04:58:32 PM   att_loss = 0.47153760503495734
04/23 04:58:32 PM   cls_loss = 0.0
04/23 04:58:32 PM   global_step = 6549
04/23 04:58:32 PM   loss = 1.297837218085688
04/23 04:58:32 PM   rep_loss = 0.8262996131872509
04/23 04:58:32 PM ***** Save model *****
04/23 04:58:40 PM ***** Running evaluation *****
04/23 04:58:40 PM   Epoch = 0 iter 6599 step
04/23 04:58:40 PM   Num examples = 1043
04/23 04:58:40 PM   Batch size = 32
04/23 04:58:40 PM ***** Eval results *****
04/23 04:58:40 PM   att_loss = 0.4713355580014268
04/23 04:58:40 PM   cls_loss = 0.0
04/23 04:58:40 PM   global_step = 6599
04/23 04:58:40 PM   loss = 1.2970561383438572
04/23 04:58:40 PM   rep_loss = 0.8257205805140456
04/23 04:58:40 PM ***** Save model *****
04/23 04:58:48 PM ***** Running evaluation *****
04/23 04:58:48 PM   Epoch = 1 iter 6649 step
04/23 04:58:48 PM   Num examples = 1043
04/23 04:58:48 PM   Batch size = 32
04/23 04:58:48 PM ***** Eval results *****
04/23 04:58:48 PM   att_loss = 0.44199524181229727
04/23 04:58:48 PM   cls_loss = 0.0
04/23 04:58:48 PM   global_step = 6649
04/23 04:58:48 PM   loss = 1.185224453608195
04/23 04:58:48 PM   rep_loss = 0.7432292188916888
04/23 04:58:48 PM ***** Save model *****
04/23 04:58:56 PM ***** Running evaluation *****
04/23 04:58:56 PM   Epoch = 1 iter 6699 step
04/23 04:58:56 PM   Num examples = 1043
04/23 04:58:56 PM   Batch size = 32
04/23 04:58:56 PM ***** Eval results *****
04/23 04:58:56 PM   att_loss = 0.44077042668638095
04/23 04:58:56 PM   cls_loss = 0.0
04/23 04:58:56 PM   global_step = 6699
04/23 04:58:56 PM   loss = 1.1832650295445617
04/23 04:58:56 PM   rep_loss = 0.7424945974014174
04/23 04:58:56 PM ***** Save model *****
04/23 04:59:04 PM ***** Running evaluation *****
04/23 04:59:04 PM   Epoch = 1 iter 6749 step
04/23 04:59:04 PM   Num examples = 1043
04/23 04:59:04 PM   Batch size = 32
04/23 04:59:04 PM ***** Eval results *****
04/23 04:59:04 PM   att_loss = 0.44273588824863275
04/23 04:59:04 PM   cls_loss = 0.0
04/23 04:59:04 PM   global_step = 6749
04/23 04:59:04 PM   loss = 1.184340170592316
04/23 04:59:04 PM   rep_loss = 0.7416042803732816
04/23 04:59:04 PM ***** Save model *****
04/23 04:59:12 PM ***** Running evaluation *****
04/23 04:59:12 PM   Epoch = 1 iter 6799 step
04/23 04:59:12 PM   Num examples = 1043
04/23 04:59:12 PM   Batch size = 32
04/23 04:59:12 PM ***** Eval results *****
04/23 04:59:12 PM   att_loss = 0.44078633712049115
04/23 04:59:12 PM   cls_loss = 0.0
04/23 04:59:12 PM   global_step = 6799
04/23 04:59:12 PM   loss = 1.1817631763324403
04/23 04:59:12 PM   rep_loss = 0.740976837991971
04/23 04:59:12 PM ***** Save model *****
04/23 04:59:20 PM ***** Running evaluation *****
04/23 04:59:20 PM   Epoch = 1 iter 6849 step
04/23 04:59:20 PM   Num examples = 1043
04/23 04:59:20 PM   Batch size = 32
04/23 04:59:20 PM ***** Eval results *****
04/23 04:59:20 PM   att_loss = 0.4398885984226589
04/23 04:59:20 PM   cls_loss = 0.0
04/23 04:59:20 PM   global_step = 6849
04/23 04:59:20 PM   loss = 1.179893905760476
04/23 04:59:20 PM   rep_loss = 0.7400053078772256
04/23 04:59:20 PM ***** Save model *****
04/23 04:59:28 PM ***** Running evaluation *****
04/23 04:59:28 PM   Epoch = 1 iter 6899 step
04/23 04:59:28 PM   Num examples = 1043
04/23 04:59:28 PM   Batch size = 32
04/23 04:59:28 PM ***** Eval results *****
04/23 04:59:28 PM   att_loss = 0.4393619132877716
04/23 04:59:28 PM   cls_loss = 0.0
04/23 04:59:28 PM   global_step = 6899
04/23 04:59:28 PM   loss = 1.1786376154290794
04/23 04:59:28 PM   rep_loss = 0.7392757026911662
04/23 04:59:28 PM ***** Save model *****
04/23 04:59:36 PM ***** Running evaluation *****
04/23 04:59:36 PM   Epoch = 1 iter 6949 step
04/23 04:59:36 PM   Num examples = 1043
04/23 04:59:36 PM   Batch size = 32
04/23 04:59:36 PM ***** Eval results *****
04/23 04:59:36 PM   att_loss = 0.4393713307157855
04/23 04:59:36 PM   cls_loss = 0.0
04/23 04:59:36 PM   global_step = 6949
04/23 04:59:36 PM   loss = 1.1791217367968456
04/23 04:59:36 PM   rep_loss = 0.7397504055240073
04/23 04:59:36 PM ***** Save model *****
04/23 04:59:45 PM ***** Running evaluation *****
04/23 04:59:45 PM   Epoch = 1 iter 6999 step
04/23 04:59:45 PM   Num examples = 1043
04/23 04:59:45 PM   Batch size = 32
04/23 04:59:45 PM ***** Eval results *****
04/23 04:59:45 PM   att_loss = 0.4390813674566881
04/23 04:59:45 PM   cls_loss = 0.0
04/23 04:59:45 PM   global_step = 6999
04/23 04:59:45 PM   loss = 1.1786047808243578
04/23 04:59:45 PM   rep_loss = 0.7395234143316264
04/23 04:59:45 PM ***** Save model *****
04/23 04:59:53 PM ***** Running evaluation *****
04/23 04:59:53 PM   Epoch = 1 iter 7049 step
04/23 04:59:53 PM   Num examples = 1043
04/23 04:59:53 PM   Batch size = 32
04/23 04:59:53 PM ***** Eval results *****
04/23 04:59:53 PM   att_loss = 0.4392584847582774
04/23 04:59:53 PM   cls_loss = 0.0
04/23 04:59:53 PM   global_step = 7049
04/23 04:59:53 PM   loss = 1.1785496343059947
04/23 04:59:53 PM   rep_loss = 0.7392911517421876
04/23 04:59:53 PM ***** Save model *****
04/23 05:00:01 PM ***** Running evaluation *****
04/23 05:00:01 PM   Epoch = 1 iter 7099 step
04/23 05:00:01 PM   Num examples = 1043
04/23 05:00:01 PM   Batch size = 32
04/23 05:00:01 PM ***** Eval results *****
04/23 05:00:01 PM   att_loss = 0.4395239203219201
04/23 05:00:01 PM   cls_loss = 0.0
04/23 05:00:01 PM   global_step = 7099
04/23 05:00:01 PM   loss = 1.1788069781730635
04/23 05:00:01 PM   rep_loss = 0.7392830599392043
04/23 05:00:01 PM ***** Save model *****
04/23 05:00:09 PM ***** Running evaluation *****
04/23 05:00:09 PM   Epoch = 1 iter 7149 step
04/23 05:00:09 PM   Num examples = 1043
04/23 05:00:09 PM   Batch size = 32
04/23 05:00:09 PM ***** Eval results *****
04/23 05:00:09 PM   att_loss = 0.43849039638339904
04/23 05:00:09 PM   cls_loss = 0.0
04/23 05:00:09 PM   global_step = 7149
04/23 05:00:09 PM   loss = 1.1776734137489333
04/23 05:00:09 PM   rep_loss = 0.7391830182807688
04/23 05:00:09 PM ***** Save model *****
04/23 05:00:17 PM ***** Running evaluation *****
04/23 05:00:17 PM   Epoch = 1 iter 7199 step
04/23 05:00:17 PM   Num examples = 1043
04/23 05:00:17 PM   Batch size = 32
04/23 05:00:17 PM ***** Eval results *****
04/23 05:00:17 PM   att_loss = 0.4383633643023396
04/23 05:00:17 PM   cls_loss = 0.0
04/23 05:00:17 PM   global_step = 7199
04/23 05:00:17 PM   loss = 1.177660038508801
04/23 05:00:17 PM   rep_loss = 0.7392966753547121
04/23 05:00:17 PM ***** Save model *****
04/23 05:00:25 PM ***** Running evaluation *****
04/23 05:00:25 PM   Epoch = 1 iter 7249 step
04/23 05:00:25 PM   Num examples = 1043
04/23 05:00:25 PM   Batch size = 32
04/23 05:00:25 PM ***** Eval results *****
04/23 05:00:25 PM   att_loss = 0.43822267857918606
04/23 05:00:25 PM   cls_loss = 0.0
04/23 05:00:25 PM   global_step = 7249
04/23 05:00:25 PM   loss = 1.1775046137795933
04/23 05:00:25 PM   rep_loss = 0.739281936256206
04/23 05:00:25 PM ***** Save model *****
04/23 05:00:33 PM ***** Running evaluation *****
04/23 05:00:33 PM   Epoch = 1 iter 7299 step
04/23 05:00:33 PM   Num examples = 1043
04/23 05:00:33 PM   Batch size = 32
04/23 05:00:33 PM ***** Eval results *****
04/23 05:00:33 PM   att_loss = 0.43858529687283115
04/23 05:00:33 PM   cls_loss = 0.0
04/23 05:00:33 PM   global_step = 7299
04/23 05:00:33 PM   loss = 1.1776847350792807
04/23 05:00:33 PM   rep_loss = 0.7390994388726714
04/23 05:00:33 PM ***** Save model *****
04/23 05:00:41 PM ***** Running evaluation *****
04/23 05:00:41 PM   Epoch = 1 iter 7349 step
04/23 05:00:41 PM   Num examples = 1043
04/23 05:00:41 PM   Batch size = 32
04/23 05:00:41 PM ***** Eval results *****
04/23 05:00:41 PM   att_loss = 0.4387696643312166
04/23 05:00:41 PM   cls_loss = 0.0
04/23 05:00:41 PM   global_step = 7349
04/23 05:00:41 PM   loss = 1.1778234340942848
04/23 05:00:41 PM   rep_loss = 0.7390537703417541
04/23 05:00:41 PM ***** Save model *****
04/23 05:00:50 PM ***** Running evaluation *****
04/23 05:00:50 PM   Epoch = 1 iter 7399 step
04/23 05:00:50 PM   Num examples = 1043
04/23 05:00:50 PM   Batch size = 32
04/23 05:00:50 PM ***** Eval results *****
04/23 05:00:50 PM   att_loss = 0.4391188038616947
04/23 05:00:50 PM   cls_loss = 0.0
04/23 05:00:50 PM   global_step = 7399
04/23 05:00:50 PM   loss = 1.1780033491928754
04/23 05:00:50 PM   rep_loss = 0.7388845464134959
04/23 05:00:50 PM ***** Save model *****
04/23 05:00:58 PM ***** Running evaluation *****
04/23 05:00:58 PM   Epoch = 1 iter 7449 step
04/23 05:00:58 PM   Num examples = 1043
04/23 05:00:58 PM   Batch size = 32
04/23 05:00:58 PM ***** Eval results *****
04/23 05:00:58 PM   att_loss = 0.4395651565399588
04/23 05:00:58 PM   cls_loss = 0.0
04/23 05:00:58 PM   global_step = 7449
04/23 05:00:58 PM   loss = 1.1783615992507748
04/23 05:00:58 PM   rep_loss = 0.7387964435094166
04/23 05:00:58 PM ***** Save model *****
04/23 05:01:06 PM ***** Running evaluation *****
04/23 05:01:06 PM   Epoch = 1 iter 7499 step
04/23 05:01:06 PM   Num examples = 1043
04/23 05:01:06 PM   Batch size = 32
04/23 05:01:06 PM ***** Eval results *****
04/23 05:01:06 PM   att_loss = 0.4398092146445361
04/23 05:01:06 PM   cls_loss = 0.0
04/23 05:01:06 PM   global_step = 7499
04/23 05:01:06 PM   loss = 1.1783921450342294
04/23 05:01:06 PM   rep_loss = 0.7385829310740176
04/23 05:01:06 PM ***** Save model *****
04/23 05:01:14 PM ***** Running evaluation *****
04/23 05:01:14 PM   Epoch = 1 iter 7549 step
04/23 05:01:14 PM   Num examples = 1043
04/23 05:01:14 PM   Batch size = 32
04/23 05:01:14 PM ***** Eval results *****
04/23 05:01:14 PM   att_loss = 0.440153124601652
04/23 05:01:14 PM   cls_loss = 0.0
04/23 05:01:14 PM   global_step = 7549
04/23 05:01:14 PM   loss = 1.1787527135606697
04/23 05:01:14 PM   rep_loss = 0.738599590253364
04/23 05:01:14 PM ***** Save model *****
04/23 05:01:22 PM ***** Running evaluation *****
04/23 05:01:22 PM   Epoch = 1 iter 7599 step
04/23 05:01:22 PM   Num examples = 1043
04/23 05:01:22 PM   Batch size = 32
04/23 05:01:22 PM ***** Eval results *****
04/23 05:01:22 PM   att_loss = 0.4400174273091659
04/23 05:01:22 PM   cls_loss = 0.0
04/23 05:01:22 PM   global_step = 7599
04/23 05:01:22 PM   loss = 1.1784585951285553
04/23 05:01:22 PM   rep_loss = 0.7384411691391628
04/23 05:01:22 PM ***** Save model *****
04/23 05:01:30 PM ***** Running evaluation *****
04/23 05:01:30 PM   Epoch = 1 iter 7649 step
04/23 05:01:30 PM   Num examples = 1043
04/23 05:01:30 PM   Batch size = 32
04/23 05:01:30 PM ***** Eval results *****
04/23 05:01:30 PM   att_loss = 0.4396226669385314
04/23 05:01:30 PM   cls_loss = 0.0
04/23 05:01:30 PM   global_step = 7649
04/23 05:01:30 PM   loss = 1.1777347450041513
04/23 05:01:30 PM   rep_loss = 0.7381120793499513
04/23 05:01:30 PM ***** Save model *****
04/23 05:01:38 PM ***** Running evaluation *****
04/23 05:01:38 PM   Epoch = 1 iter 7699 step
04/23 05:01:38 PM   Num examples = 1043
04/23 05:01:38 PM   Batch size = 32
04/23 05:01:38 PM ***** Eval results *****
04/23 05:01:38 PM   att_loss = 0.43982533204789254
04/23 05:01:38 PM   cls_loss = 0.0
04/23 05:01:38 PM   global_step = 7699
04/23 05:01:38 PM   loss = 1.1777881940428505
04/23 05:01:38 PM   rep_loss = 0.7379628632471563
04/23 05:01:38 PM ***** Save model *****
04/23 05:01:46 PM ***** Running evaluation *****
04/23 05:01:46 PM   Epoch = 1 iter 7749 step
04/23 05:01:46 PM   Num examples = 1043
04/23 05:01:46 PM   Batch size = 32
04/23 05:01:46 PM ***** Eval results *****
04/23 05:01:46 PM   att_loss = 0.439544821535233
04/23 05:01:46 PM   cls_loss = 0.0
04/23 05:01:46 PM   global_step = 7749
04/23 05:01:46 PM   loss = 1.1773580086220599
04/23 05:01:46 PM   rep_loss = 0.7378131881768314
04/23 05:01:46 PM ***** Save model *****
04/23 05:01:54 PM ***** Running evaluation *****
04/23 05:01:54 PM   Epoch = 1 iter 7799 step
04/23 05:01:54 PM   Num examples = 1043
04/23 05:01:54 PM   Batch size = 32
04/23 05:01:54 PM ***** Eval results *****
04/23 05:01:54 PM   att_loss = 0.43946853616011644
04/23 05:01:54 PM   cls_loss = 0.0
04/23 05:01:54 PM   global_step = 7799
04/23 05:01:54 PM   loss = 1.1771106604935266
04/23 05:01:54 PM   rep_loss = 0.7376421254277739
04/23 05:01:54 PM ***** Save model *****
04/23 05:02:03 PM ***** Running evaluation *****
04/23 05:02:03 PM   Epoch = 1 iter 7849 step
04/23 05:02:03 PM   Num examples = 1043
04/23 05:02:03 PM   Batch size = 32
04/23 05:02:03 PM ***** Eval results *****
04/23 05:02:03 PM   att_loss = 0.43953984333881096
04/23 05:02:03 PM   cls_loss = 0.0
04/23 05:02:03 PM   global_step = 7849
04/23 05:02:03 PM   loss = 1.176984131482661
04/23 05:02:03 PM   rep_loss = 0.7374442893398482
04/23 05:02:03 PM ***** Save model *****
04/23 05:02:11 PM ***** Running evaluation *****
04/23 05:02:11 PM   Epoch = 1 iter 7899 step
04/23 05:02:11 PM   Num examples = 1043
04/23 05:02:11 PM   Batch size = 32
04/23 05:02:11 PM ***** Eval results *****
04/23 05:02:11 PM   att_loss = 0.4396494438008564
04/23 05:02:11 PM   cls_loss = 0.0
04/23 05:02:11 PM   global_step = 7899
04/23 05:02:11 PM   loss = 1.1769610467996305
04/23 05:02:11 PM   rep_loss = 0.7373116040304831
04/23 05:02:11 PM ***** Save model *****
04/23 05:02:19 PM ***** Running evaluation *****
04/23 05:02:19 PM   Epoch = 1 iter 7949 step
04/23 05:02:19 PM   Num examples = 1043
04/23 05:02:19 PM   Batch size = 32
04/23 05:02:19 PM ***** Eval results *****
04/23 05:02:19 PM   att_loss = 0.43946056484183427
04/23 05:02:19 PM   cls_loss = 0.0
04/23 05:02:19 PM   global_step = 7949
04/23 05:02:19 PM   loss = 1.1764324966657351
04/23 05:02:19 PM   rep_loss = 0.7369719327714387
04/23 05:02:19 PM ***** Save model *****
04/23 05:02:27 PM ***** Running evaluation *****
04/23 05:02:27 PM   Epoch = 1 iter 7999 step
04/23 05:02:27 PM   Num examples = 1043
04/23 05:02:27 PM   Batch size = 32
04/23 05:02:27 PM ***** Eval results *****
04/23 05:02:27 PM   att_loss = 0.43943099676475833
04/23 05:02:27 PM   cls_loss = 0.0
04/23 05:02:27 PM   global_step = 7999
04/23 05:02:27 PM   loss = 1.1760364991743837
04/23 05:02:27 PM   rep_loss = 0.7366055034530328
04/23 05:02:27 PM ***** Save model *****
04/23 05:02:35 PM ***** Running evaluation *****
04/23 05:02:35 PM   Epoch = 1 iter 8049 step
04/23 05:02:35 PM   Num examples = 1043
04/23 05:02:35 PM   Batch size = 32
04/23 05:02:35 PM ***** Eval results *****
04/23 05:02:35 PM   att_loss = 0.4391559216231213
04/23 05:02:35 PM   cls_loss = 0.0
04/23 05:02:35 PM   global_step = 8049
04/23 05:02:35 PM   loss = 1.1755351686376991
04/23 05:02:35 PM   rep_loss = 0.7363792479583531
04/23 05:02:35 PM ***** Save model *****
04/23 05:02:43 PM ***** Running evaluation *****
04/23 05:02:43 PM   Epoch = 1 iter 8099 step
04/23 05:02:43 PM   Num examples = 1043
04/23 05:02:43 PM   Batch size = 32
04/23 05:02:43 PM ***** Eval results *****
04/23 05:02:43 PM   att_loss = 0.4392906764305667
04/23 05:02:43 PM   cls_loss = 0.0
04/23 05:02:43 PM   global_step = 8099
04/23 05:02:43 PM   loss = 1.175625223435973
04/23 05:02:43 PM   rep_loss = 0.7363345476739833
04/23 05:02:43 PM ***** Save model *****
04/23 05:02:51 PM ***** Running evaluation *****
04/23 05:02:51 PM   Epoch = 1 iter 8149 step
04/23 05:02:51 PM   Num examples = 1043
04/23 05:02:51 PM   Batch size = 32
04/23 05:02:51 PM ***** Eval results *****
04/23 05:02:51 PM   att_loss = 0.4392489108264956
04/23 05:02:51 PM   cls_loss = 0.0
04/23 05:02:51 PM   global_step = 8149
04/23 05:02:51 PM   loss = 1.175447959479809
04/23 05:02:51 PM   rep_loss = 0.7361990494762574
04/23 05:02:51 PM ***** Save model *****
04/23 05:02:59 PM ***** Running evaluation *****
04/23 05:02:59 PM   Epoch = 1 iter 8199 step
04/23 05:02:59 PM   Num examples = 1043
04/23 05:02:59 PM   Batch size = 32
04/23 05:02:59 PM ***** Eval results *****
04/23 05:02:59 PM   att_loss = 0.43917465851156673
04/23 05:02:59 PM   cls_loss = 0.0
04/23 05:02:59 PM   global_step = 8199
04/23 05:02:59 PM   loss = 1.175253120825444
04/23 05:02:59 PM   rep_loss = 0.7360784630726888
04/23 05:02:59 PM ***** Save model *****
04/23 05:03:08 PM ***** Running evaluation *****
04/23 05:03:08 PM   Epoch = 1 iter 8249 step
04/23 05:03:08 PM   Num examples = 1043
04/23 05:03:08 PM   Batch size = 32
04/23 05:03:08 PM ***** Eval results *****
04/23 05:03:08 PM   att_loss = 0.43907733564020895
04/23 05:03:08 PM   cls_loss = 0.0
04/23 05:03:08 PM   global_step = 8249
04/23 05:03:08 PM   loss = 1.1749721982462917
04/23 05:03:08 PM   rep_loss = 0.7358948632863331
04/23 05:03:08 PM ***** Save model *****
04/23 05:03:16 PM ***** Running evaluation *****
04/23 05:03:16 PM   Epoch = 1 iter 8299 step
04/23 05:03:16 PM   Num examples = 1043
04/23 05:03:16 PM   Batch size = 32
04/23 05:03:16 PM ***** Eval results *****
04/23 05:03:16 PM   att_loss = 0.43890891902322615
04/23 05:03:16 PM   cls_loss = 0.0
04/23 05:03:16 PM   global_step = 8299
04/23 05:03:16 PM   loss = 1.1745744599046142
04/23 05:03:16 PM   rep_loss = 0.735665541648294
04/23 05:03:16 PM ***** Save model *****
04/23 05:03:24 PM ***** Running evaluation *****
04/23 05:03:24 PM   Epoch = 1 iter 8349 step
04/23 05:03:24 PM   Num examples = 1043
04/23 05:03:24 PM   Batch size = 32
04/23 05:03:24 PM ***** Eval results *****
04/23 05:03:24 PM   att_loss = 0.4388177418937384
04/23 05:03:24 PM   cls_loss = 0.0
04/23 05:03:24 PM   global_step = 8349
04/23 05:03:24 PM   loss = 1.1742822083534714
04/23 05:03:24 PM   rep_loss = 0.7354644672043582
04/23 05:03:24 PM ***** Save model *****
04/23 05:03:32 PM ***** Running evaluation *****
04/23 05:03:32 PM   Epoch = 1 iter 8399 step
04/23 05:03:32 PM   Num examples = 1043
04/23 05:03:32 PM   Batch size = 32
04/23 05:03:32 PM ***** Eval results *****
04/23 05:03:32 PM   att_loss = 0.4387526236167404
04/23 05:03:32 PM   cls_loss = 0.0
04/23 05:03:32 PM   global_step = 8399
04/23 05:03:32 PM   loss = 1.1739755442827722
04/23 05:03:32 PM   rep_loss = 0.7352229214064622
04/23 05:03:32 PM ***** Save model *****
04/23 05:03:40 PM ***** Running evaluation *****
04/23 05:03:40 PM   Epoch = 1 iter 8449 step
04/23 05:03:40 PM   Num examples = 1043
04/23 05:03:40 PM   Batch size = 32
04/23 05:03:40 PM ***** Eval results *****
04/23 05:03:40 PM   att_loss = 0.43871345577627535
04/23 05:03:40 PM   cls_loss = 0.0
04/23 05:03:40 PM   global_step = 8449
04/23 05:03:40 PM   loss = 1.1737377136896627
04/23 05:03:40 PM   rep_loss = 0.7350242586662192
04/23 05:03:40 PM ***** Save model *****
04/23 05:03:48 PM ***** Running evaluation *****
04/23 05:03:48 PM   Epoch = 1 iter 8499 step
04/23 05:03:48 PM   Num examples = 1043
04/23 05:03:48 PM   Batch size = 32
04/23 05:03:48 PM ***** Eval results *****
04/23 05:03:48 PM   att_loss = 0.43862181146918355
04/23 05:03:48 PM   cls_loss = 0.0
04/23 05:03:48 PM   global_step = 8499
04/23 05:03:48 PM   loss = 1.173437856723127
04/23 05:03:48 PM   rep_loss = 0.7348160459229425
04/23 05:03:48 PM ***** Save model *****
04/23 05:03:56 PM ***** Running evaluation *****
04/23 05:03:56 PM   Epoch = 1 iter 8549 step
04/23 05:03:56 PM   Num examples = 1043
04/23 05:03:56 PM   Batch size = 32
04/23 05:03:56 PM ***** Eval results *****
04/23 05:03:56 PM   att_loss = 0.4385811359636614
04/23 05:03:56 PM   cls_loss = 0.0
04/23 05:03:56 PM   global_step = 8549
04/23 05:03:56 PM   loss = 1.1731854284386782
04/23 05:03:56 PM   rep_loss = 0.7346042933282847
04/23 05:03:56 PM ***** Save model *****
04/23 05:04:04 PM ***** Running evaluation *****
04/23 05:04:04 PM   Epoch = 1 iter 8599 step
04/23 05:04:04 PM   Num examples = 1043
04/23 05:04:04 PM   Batch size = 32
04/23 05:04:04 PM ***** Eval results *****
04/23 05:04:04 PM   att_loss = 0.43848381264448044
04/23 05:04:04 PM   cls_loss = 0.0
04/23 05:04:04 PM   global_step = 8599
04/23 05:04:04 PM   loss = 1.172924677107553
04/23 05:04:04 PM   rep_loss = 0.734440865219093
04/23 05:04:04 PM ***** Save model *****
04/23 05:04:13 PM ***** Running evaluation *****
04/23 05:04:13 PM   Epoch = 1 iter 8649 step
04/23 05:04:13 PM   Num examples = 1043
04/23 05:04:13 PM   Batch size = 32
04/23 05:04:13 PM ***** Eval results *****
04/23 05:04:13 PM   att_loss = 0.43837126046935265
04/23 05:04:13 PM   cls_loss = 0.0
04/23 05:04:13 PM   global_step = 8649
04/23 05:04:13 PM   loss = 1.1727470726969218
04/23 05:04:13 PM   rep_loss = 0.7343758127584368
04/23 05:04:13 PM ***** Save model *****
04/23 05:04:21 PM ***** Running evaluation *****
04/23 05:04:21 PM   Epoch = 1 iter 8699 step
04/23 05:04:21 PM   Num examples = 1043
04/23 05:04:21 PM   Batch size = 32
04/23 05:04:21 PM ***** Eval results *****
04/23 05:04:21 PM   att_loss = 0.4382047558653936
04/23 05:04:21 PM   cls_loss = 0.0
04/23 05:04:21 PM   global_step = 8699
04/23 05:04:21 PM   loss = 1.172254143620044
04/23 05:04:21 PM   rep_loss = 0.7340493883158722
04/23 05:04:21 PM ***** Save model *****
04/23 05:04:29 PM ***** Running evaluation *****
04/23 05:04:29 PM   Epoch = 1 iter 8749 step
04/23 05:04:29 PM   Num examples = 1043
04/23 05:04:29 PM   Batch size = 32
04/23 05:04:29 PM ***** Eval results *****
04/23 05:04:29 PM   att_loss = 0.43808637623346286
04/23 05:04:29 PM   cls_loss = 0.0
04/23 05:04:29 PM   global_step = 8749
04/23 05:04:29 PM   loss = 1.172037614791363
04/23 05:04:29 PM   rep_loss = 0.733951239330709
04/23 05:04:29 PM ***** Save model *****
04/23 05:04:37 PM ***** Running evaluation *****
04/23 05:04:37 PM   Epoch = 1 iter 8799 step
04/23 05:04:37 PM   Num examples = 1043
04/23 05:04:37 PM   Batch size = 32
04/23 05:04:37 PM ***** Eval results *****
04/23 05:04:37 PM   att_loss = 0.43822451750565544
04/23 05:04:37 PM   cls_loss = 0.0
04/23 05:04:37 PM   global_step = 8799
04/23 05:04:37 PM   loss = 1.1720932457426185
04/23 05:04:37 PM   rep_loss = 0.7338687290743384
04/23 05:04:37 PM ***** Save model *****
04/23 05:04:45 PM ***** Running evaluation *****
04/23 05:04:45 PM   Epoch = 1 iter 8849 step
04/23 05:04:45 PM   Num examples = 1043
04/23 05:04:45 PM   Batch size = 32
04/23 05:04:45 PM ***** Eval results *****
04/23 05:04:45 PM   att_loss = 0.4384276139365827
04/23 05:04:45 PM   cls_loss = 0.0
04/23 05:04:45 PM   global_step = 8849
04/23 05:04:45 PM   loss = 1.1722731199526455
04/23 05:04:45 PM   rep_loss = 0.7338455068211682
04/23 05:04:45 PM ***** Save model *****
04/23 05:04:53 PM ***** Running evaluation *****
04/23 05:04:53 PM   Epoch = 1 iter 8899 step
04/23 05:04:53 PM   Num examples = 1043
04/23 05:04:53 PM   Batch size = 32
04/23 05:04:53 PM ***** Eval results *****
04/23 05:04:53 PM   att_loss = 0.43824840102464496
04/23 05:04:53 PM   cls_loss = 0.0
04/23 05:04:53 PM   global_step = 8899
04/23 05:04:53 PM   loss = 1.1719505356461506
04/23 05:04:53 PM   rep_loss = 0.7337021355532382
04/23 05:04:53 PM ***** Save model *****
04/23 05:05:01 PM ***** Running evaluation *****
04/23 05:05:01 PM   Epoch = 1 iter 8949 step
04/23 05:05:01 PM   Num examples = 1043
04/23 05:05:01 PM   Batch size = 32
04/23 05:05:01 PM ***** Eval results *****
04/23 05:05:01 PM   att_loss = 0.43813888261873934
04/23 05:05:01 PM   cls_loss = 0.0
04/23 05:05:01 PM   global_step = 8949
04/23 05:05:01 PM   loss = 1.1716544284537043
04/23 05:05:01 PM   rep_loss = 0.7335155466824244
04/23 05:05:01 PM ***** Save model *****
04/23 05:05:09 PM ***** Running evaluation *****
04/23 05:05:09 PM   Epoch = 1 iter 8999 step
04/23 05:05:09 PM   Num examples = 1043
04/23 05:05:09 PM   Batch size = 32
04/23 05:05:09 PM ***** Eval results *****
04/23 05:05:09 PM   att_loss = 0.4380816677007832
04/23 05:05:09 PM   cls_loss = 0.0
04/23 05:05:09 PM   global_step = 8999
04/23 05:05:09 PM   loss = 1.171459548989211
04/23 05:05:09 PM   rep_loss = 0.733377882218572
04/23 05:05:09 PM ***** Save model *****
04/23 05:05:17 PM ***** Running evaluation *****
04/23 05:05:17 PM   Epoch = 1 iter 9049 step
04/23 05:05:17 PM   Num examples = 1043
04/23 05:05:17 PM   Batch size = 32
04/23 05:05:17 PM ***** Eval results *****
04/23 05:05:17 PM   att_loss = 0.4380015701314035
04/23 05:05:17 PM   cls_loss = 0.0
04/23 05:05:17 PM   global_step = 9049
04/23 05:05:17 PM   loss = 1.1712047095537088
04/23 05:05:17 PM   rep_loss = 0.7332031404563387
04/23 05:05:17 PM ***** Save model *****
04/23 05:05:26 PM ***** Running evaluation *****
04/23 05:05:26 PM   Epoch = 1 iter 9099 step
04/23 05:05:26 PM   Num examples = 1043
04/23 05:05:26 PM   Batch size = 32
04/23 05:05:26 PM ***** Eval results *****
04/23 05:05:26 PM   att_loss = 0.4377796812754129
04/23 05:05:26 PM   cls_loss = 0.0
04/23 05:05:26 PM   global_step = 9099
04/23 05:05:26 PM   loss = 1.1707275379818491
04/23 05:05:26 PM   rep_loss = 0.7329478577436681
04/23 05:05:26 PM ***** Save model *****
04/23 05:05:34 PM ***** Running evaluation *****
04/23 05:05:34 PM   Epoch = 1 iter 9149 step
04/23 05:05:34 PM   Num examples = 1043
04/23 05:05:34 PM   Batch size = 32
04/23 05:05:34 PM ***** Eval results *****
04/23 05:05:34 PM   att_loss = 0.4377686926435261
04/23 05:05:34 PM   cls_loss = 0.0
04/23 05:05:34 PM   global_step = 9149
04/23 05:05:34 PM   loss = 1.1705318631656771
04/23 05:05:34 PM   rep_loss = 0.7327631714797029
04/23 05:05:34 PM ***** Save model *****
04/23 05:05:42 PM ***** Running evaluation *****
04/23 05:05:42 PM   Epoch = 1 iter 9199 step
04/23 05:05:42 PM   Num examples = 1043
04/23 05:05:42 PM   Batch size = 32
04/23 05:05:42 PM ***** Eval results *****
04/23 05:05:42 PM   att_loss = 0.4375516063320363
04/23 05:05:42 PM   cls_loss = 0.0
04/23 05:05:42 PM   global_step = 9199
04/23 05:05:42 PM   loss = 1.1702004219946904
04/23 05:05:42 PM   rep_loss = 0.732648816589992
04/23 05:05:42 PM ***** Save model *****
04/23 05:05:50 PM ***** Running evaluation *****
04/23 05:05:50 PM   Epoch = 1 iter 9249 step
04/23 05:05:50 PM   Num examples = 1043
04/23 05:05:50 PM   Batch size = 32
04/23 05:05:50 PM ***** Eval results *****
04/23 05:05:50 PM   att_loss = 0.4376024397240027
04/23 05:05:50 PM   cls_loss = 0.0
04/23 05:05:50 PM   global_step = 9249
04/23 05:05:50 PM   loss = 1.1701224195461426
04/23 05:05:50 PM   rep_loss = 0.7325199806976755
04/23 05:05:50 PM ***** Save model *****
04/23 05:05:58 PM ***** Running evaluation *****
04/23 05:05:58 PM   Epoch = 1 iter 9299 step
04/23 05:05:58 PM   Num examples = 1043
04/23 05:05:58 PM   Batch size = 32
04/23 05:05:58 PM ***** Eval results *****
04/23 05:05:58 PM   att_loss = 0.4374002443409645
04/23 05:05:58 PM   cls_loss = 0.0
04/23 05:05:58 PM   global_step = 9299
04/23 05:05:58 PM   loss = 1.1697102899812037
04/23 05:05:58 PM   rep_loss = 0.7323100464435964
04/23 05:05:58 PM ***** Save model *****
04/23 05:06:06 PM ***** Running evaluation *****
04/23 05:06:06 PM   Epoch = 1 iter 9349 step
04/23 05:06:06 PM   Num examples = 1043
04/23 05:06:06 PM   Batch size = 32
04/23 05:06:06 PM ***** Eval results *****
04/23 05:06:06 PM   att_loss = 0.4373549160187142
04/23 05:06:06 PM   cls_loss = 0.0
04/23 05:06:06 PM   global_step = 9349
04/23 05:06:06 PM   loss = 1.1694801870578793
04/23 05:06:06 PM   rep_loss = 0.7321252718387129
04/23 05:06:06 PM ***** Save model *****
04/23 05:06:14 PM ***** Running evaluation *****
04/23 05:06:14 PM   Epoch = 1 iter 9399 step
04/23 05:06:14 PM   Num examples = 1043
04/23 05:06:14 PM   Batch size = 32
04/23 05:06:14 PM ***** Eval results *****
04/23 05:06:14 PM   att_loss = 0.4373249113774825
04/23 05:06:14 PM   cls_loss = 0.0
04/23 05:06:14 PM   global_step = 9399
04/23 05:06:14 PM   loss = 1.1692770807719841
04/23 05:06:14 PM   rep_loss = 0.7319521702441529
04/23 05:06:14 PM ***** Save model *****
04/23 05:06:22 PM ***** Running evaluation *****
04/23 05:06:22 PM   Epoch = 1 iter 9449 step
04/23 05:06:22 PM   Num examples = 1043
04/23 05:06:22 PM   Batch size = 32
04/23 05:06:22 PM ***** Eval results *****
04/23 05:06:22 PM   att_loss = 0.4372824887483942
04/23 05:06:22 PM   cls_loss = 0.0
04/23 05:06:22 PM   global_step = 9449
04/23 05:06:22 PM   loss = 1.1691111729357184
04/23 05:06:22 PM   rep_loss = 0.7318286850113516
04/23 05:06:22 PM ***** Save model *****
04/23 05:06:31 PM ***** Running evaluation *****
04/23 05:06:31 PM   Epoch = 1 iter 9499 step
04/23 05:06:31 PM   Num examples = 1043
04/23 05:06:31 PM   Batch size = 32
04/23 05:06:31 PM ***** Eval results *****
04/23 05:06:31 PM   att_loss = 0.4370946944050571
04/23 05:06:31 PM   cls_loss = 0.0
04/23 05:06:31 PM   global_step = 9499
04/23 05:06:31 PM   loss = 1.16873388479745
04/23 05:06:31 PM   rep_loss = 0.7316391910671233
04/23 05:06:31 PM ***** Save model *****
04/23 05:06:39 PM ***** Running evaluation *****
04/23 05:06:39 PM   Epoch = 1 iter 9549 step
04/23 05:06:39 PM   Num examples = 1043
04/23 05:06:39 PM   Batch size = 32
04/23 05:06:39 PM ***** Eval results *****
04/23 05:06:39 PM   att_loss = 0.4369349107885965
04/23 05:06:39 PM   cls_loss = 0.0
04/23 05:06:39 PM   global_step = 9549
04/23 05:06:39 PM   loss = 1.168361720219331
04/23 05:06:39 PM   rep_loss = 0.7314268102061459
04/23 05:06:39 PM ***** Save model *****
04/23 05:06:47 PM ***** Running evaluation *****
04/23 05:06:47 PM   Epoch = 1 iter 9599 step
04/23 05:06:47 PM   Num examples = 1043
04/23 05:06:47 PM   Batch size = 32
04/23 05:06:47 PM ***** Eval results *****
04/23 05:06:47 PM   att_loss = 0.4368284347080615
04/23 05:06:47 PM   cls_loss = 0.0
04/23 05:06:47 PM   global_step = 9599
04/23 05:06:47 PM   loss = 1.1681099640965984
04/23 05:06:47 PM   rep_loss = 0.7312815301709606
04/23 05:06:47 PM ***** Save model *****
04/23 05:06:55 PM ***** Running evaluation *****
04/23 05:06:55 PM   Epoch = 1 iter 9649 step
04/23 05:06:55 PM   Num examples = 1043
04/23 05:06:55 PM   Batch size = 32
04/23 05:06:55 PM ***** Eval results *****
04/23 05:06:55 PM   att_loss = 0.43690005242725904
04/23 05:06:55 PM   cls_loss = 0.0
04/23 05:06:55 PM   global_step = 9649
04/23 05:06:55 PM   loss = 1.1680831301097876
04/23 05:06:55 PM   rep_loss = 0.7311830784224075
04/23 05:06:55 PM ***** Save model *****
04/23 05:07:03 PM ***** Running evaluation *****
04/23 05:07:03 PM   Epoch = 1 iter 9699 step
04/23 05:07:03 PM   Num examples = 1043
04/23 05:07:03 PM   Batch size = 32
04/23 05:07:03 PM ***** Eval results *****
04/23 05:07:03 PM   att_loss = 0.43683075831092477
04/23 05:07:03 PM   cls_loss = 0.0
04/23 05:07:03 PM   global_step = 9699
04/23 05:07:03 PM   loss = 1.1678759057216712
04/23 05:07:03 PM   rep_loss = 0.7310451481871013
04/23 05:07:03 PM ***** Save model *****
04/23 05:07:11 PM ***** Running evaluation *****
04/23 05:07:11 PM   Epoch = 1 iter 9749 step
04/23 05:07:11 PM   Num examples = 1043
04/23 05:07:11 PM   Batch size = 32
04/23 05:07:11 PM ***** Eval results *****
04/23 05:07:11 PM   att_loss = 0.4366988889378869
04/23 05:07:11 PM   cls_loss = 0.0
04/23 05:07:11 PM   global_step = 9749
04/23 05:07:11 PM   loss = 1.1675568713243478
04/23 05:07:11 PM   rep_loss = 0.7308579831503783
04/23 05:07:11 PM ***** Save model *****
04/23 05:07:19 PM ***** Running evaluation *****
04/23 05:07:19 PM   Epoch = 1 iter 9799 step
04/23 05:07:19 PM   Num examples = 1043
04/23 05:07:19 PM   Batch size = 32
04/23 05:07:19 PM ***** Eval results *****
04/23 05:07:19 PM   att_loss = 0.4365876429053144
04/23 05:07:19 PM   cls_loss = 0.0
04/23 05:07:19 PM   global_step = 9799
04/23 05:07:19 PM   loss = 1.1673149068210449
04/23 05:07:19 PM   rep_loss = 0.730727264517228
04/23 05:07:19 PM ***** Save model *****
04/23 05:07:27 PM ***** Running evaluation *****
04/23 05:07:27 PM   Epoch = 1 iter 9849 step
04/23 05:07:27 PM   Num examples = 1043
04/23 05:07:27 PM   Batch size = 32
04/23 05:07:27 PM ***** Eval results *****
04/23 05:07:27 PM   att_loss = 0.4365864223998661
04/23 05:07:27 PM   cls_loss = 0.0
04/23 05:07:27 PM   global_step = 9849
04/23 05:07:27 PM   loss = 1.1672139878008019
04/23 05:07:27 PM   rep_loss = 0.730627565937581
04/23 05:07:27 PM ***** Save model *****
04/23 05:07:35 PM ***** Running evaluation *****
04/23 05:07:35 PM   Epoch = 1 iter 9899 step
04/23 05:07:35 PM   Num examples = 1043
04/23 05:07:35 PM   Batch size = 32
04/23 05:07:35 PM ***** Eval results *****
04/23 05:07:35 PM   att_loss = 0.436465536188693
04/23 05:07:35 PM   cls_loss = 0.0
04/23 05:07:35 PM   global_step = 9899
04/23 05:07:35 PM   loss = 1.166905015333462
04/23 05:07:35 PM   rep_loss = 0.7304394797278777
04/23 05:07:35 PM ***** Save model *****
04/23 05:07:44 PM ***** Running evaluation *****
04/23 05:07:44 PM   Epoch = 1 iter 9949 step
04/23 05:07:44 PM   Num examples = 1043
04/23 05:07:44 PM   Batch size = 32
04/23 05:07:44 PM ***** Eval results *****
04/23 05:07:44 PM   att_loss = 0.4363980296235313
04/23 05:07:44 PM   cls_loss = 0.0
04/23 05:07:44 PM   global_step = 9949
04/23 05:07:44 PM   loss = 1.1666876184620867
04/23 05:07:44 PM   rep_loss = 0.7302895893680156
04/23 05:07:44 PM ***** Save model *****
04/23 05:07:52 PM ***** Running evaluation *****
04/23 05:07:52 PM   Epoch = 1 iter 9999 step
04/23 05:07:52 PM   Num examples = 1043
04/23 05:07:52 PM   Batch size = 32
04/23 05:07:52 PM ***** Eval results *****
04/23 05:07:52 PM   att_loss = 0.4363826615932044
04/23 05:07:52 PM   cls_loss = 0.0
04/23 05:07:52 PM   global_step = 9999
04/23 05:07:52 PM   loss = 1.166555179045979
04/23 05:07:52 PM   rep_loss = 0.7301725179920632
04/23 05:07:52 PM ***** Save model *****
04/23 05:08:00 PM ***** Running evaluation *****
04/23 05:08:00 PM   Epoch = 1 iter 10049 step
04/23 05:08:00 PM   Num examples = 1043
04/23 05:08:00 PM   Batch size = 32
04/23 05:08:00 PM ***** Eval results *****
04/23 05:08:00 PM   att_loss = 0.4362774742377916
04/23 05:08:00 PM   cls_loss = 0.0
04/23 05:08:00 PM   global_step = 10049
04/23 05:08:00 PM   loss = 1.1663121962819103
04/23 05:08:00 PM   rep_loss = 0.7300347226190832
04/23 05:08:00 PM ***** Save model *****
04/23 05:08:08 PM ***** Running evaluation *****
04/23 05:08:08 PM   Epoch = 1 iter 10099 step
04/23 05:08:08 PM   Num examples = 1043
04/23 05:08:08 PM   Batch size = 32
04/23 05:08:08 PM ***** Eval results *****
04/23 05:08:08 PM   att_loss = 0.4362030363467543
04/23 05:08:08 PM   cls_loss = 0.0
04/23 05:08:08 PM   global_step = 10099
04/23 05:08:08 PM   loss = 1.1660486400316306
04/23 05:08:08 PM   rep_loss = 0.7298456042000417
04/23 05:08:08 PM ***** Save model *****
04/23 05:08:16 PM ***** Running evaluation *****
04/23 05:08:16 PM   Epoch = 1 iter 10149 step
04/23 05:08:16 PM   Num examples = 1043
04/23 05:08:16 PM   Batch size = 32
04/23 05:08:16 PM ***** Eval results *****
04/23 05:08:16 PM   att_loss = 0.43609761823581317
04/23 05:08:16 PM   cls_loss = 0.0
04/23 05:08:16 PM   global_step = 10149
04/23 05:08:16 PM   loss = 1.1658221524197145
04/23 05:08:16 PM   rep_loss = 0.7297245348187138
04/23 05:08:16 PM ***** Save model *****
04/23 05:08:24 PM ***** Running evaluation *****
04/23 05:08:24 PM   Epoch = 1 iter 10199 step
04/23 05:08:24 PM   Num examples = 1043
04/23 05:08:24 PM   Batch size = 32
04/23 05:08:24 PM ***** Eval results *****
04/23 05:08:24 PM   att_loss = 0.43606576191647917
04/23 05:08:24 PM   cls_loss = 0.0
04/23 05:08:24 PM   global_step = 10199
04/23 05:08:24 PM   loss = 1.165684012263738
04/23 05:08:24 PM   rep_loss = 0.7296182508563435
04/23 05:08:24 PM ***** Save model *****
04/23 05:08:32 PM ***** Running evaluation *****
04/23 05:08:32 PM   Epoch = 1 iter 10249 step
04/23 05:08:32 PM   Num examples = 1043
04/23 05:08:32 PM   Batch size = 32
04/23 05:08:32 PM ***** Eval results *****
04/23 05:08:32 PM   att_loss = 0.43609852922189896
04/23 05:08:32 PM   cls_loss = 0.0
04/23 05:08:32 PM   global_step = 10249
04/23 05:08:32 PM   loss = 1.1656733204139198
04/23 05:08:32 PM   rep_loss = 0.7295747917023063
04/23 05:08:32 PM ***** Save model *****
04/23 05:08:40 PM ***** Running evaluation *****
04/23 05:08:40 PM   Epoch = 1 iter 10299 step
04/23 05:08:40 PM   Num examples = 1043
04/23 05:08:40 PM   Batch size = 32
04/23 05:08:40 PM ***** Eval results *****
04/23 05:08:40 PM   att_loss = 0.4361278265674054
04/23 05:08:40 PM   cls_loss = 0.0
04/23 05:08:40 PM   global_step = 10299
04/23 05:08:40 PM   loss = 1.1656365893056626
04/23 05:08:40 PM   rep_loss = 0.729508763306539
04/23 05:08:40 PM ***** Save model *****
04/23 05:08:49 PM ***** Running evaluation *****
04/23 05:08:49 PM   Epoch = 1 iter 10349 step
04/23 05:08:49 PM   Num examples = 1043
04/23 05:08:49 PM   Batch size = 32
04/23 05:08:49 PM ***** Eval results *****
04/23 05:08:49 PM   att_loss = 0.4361162653727994
04/23 05:08:49 PM   cls_loss = 0.0
04/23 05:08:49 PM   global_step = 10349
04/23 05:08:49 PM   loss = 1.1655085249249573
04/23 05:08:49 PM   rep_loss = 0.7293922601608588
04/23 05:08:49 PM ***** Save model *****
04/23 05:08:57 PM ***** Running evaluation *****
04/23 05:08:57 PM   Epoch = 1 iter 10399 step
04/23 05:08:57 PM   Num examples = 1043
04/23 05:08:57 PM   Batch size = 32
04/23 05:08:57 PM ***** Eval results *****
04/23 05:08:57 PM   att_loss = 0.4360665882164842
04/23 05:08:57 PM   cls_loss = 0.0
04/23 05:08:57 PM   global_step = 10399
04/23 05:08:57 PM   loss = 1.1653324578049264
04/23 05:08:57 PM   rep_loss = 0.7292658702443936
04/23 05:08:57 PM ***** Save model *****
04/23 05:09:05 PM ***** Running evaluation *****
04/23 05:09:05 PM   Epoch = 1 iter 10449 step
04/23 05:09:05 PM   Num examples = 1043
04/23 05:09:05 PM   Batch size = 32
04/23 05:09:05 PM ***** Eval results *****
04/23 05:09:05 PM   att_loss = 0.4360270594012453
04/23 05:09:05 PM   cls_loss = 0.0
04/23 05:09:05 PM   global_step = 10449
04/23 05:09:05 PM   loss = 1.1651546076872186
04/23 05:09:05 PM   rep_loss = 0.7291275489801389
04/23 05:09:05 PM ***** Save model *****
04/23 05:09:13 PM ***** Running evaluation *****
04/23 05:09:13 PM   Epoch = 1 iter 10499 step
04/23 05:09:13 PM   Num examples = 1043
04/23 05:09:13 PM   Batch size = 32
04/23 05:09:13 PM ***** Eval results *****
04/23 05:09:13 PM   att_loss = 0.43596927139131453
04/23 05:09:13 PM   cls_loss = 0.0
04/23 05:09:13 PM   global_step = 10499
04/23 05:09:13 PM   loss = 1.164977959686088
04/23 05:09:13 PM   rep_loss = 0.7290086889722741
04/23 05:09:13 PM ***** Save model *****
04/23 05:09:21 PM ***** Running evaluation *****
04/23 05:09:21 PM   Epoch = 1 iter 10549 step
04/23 05:09:21 PM   Num examples = 1043
04/23 05:09:21 PM   Batch size = 32
04/23 05:09:21 PM ***** Eval results *****
04/23 05:09:21 PM   att_loss = 0.4359517151590088
04/23 05:09:21 PM   cls_loss = 0.0
04/23 05:09:21 PM   global_step = 10549
04/23 05:09:21 PM   loss = 1.1648395955030544
04/23 05:09:21 PM   rep_loss = 0.7288878809368996
04/23 05:09:21 PM ***** Save model *****
04/23 05:09:29 PM ***** Running evaluation *****
04/23 05:09:29 PM   Epoch = 1 iter 10599 step
04/23 05:09:29 PM   Num examples = 1043
04/23 05:09:29 PM   Batch size = 32
04/23 05:09:29 PM ***** Eval results *****
04/23 05:09:29 PM   att_loss = 0.435840074075196
04/23 05:09:29 PM   cls_loss = 0.0
04/23 05:09:29 PM   global_step = 10599
04/23 05:09:29 PM   loss = 1.1646227957889554
04/23 05:09:29 PM   rep_loss = 0.7287827224342387
04/23 05:09:29 PM ***** Save model *****
04/23 05:09:37 PM ***** Running evaluation *****
04/23 05:09:37 PM   Epoch = 1 iter 10649 step
04/23 05:09:37 PM   Num examples = 1043
04/23 05:09:37 PM   Batch size = 32
04/23 05:09:37 PM ***** Eval results *****
04/23 05:09:37 PM   att_loss = 0.43577153670553603
04/23 05:09:37 PM   cls_loss = 0.0
04/23 05:09:37 PM   global_step = 10649
04/23 05:09:37 PM   loss = 1.1643971539765143
04/23 05:09:37 PM   rep_loss = 0.7286256180269687
04/23 05:09:37 PM ***** Save model *****
04/23 05:09:45 PM ***** Running evaluation *****
04/23 05:09:45 PM   Epoch = 1 iter 10699 step
04/23 05:09:45 PM   Num examples = 1043
04/23 05:09:45 PM   Batch size = 32
04/23 05:09:45 PM ***** Eval results *****
04/23 05:09:45 PM   att_loss = 0.43569253974744476
04/23 05:09:45 PM   cls_loss = 0.0
04/23 05:09:45 PM   global_step = 10699
04/23 05:09:45 PM   loss = 1.1641307620034702
04/23 05:09:45 PM   rep_loss = 0.7284382229588068
04/23 05:09:45 PM ***** Save model *****
04/23 05:09:54 PM ***** Running evaluation *****
04/23 05:09:54 PM   Epoch = 1 iter 10749 step
04/23 05:09:54 PM   Num examples = 1043
04/23 05:09:54 PM   Batch size = 32
04/23 05:09:54 PM ***** Eval results *****
04/23 05:09:54 PM   att_loss = 0.43557602514979965
04/23 05:09:54 PM   cls_loss = 0.0
04/23 05:09:54 PM   global_step = 10749
04/23 05:09:54 PM   loss = 1.1638668720596654
04/23 05:09:54 PM   rep_loss = 0.7282908476836703
04/23 05:09:54 PM ***** Save model *****
04/23 05:10:02 PM ***** Running evaluation *****
04/23 05:10:02 PM   Epoch = 1 iter 10799 step
04/23 05:10:02 PM   Num examples = 1043
04/23 05:10:02 PM   Batch size = 32
04/23 05:10:02 PM ***** Eval results *****
04/23 05:10:02 PM   att_loss = 0.43566461433697823
04/23 05:10:02 PM   cls_loss = 0.0
04/23 05:10:02 PM   global_step = 10799
04/23 05:10:02 PM   loss = 1.1638330638165726
04/23 05:10:02 PM   rep_loss = 0.7281684503512998
04/23 05:10:02 PM ***** Save model *****
04/23 05:10:10 PM ***** Running evaluation *****
04/23 05:10:10 PM   Epoch = 1 iter 10849 step
04/23 05:10:10 PM   Num examples = 1043
04/23 05:10:10 PM   Batch size = 32
04/23 05:10:10 PM ***** Eval results *****
04/23 05:10:10 PM   att_loss = 0.4356547897247815
04/23 05:10:10 PM   cls_loss = 0.0
04/23 05:10:10 PM   global_step = 10849
04/23 05:10:10 PM   loss = 1.1636521127149975
04/23 05:10:10 PM   rep_loss = 0.7279973237951116
04/23 05:10:10 PM ***** Save model *****
04/23 05:10:18 PM ***** Running evaluation *****
04/23 05:10:18 PM   Epoch = 1 iter 10899 step
04/23 05:10:18 PM   Num examples = 1043
04/23 05:10:18 PM   Batch size = 32
04/23 05:10:18 PM ***** Eval results *****
04/23 05:10:18 PM   att_loss = 0.4356455169051181
04/23 05:10:18 PM   cls_loss = 0.0
04/23 05:10:18 PM   global_step = 10899
04/23 05:10:18 PM   loss = 1.1634924958835746
04/23 05:10:18 PM   rep_loss = 0.7278469797181067
04/23 05:10:18 PM ***** Save model *****
04/23 05:10:26 PM ***** Running evaluation *****
04/23 05:10:26 PM   Epoch = 1 iter 10949 step
04/23 05:10:26 PM   Num examples = 1043
04/23 05:10:26 PM   Batch size = 32
04/23 05:10:26 PM ***** Eval results *****
04/23 05:10:26 PM   att_loss = 0.4355078816924264
04/23 05:10:26 PM   cls_loss = 0.0
04/23 05:10:26 PM   global_step = 10949
04/23 05:10:26 PM   loss = 1.1631704449957097
04/23 05:10:26 PM   rep_loss = 0.7276625639585068
04/23 05:10:26 PM ***** Save model *****
04/23 05:10:34 PM ***** Running evaluation *****
04/23 05:10:34 PM   Epoch = 1 iter 10999 step
04/23 05:10:34 PM   Num examples = 1043
04/23 05:10:34 PM   Batch size = 32
04/23 05:10:34 PM ***** Eval results *****
04/23 05:10:34 PM   att_loss = 0.435393845856367
04/23 05:10:34 PM   cls_loss = 0.0
04/23 05:10:34 PM   global_step = 10999
04/23 05:10:34 PM   loss = 1.1629562396475173
04/23 05:10:34 PM   rep_loss = 0.7275623944388786
04/23 05:10:34 PM ***** Save model *****
04/23 05:10:42 PM ***** Running evaluation *****
04/23 05:10:42 PM   Epoch = 1 iter 11049 step
04/23 05:10:42 PM   Num examples = 1043
04/23 05:10:42 PM   Batch size = 32
04/23 05:10:42 PM ***** Eval results *****
04/23 05:10:42 PM   att_loss = 0.435308971304722
04/23 05:10:42 PM   cls_loss = 0.0
04/23 05:10:42 PM   global_step = 11049
04/23 05:10:42 PM   loss = 1.1627257684862093
04/23 05:10:42 PM   rep_loss = 0.7274167979230063
04/23 05:10:42 PM ***** Save model *****
04/23 05:10:50 PM ***** Running evaluation *****
04/23 05:10:50 PM   Epoch = 1 iter 11099 step
04/23 05:10:50 PM   Num examples = 1043
04/23 05:10:50 PM   Batch size = 32
04/23 05:10:50 PM ***** Eval results *****
04/23 05:10:50 PM   att_loss = 0.43529506369315385
04/23 05:10:50 PM   cls_loss = 0.0
04/23 05:10:50 PM   global_step = 11099
04/23 05:10:50 PM   loss = 1.1625886171676254
04/23 05:10:50 PM   rep_loss = 0.7272935541143782
04/23 05:10:50 PM ***** Save model *****
04/23 05:10:58 PM ***** Running evaluation *****
04/23 05:10:58 PM   Epoch = 1 iter 11149 step
04/23 05:10:58 PM   Num examples = 1043
04/23 05:10:58 PM   Batch size = 32
04/23 05:10:58 PM ***** Eval results *****
04/23 05:10:58 PM   att_loss = 0.43523969689952247
04/23 05:10:58 PM   cls_loss = 0.0
04/23 05:10:58 PM   global_step = 11149
04/23 05:10:58 PM   loss = 1.162430629717568
04/23 05:10:58 PM   rep_loss = 0.7271909333915474
04/23 05:10:58 PM ***** Save model *****
04/23 05:11:07 PM ***** Running evaluation *****
04/23 05:11:07 PM   Epoch = 1 iter 11199 step
04/23 05:11:07 PM   Num examples = 1043
04/23 05:11:07 PM   Batch size = 32
04/23 05:11:07 PM ***** Eval results *****
04/23 05:11:07 PM   att_loss = 0.4351574082495582
04/23 05:11:07 PM   cls_loss = 0.0
04/23 05:11:07 PM   global_step = 11199
04/23 05:11:07 PM   loss = 1.1621994812101015
04/23 05:11:07 PM   rep_loss = 0.7270420735342918
04/23 05:11:07 PM ***** Save model *****
04/23 05:11:15 PM ***** Running evaluation *****
04/23 05:11:15 PM   Epoch = 1 iter 11249 step
04/23 05:11:15 PM   Num examples = 1043
04/23 05:11:15 PM   Batch size = 32
04/23 05:11:15 PM ***** Eval results *****
04/23 05:11:15 PM   att_loss = 0.43517213765740576
04/23 05:11:15 PM   cls_loss = 0.0
04/23 05:11:15 PM   global_step = 11249
04/23 05:11:15 PM   loss = 1.1620901258341085
04/23 05:11:15 PM   rep_loss = 0.7269179888861285
04/23 05:11:15 PM ***** Save model *****
04/23 05:11:23 PM ***** Running evaluation *****
04/23 05:11:23 PM   Epoch = 1 iter 11299 step
04/23 05:11:23 PM   Num examples = 1043
04/23 05:11:23 PM   Batch size = 32
04/23 05:11:23 PM ***** Eval results *****
04/23 05:11:23 PM   att_loss = 0.43515769317762115
04/23 05:11:23 PM   cls_loss = 0.0
04/23 05:11:23 PM   global_step = 11299
04/23 05:11:23 PM   loss = 1.1619785602484238
04/23 05:11:23 PM   rep_loss = 0.7268208677726342
04/23 05:11:23 PM ***** Save model *****
04/23 05:11:31 PM ***** Running evaluation *****
04/23 05:11:31 PM   Epoch = 1 iter 11349 step
04/23 05:11:31 PM   Num examples = 1043
04/23 05:11:31 PM   Batch size = 32
04/23 05:11:31 PM ***** Eval results *****
04/23 05:11:31 PM   att_loss = 0.43513973366908665
04/23 05:11:31 PM   cls_loss = 0.0
04/23 05:11:31 PM   global_step = 11349
04/23 05:11:31 PM   loss = 1.1618442664179756
04/23 05:11:31 PM   rep_loss = 0.7267045334874763
04/23 05:11:31 PM ***** Save model *****
04/23 05:11:39 PM ***** Running evaluation *****
04/23 05:11:39 PM   Epoch = 1 iter 11399 step
04/23 05:11:39 PM   Num examples = 1043
04/23 05:11:39 PM   Batch size = 32
04/23 05:11:39 PM ***** Eval results *****
04/23 05:11:39 PM   att_loss = 0.435190510497456
04/23 05:11:39 PM   cls_loss = 0.0
04/23 05:11:39 PM   global_step = 11399
04/23 05:11:39 PM   loss = 1.161798557553544
04/23 05:11:39 PM   rep_loss = 0.7266080478431544
04/23 05:11:39 PM ***** Save model *****
04/23 05:11:47 PM ***** Running evaluation *****
04/23 05:11:47 PM   Epoch = 1 iter 11449 step
04/23 05:11:47 PM   Num examples = 1043
04/23 05:11:47 PM   Batch size = 32
04/23 05:11:47 PM ***** Eval results *****
04/23 05:11:47 PM   att_loss = 0.4352542633857996
04/23 05:11:47 PM   cls_loss = 0.0
04/23 05:11:47 PM   global_step = 11449
04/23 05:11:47 PM   loss = 1.1617328852841626
04/23 05:11:47 PM   rep_loss = 0.7264786227638111
04/23 05:11:47 PM ***** Save model *****
04/23 05:11:55 PM ***** Running evaluation *****
04/23 05:11:55 PM   Epoch = 1 iter 11499 step
04/23 05:11:55 PM   Num examples = 1043
04/23 05:11:55 PM   Batch size = 32
04/23 05:11:55 PM ***** Eval results *****
04/23 05:11:55 PM   att_loss = 0.43523971770999614
04/23 05:11:55 PM   cls_loss = 0.0
04/23 05:11:55 PM   global_step = 11499
04/23 05:11:55 PM   loss = 1.1616242251291433
04/23 05:11:55 PM   rep_loss = 0.7263845083185398
04/23 05:11:55 PM ***** Save model *****
04/23 05:12:03 PM ***** Running evaluation *****
04/23 05:12:03 PM   Epoch = 1 iter 11549 step
04/23 05:12:03 PM   Num examples = 1043
04/23 05:12:03 PM   Batch size = 32
04/23 05:12:03 PM ***** Eval results *****
04/23 05:12:03 PM   att_loss = 0.4351739721602479
04/23 05:12:03 PM   cls_loss = 0.0
04/23 05:12:03 PM   global_step = 11549
04/23 05:12:03 PM   loss = 1.1614044946617432
04/23 05:12:03 PM   rep_loss = 0.7262305233856935
04/23 05:12:03 PM ***** Save model *****
04/23 05:12:11 PM ***** Running evaluation *****
04/23 05:12:11 PM   Epoch = 1 iter 11599 step
04/23 05:12:11 PM   Num examples = 1043
04/23 05:12:11 PM   Batch size = 32
04/23 05:12:11 PM ***** Eval results *****
04/23 05:12:11 PM   att_loss = 0.4351045402500189
04/23 05:12:11 PM   cls_loss = 0.0
04/23 05:12:11 PM   global_step = 11599
04/23 05:12:11 PM   loss = 1.1611872361330313
04/23 05:12:11 PM   rep_loss = 0.7260826967703076
04/23 05:12:11 PM ***** Save model *****
04/23 05:12:20 PM ***** Running evaluation *****
04/23 05:12:20 PM   Epoch = 1 iter 11649 step
04/23 05:12:20 PM   Num examples = 1043
04/23 05:12:20 PM   Batch size = 32
04/23 05:12:20 PM ***** Eval results *****
04/23 05:12:20 PM   att_loss = 0.4350503037660109
04/23 05:12:20 PM   cls_loss = 0.0
04/23 05:12:20 PM   global_step = 11649
04/23 05:12:20 PM   loss = 1.160981993303905
04/23 05:12:20 PM   rep_loss = 0.7259316904163532
04/23 05:12:20 PM ***** Save model *****
04/23 05:12:28 PM ***** Running evaluation *****
04/23 05:12:28 PM   Epoch = 1 iter 11699 step
04/23 05:12:28 PM   Num examples = 1043
04/23 05:12:28 PM   Batch size = 32
04/23 05:12:28 PM ***** Eval results *****
04/23 05:12:28 PM   att_loss = 0.43490883774998107
04/23 05:12:28 PM   cls_loss = 0.0
04/23 05:12:28 PM   global_step = 11699
04/23 05:12:28 PM   loss = 1.1607493547687069
04/23 05:12:28 PM   rep_loss = 0.7258405178708923
04/23 05:12:28 PM ***** Save model *****
04/23 05:12:36 PM ***** Running evaluation *****
04/23 05:12:36 PM   Epoch = 1 iter 11749 step
04/23 05:12:36 PM   Num examples = 1043
04/23 05:12:36 PM   Batch size = 32
04/23 05:12:36 PM ***** Eval results *****
04/23 05:12:36 PM   att_loss = 0.4348339796403823
04/23 05:12:36 PM   cls_loss = 0.0
04/23 05:12:36 PM   global_step = 11749
04/23 05:12:36 PM   loss = 1.160529261337456
04/23 05:12:36 PM   rep_loss = 0.7256952825409201
04/23 05:12:36 PM ***** Save model *****
04/23 05:12:44 PM ***** Running evaluation *****
04/23 05:12:44 PM   Epoch = 1 iter 11799 step
04/23 05:12:44 PM   Num examples = 1043
04/23 05:12:44 PM   Batch size = 32
04/23 05:12:44 PM ***** Eval results *****
04/23 05:12:44 PM   att_loss = 0.43488992419539785
04/23 05:12:44 PM   cls_loss = 0.0
04/23 05:12:44 PM   global_step = 11799
04/23 05:12:44 PM   loss = 1.1605165001963813
04/23 05:12:44 PM   rep_loss = 0.7256265769404108
04/23 05:12:44 PM ***** Save model *****
04/23 05:12:52 PM ***** Running evaluation *****
04/23 05:12:52 PM   Epoch = 1 iter 11849 step
04/23 05:12:52 PM   Num examples = 1043
04/23 05:12:52 PM   Batch size = 32
04/23 05:12:52 PM ***** Eval results *****
04/23 05:12:52 PM   att_loss = 0.4348424960258157
04/23 05:12:52 PM   cls_loss = 0.0
04/23 05:12:52 PM   global_step = 11849
04/23 05:12:52 PM   loss = 1.1603422984380964
04/23 05:12:52 PM   rep_loss = 0.7254998032856298
04/23 05:12:52 PM ***** Save model *****
04/23 05:13:00 PM ***** Running evaluation *****
04/23 05:13:00 PM   Epoch = 1 iter 11899 step
04/23 05:13:00 PM   Num examples = 1043
04/23 05:13:00 PM   Batch size = 32
04/23 05:13:00 PM ***** Eval results *****
04/23 05:13:00 PM   att_loss = 0.43479199309182603
04/23 05:13:00 PM   cls_loss = 0.0
04/23 05:13:00 PM   global_step = 11899
04/23 05:13:00 PM   loss = 1.1601718361566333
04/23 05:13:00 PM   rep_loss = 0.725379843952488
04/23 05:13:00 PM ***** Save model *****
04/23 05:13:08 PM ***** Running evaluation *****
04/23 05:13:08 PM   Epoch = 1 iter 11949 step
04/23 05:13:08 PM   Num examples = 1043
04/23 05:13:08 PM   Batch size = 32
04/23 05:13:08 PM ***** Eval results *****
04/23 05:13:08 PM   att_loss = 0.43465148835248507
04/23 05:13:08 PM   cls_loss = 0.0
04/23 05:13:08 PM   global_step = 11949
04/23 05:13:08 PM   loss = 1.1599111510183417
04/23 05:13:08 PM   rep_loss = 0.7252596635675995
04/23 05:13:08 PM ***** Save model *****
04/23 05:13:16 PM ***** Running evaluation *****
04/23 05:13:16 PM   Epoch = 1 iter 11999 step
04/23 05:13:16 PM   Num examples = 1043
04/23 05:13:16 PM   Batch size = 32
04/23 05:13:16 PM ***** Eval results *****
04/23 05:13:16 PM   att_loss = 0.4345596659130234
04/23 05:13:16 PM   cls_loss = 0.0
04/23 05:13:16 PM   global_step = 11999
04/23 05:13:16 PM   loss = 1.1596777548760682
04/23 05:13:16 PM   rep_loss = 0.7251180898009055
04/23 05:13:16 PM ***** Save model *****
04/23 05:13:25 PM ***** Running evaluation *****
04/23 05:13:25 PM   Epoch = 1 iter 12049 step
04/23 05:13:25 PM   Num examples = 1043
04/23 05:13:25 PM   Batch size = 32
04/23 05:13:25 PM ***** Eval results *****
04/23 05:13:25 PM   att_loss = 0.4345031614519973
04/23 05:13:25 PM   cls_loss = 0.0
04/23 05:13:25 PM   global_step = 12049
04/23 05:13:25 PM   loss = 1.1595017068435776
04/23 05:13:25 PM   rep_loss = 0.7249985461942253
04/23 05:13:25 PM ***** Save model *****
04/23 05:13:33 PM ***** Running evaluation *****
04/23 05:13:33 PM   Epoch = 1 iter 12099 step
04/23 05:13:33 PM   Num examples = 1043
04/23 05:13:33 PM   Batch size = 32
04/23 05:13:33 PM ***** Eval results *****
04/23 05:13:33 PM   att_loss = 0.4343810983777068
04/23 05:13:33 PM   cls_loss = 0.0
04/23 05:13:33 PM   global_step = 12099
04/23 05:13:33 PM   loss = 1.1592579856474077
04/23 05:13:33 PM   rep_loss = 0.7248768879996426
04/23 05:13:33 PM ***** Save model *****
04/23 05:13:41 PM ***** Running evaluation *****
04/23 05:13:41 PM   Epoch = 1 iter 12149 step
04/23 05:13:41 PM   Num examples = 1043
04/23 05:13:41 PM   Batch size = 32
04/23 05:13:41 PM ***** Eval results *****
04/23 05:13:41 PM   att_loss = 0.43429696786081934
04/23 05:13:41 PM   cls_loss = 0.0
04/23 05:13:41 PM   global_step = 12149
04/23 05:13:41 PM   loss = 1.1590563960749911
04/23 05:13:41 PM   rep_loss = 0.7247594289536969
04/23 05:13:41 PM ***** Save model *****
04/23 05:13:49 PM ***** Running evaluation *****
04/23 05:13:49 PM   Epoch = 1 iter 12199 step
04/23 05:13:49 PM   Num examples = 1043
04/23 05:13:49 PM   Batch size = 32
04/23 05:13:49 PM ***** Eval results *****
04/23 05:13:49 PM   att_loss = 0.4343262200958103
04/23 05:13:49 PM   cls_loss = 0.0
04/23 05:13:49 PM   global_step = 12199
04/23 05:13:49 PM   loss = 1.1590017001133721
04/23 05:13:49 PM   rep_loss = 0.7246754807664983
04/23 05:13:49 PM ***** Save model *****
04/23 05:13:57 PM ***** Running evaluation *****
04/23 05:13:57 PM   Epoch = 1 iter 12249 step
04/23 05:13:57 PM   Num examples = 1043
04/23 05:13:57 PM   Batch size = 32
04/23 05:13:57 PM ***** Eval results *****
04/23 05:13:57 PM   att_loss = 0.4343155558858769
04/23 05:13:57 PM   cls_loss = 0.0
04/23 05:13:57 PM   global_step = 12249
04/23 05:13:57 PM   loss = 1.1588813998779355
04/23 05:13:57 PM   rep_loss = 0.7245658447661448
04/23 05:13:57 PM ***** Save model *****
04/23 05:14:05 PM ***** Running evaluation *****
04/23 05:14:05 PM   Epoch = 1 iter 12299 step
04/23 05:14:05 PM   Num examples = 1043
04/23 05:14:05 PM   Batch size = 32
04/23 05:14:05 PM ***** Eval results *****
04/23 05:14:05 PM   att_loss = 0.43434135747468783
04/23 05:14:05 PM   cls_loss = 0.0
04/23 05:14:05 PM   global_step = 12299
04/23 05:14:05 PM   loss = 1.1588211338937524
04/23 05:14:05 PM   rep_loss = 0.7244797771810707
04/23 05:14:05 PM ***** Save model *****
04/23 05:14:13 PM ***** Running evaluation *****
04/23 05:14:13 PM   Epoch = 1 iter 12349 step
04/23 05:14:13 PM   Num examples = 1043
04/23 05:14:13 PM   Batch size = 32
04/23 05:14:13 PM ***** Eval results *****
04/23 05:14:13 PM   att_loss = 0.4342184140119201
04/23 05:14:13 PM   cls_loss = 0.0
04/23 05:14:13 PM   global_step = 12349
04/23 05:14:13 PM   loss = 1.1585787917492045
04/23 05:14:13 PM   rep_loss = 0.7243603784770029
04/23 05:14:13 PM ***** Save model *****
04/23 05:14:21 PM ***** Running evaluation *****
04/23 05:14:21 PM   Epoch = 1 iter 12399 step
04/23 05:14:21 PM   Num examples = 1043
04/23 05:14:21 PM   Batch size = 32
04/23 05:14:21 PM ***** Eval results *****
04/23 05:14:21 PM   att_loss = 0.4341725292475999
04/23 05:14:21 PM   cls_loss = 0.0
04/23 05:14:21 PM   global_step = 12399
04/23 05:14:21 PM   loss = 1.1583985997700563
04/23 05:14:21 PM   rep_loss = 0.7242260712970793
04/23 05:14:21 PM ***** Save model *****
04/23 05:14:30 PM ***** Running evaluation *****
04/23 05:14:30 PM   Epoch = 1 iter 12449 step
04/23 05:14:30 PM   Num examples = 1043
04/23 05:14:30 PM   Batch size = 32
04/23 05:14:30 PM ***** Eval results *****
04/23 05:14:30 PM   att_loss = 0.4341016628143817
04/23 05:14:30 PM   cls_loss = 0.0
04/23 05:14:30 PM   global_step = 12449
04/23 05:14:30 PM   loss = 1.1582075985328701
04/23 05:14:30 PM   rep_loss = 0.7241059364454994
04/23 05:14:30 PM ***** Save model *****
04/23 05:14:38 PM ***** Running evaluation *****
04/23 05:14:38 PM   Epoch = 1 iter 12499 step
04/23 05:14:38 PM   Num examples = 1043
04/23 05:14:38 PM   Batch size = 32
04/23 05:14:38 PM ***** Eval results *****
04/23 05:14:38 PM   att_loss = 0.4340470462829367
04/23 05:14:38 PM   cls_loss = 0.0
04/23 05:14:38 PM   global_step = 12499
04/23 05:14:38 PM   loss = 1.1580370258907304
04/23 05:14:38 PM   rep_loss = 0.7239899804250607
04/23 05:14:38 PM ***** Save model *****
04/23 05:14:46 PM ***** Running evaluation *****
04/23 05:14:46 PM   Epoch = 1 iter 12549 step
04/23 05:14:46 PM   Num examples = 1043
04/23 05:14:46 PM   Batch size = 32
04/23 05:14:46 PM ***** Eval results *****
04/23 05:14:46 PM   att_loss = 0.43397748032910377
04/23 05:14:46 PM   cls_loss = 0.0
04/23 05:14:46 PM   global_step = 12549
04/23 05:14:46 PM   loss = 1.157848781698601
04/23 05:14:46 PM   rep_loss = 0.7238713021798626
04/23 05:14:46 PM ***** Save model *****
04/23 05:14:54 PM ***** Running evaluation *****
04/23 05:14:54 PM   Epoch = 1 iter 12599 step
04/23 05:14:54 PM   Num examples = 1043
04/23 05:14:54 PM   Batch size = 32
04/23 05:14:54 PM ***** Eval results *****
04/23 05:14:54 PM   att_loss = 0.43394926768853787
04/23 05:14:54 PM   cls_loss = 0.0
04/23 05:14:54 PM   global_step = 12599
04/23 05:14:54 PM   loss = 1.1577015048673736
04/23 05:14:54 PM   rep_loss = 0.7237522380073712
04/23 05:14:54 PM ***** Save model *****
04/23 05:15:02 PM ***** Running evaluation *****
04/23 05:15:02 PM   Epoch = 1 iter 12649 step
04/23 05:15:02 PM   Num examples = 1043
04/23 05:15:02 PM   Batch size = 32
04/23 05:15:02 PM ***** Eval results *****
04/23 05:15:02 PM   att_loss = 0.4339523840744498
04/23 05:15:02 PM   cls_loss = 0.0
04/23 05:15:02 PM   global_step = 12649
04/23 05:15:02 PM   loss = 1.1575902437296566
04/23 05:15:02 PM   rep_loss = 0.723637860491711
04/23 05:15:02 PM ***** Save model *****
04/23 05:15:10 PM ***** Running evaluation *****
04/23 05:15:10 PM   Epoch = 1 iter 12699 step
04/23 05:15:10 PM   Num examples = 1043
04/23 05:15:10 PM   Batch size = 32
04/23 05:15:10 PM ***** Eval results *****
04/23 05:15:10 PM   att_loss = 0.43392291263033034
04/23 05:15:10 PM   cls_loss = 0.0
04/23 05:15:10 PM   global_step = 12699
04/23 05:15:10 PM   loss = 1.1574607424240413
04/23 05:15:10 PM   rep_loss = 0.7235378307165964
04/23 05:15:10 PM ***** Save model *****
04/23 05:15:18 PM ***** Running evaluation *****
04/23 05:15:18 PM   Epoch = 1 iter 12749 step
04/23 05:15:18 PM   Num examples = 1043
04/23 05:15:18 PM   Batch size = 32
04/23 05:15:18 PM ***** Eval results *****
04/23 05:15:18 PM   att_loss = 0.4339126015513809
04/23 05:15:18 PM   cls_loss = 0.0
04/23 05:15:18 PM   global_step = 12749
04/23 05:15:18 PM   loss = 1.1573552109217102
04/23 05:15:18 PM   rep_loss = 0.7234426102321184
04/23 05:15:18 PM ***** Save model *****
04/23 05:15:26 PM ***** Running evaluation *****
04/23 05:15:26 PM   Epoch = 1 iter 12799 step
04/23 05:15:26 PM   Num examples = 1043
04/23 05:15:26 PM   Batch size = 32
04/23 05:15:26 PM ***** Eval results *****
04/23 05:15:26 PM   att_loss = 0.4338686942687164
04/23 05:15:26 PM   cls_loss = 0.0
04/23 05:15:26 PM   global_step = 12799
04/23 05:15:26 PM   loss = 1.1571885740673922
04/23 05:15:26 PM   rep_loss = 0.7233198806389942
04/23 05:15:26 PM ***** Save model *****
04/23 05:15:34 PM ***** Running evaluation *****
04/23 05:15:34 PM   Epoch = 1 iter 12849 step
04/23 05:15:34 PM   Num examples = 1043
04/23 05:15:34 PM   Batch size = 32
04/23 05:15:34 PM ***** Eval results *****
04/23 05:15:34 PM   att_loss = 0.43382894250764437
04/23 05:15:34 PM   cls_loss = 0.0
04/23 05:15:34 PM   global_step = 12849
04/23 05:15:34 PM   loss = 1.1570165258303962
04/23 05:15:34 PM   rep_loss = 0.7231875841419445
04/23 05:15:34 PM ***** Save model *****
04/23 05:15:43 PM ***** Running evaluation *****
04/23 05:15:43 PM   Epoch = 1 iter 12899 step
04/23 05:15:43 PM   Num examples = 1043
04/23 05:15:43 PM   Batch size = 32
04/23 05:15:43 PM ***** Eval results *****
04/23 05:15:43 PM   att_loss = 0.43374442953923503
04/23 05:15:43 PM   cls_loss = 0.0
04/23 05:15:43 PM   global_step = 12899
04/23 05:15:43 PM   loss = 1.1568064774609206
04/23 05:15:43 PM   rep_loss = 0.7230620487153369
04/23 05:15:43 PM ***** Save model *****
04/23 05:15:51 PM ***** Running evaluation *****
04/23 05:15:51 PM   Epoch = 1 iter 12949 step
04/23 05:15:51 PM   Num examples = 1043
04/23 05:15:51 PM   Batch size = 32
04/23 05:15:51 PM ***** Eval results *****
04/23 05:15:51 PM   att_loss = 0.4336792907935874
04/23 05:15:51 PM   cls_loss = 0.0
04/23 05:15:51 PM   global_step = 12949
04/23 05:15:51 PM   loss = 1.156637415122503
04/23 05:15:51 PM   rep_loss = 0.7229581251210039
04/23 05:15:51 PM ***** Save model *****
04/23 05:15:59 PM ***** Running evaluation *****
04/23 05:15:59 PM   Epoch = 1 iter 12999 step
04/23 05:15:59 PM   Num examples = 1043
04/23 05:15:59 PM   Batch size = 32
04/23 05:15:59 PM ***** Eval results *****
04/23 05:15:59 PM   att_loss = 0.4336338369957863
04/23 05:15:59 PM   cls_loss = 0.0
04/23 05:15:59 PM   global_step = 12999
04/23 05:15:59 PM   loss = 1.156499214251699
04/23 05:15:59 PM   rep_loss = 0.7228653779716174
04/23 05:15:59 PM ***** Save model *****
04/23 05:16:07 PM ***** Running evaluation *****
04/23 05:16:07 PM   Epoch = 1 iter 13049 step
04/23 05:16:07 PM   Num examples = 1043
04/23 05:16:07 PM   Batch size = 32
04/23 05:16:07 PM ***** Eval results *****
04/23 05:16:07 PM   att_loss = 0.4335736790293382
04/23 05:16:07 PM   cls_loss = 0.0
04/23 05:16:07 PM   global_step = 13049
04/23 05:16:07 PM   loss = 1.1563319993007966
04/23 05:16:07 PM   rep_loss = 0.7227583210001555
04/23 05:16:07 PM ***** Save model *****
04/23 05:16:15 PM ***** Running evaluation *****
04/23 05:16:15 PM   Epoch = 1 iter 13099 step
04/23 05:16:15 PM   Num examples = 1043
04/23 05:16:15 PM   Batch size = 32
04/23 05:16:15 PM ***** Eval results *****
04/23 05:16:15 PM   att_loss = 0.4334965244711615
04/23 05:16:15 PM   cls_loss = 0.0
04/23 05:16:15 PM   global_step = 13099
04/23 05:16:15 PM   loss = 1.1561267382393774
04/23 05:16:15 PM   rep_loss = 0.7226302144498329
04/23 05:16:15 PM ***** Save model *****
04/23 05:16:23 PM ***** Running evaluation *****
04/23 05:16:23 PM   Epoch = 1 iter 13149 step
04/23 05:16:23 PM   Num examples = 1043
04/23 05:16:23 PM   Batch size = 32
04/23 05:16:23 PM ***** Eval results *****
04/23 05:16:23 PM   att_loss = 0.43347110449490855
04/23 05:16:23 PM   cls_loss = 0.0
04/23 05:16:23 PM   global_step = 13149
04/23 05:16:23 PM   loss = 1.155998938911039
04/23 05:16:23 PM   rep_loss = 0.7225278350788106
04/23 05:16:23 PM ***** Save model *****
04/23 05:16:31 PM ***** Running evaluation *****
04/23 05:16:31 PM   Epoch = 1 iter 13199 step
04/23 05:16:31 PM   Num examples = 1043
04/23 05:16:31 PM   Batch size = 32
04/23 05:16:31 PM ***** Eval results *****
04/23 05:16:31 PM   att_loss = 0.43342864346039783
04/23 05:16:31 PM   cls_loss = 0.0
04/23 05:16:31 PM   global_step = 13199
04/23 05:16:31 PM   loss = 1.155827150771542
04/23 05:16:31 PM   rep_loss = 0.7223985079869235
04/23 05:16:31 PM ***** Save model *****
04/23 05:16:39 PM ***** Running evaluation *****
04/23 05:16:39 PM   Epoch = 1 iter 13249 step
04/23 05:16:39 PM   Num examples = 1043
04/23 05:16:39 PM   Batch size = 32
04/23 05:16:39 PM ***** Eval results *****
04/23 05:16:39 PM   att_loss = 0.43341048861482573
04/23 05:16:39 PM   cls_loss = 0.0
04/23 05:16:39 PM   global_step = 13249
04/23 05:16:39 PM   loss = 1.1556863093048473
04/23 05:16:39 PM   rep_loss = 0.7222758213697
04/23 05:16:39 PM ***** Save model *****
04/23 05:16:48 PM ***** Running evaluation *****
04/23 05:16:48 PM   Epoch = 2 iter 13299 step
04/23 05:16:48 PM   Num examples = 1043
04/23 05:16:48 PM   Batch size = 32
04/23 05:16:48 PM ***** Eval results *****
04/23 05:16:48 PM   att_loss = 0.42266402341598686
04/23 05:16:48 PM   cls_loss = 0.0
04/23 05:16:48 PM   global_step = 13299
04/23 05:16:48 PM   loss = 1.1271208746488703
04/23 05:16:48 PM   rep_loss = 0.7044568505398062
04/23 05:16:48 PM ***** Save model *****
04/23 05:16:56 PM ***** Running evaluation *****
04/23 05:16:56 PM   Epoch = 2 iter 13349 step
04/23 05:16:56 PM   Num examples = 1043
04/23 05:16:56 PM   Batch size = 32
04/23 05:16:56 PM ***** Eval results *****
04/23 05:16:56 PM   att_loss = 0.4219917478740856
04/23 05:16:56 PM   cls_loss = 0.0
04/23 05:16:56 PM   global_step = 13349
04/23 05:16:56 PM   loss = 1.1269551284851567
04/23 05:16:56 PM   rep_loss = 0.7049633732406042
04/23 05:16:56 PM ***** Save model *****
04/23 05:17:04 PM ***** Running evaluation *****
04/23 05:17:04 PM   Epoch = 2 iter 13399 step
04/23 05:17:04 PM   Num examples = 1043
04/23 05:17:04 PM   Batch size = 32
04/23 05:17:04 PM ***** Eval results *****
04/23 05:17:04 PM   att_loss = 0.4218645202113198
04/23 05:17:04 PM   cls_loss = 0.0
04/23 05:17:04 PM   global_step = 13399
04/23 05:17:04 PM   loss = 1.127304004622506
04/23 05:17:04 PM   rep_loss = 0.7054394800346214
04/23 05:17:04 PM ***** Save model *****
04/23 05:17:12 PM ***** Running evaluation *****
04/23 05:17:12 PM   Epoch = 2 iter 13449 step
04/23 05:17:12 PM   Num examples = 1043
04/23 05:17:12 PM   Batch size = 32
04/23 05:17:12 PM ***** Eval results *****
04/23 05:17:12 PM   att_loss = 0.42332204728546535
04/23 05:17:12 PM   cls_loss = 0.0
04/23 05:17:12 PM   global_step = 13449
04/23 05:17:12 PM   loss = 1.1286612137611667
04/23 05:17:12 PM   rep_loss = 0.7053391630785453
04/23 05:17:12 PM ***** Save model *****
04/23 05:17:20 PM ***** Running evaluation *****
04/23 05:17:20 PM   Epoch = 2 iter 13499 step
04/23 05:17:20 PM   Num examples = 1043
04/23 05:17:20 PM   Batch size = 32
04/23 05:17:20 PM ***** Eval results *****
04/23 05:17:20 PM   att_loss = 0.42387613580550676
04/23 05:17:20 PM   cls_loss = 0.0
04/23 05:17:20 PM   global_step = 13499
04/23 05:17:20 PM   loss = 1.129018347449754
04/23 05:17:20 PM   rep_loss = 0.7051422088234512
04/23 05:17:20 PM ***** Save model *****
04/23 05:17:28 PM ***** Running evaluation *****
04/23 05:17:28 PM   Epoch = 2 iter 13549 step
04/23 05:17:28 PM   Num examples = 1043
04/23 05:17:28 PM   Batch size = 32
04/23 05:17:28 PM ***** Eval results *****
04/23 05:17:28 PM   att_loss = 0.4231168257498497
04/23 05:17:28 PM   cls_loss = 0.0
04/23 05:17:28 PM   global_step = 13549
04/23 05:17:28 PM   loss = 1.1281333917643837
04/23 05:17:28 PM   rep_loss = 0.7050165635733882
04/23 05:17:28 PM ***** Save model *****
04/23 05:17:36 PM ***** Running evaluation *****
04/23 05:17:36 PM   Epoch = 2 iter 13599 step
04/23 05:17:36 PM   Num examples = 1043
04/23 05:17:36 PM   Batch size = 32
04/23 05:17:36 PM ***** Eval results *****
04/23 05:17:36 PM   att_loss = 0.4232612847412988
04/23 05:17:36 PM   cls_loss = 0.0
04/23 05:17:36 PM   global_step = 13599
04/23 05:17:36 PM   loss = 1.1285804954979233
04/23 05:17:36 PM   rep_loss = 0.7053192094533158
04/23 05:17:36 PM ***** Save model *****
04/23 05:17:44 PM ***** Running evaluation *****
04/23 05:17:44 PM   Epoch = 2 iter 13649 step
04/23 05:17:44 PM   Num examples = 1043
04/23 05:17:44 PM   Batch size = 32
04/23 05:17:44 PM ***** Eval results *****
04/23 05:17:44 PM   att_loss = 0.42387662323679937
04/23 05:17:44 PM   cls_loss = 0.0
04/23 05:17:44 PM   global_step = 13649
04/23 05:17:44 PM   loss = 1.1294204660954366
04/23 05:17:44 PM   rep_loss = 0.7055438427828044
04/23 05:17:44 PM ***** Save model *****
04/23 05:17:52 PM ***** Running evaluation *****
04/23 05:17:52 PM   Epoch = 2 iter 13699 step
04/23 05:17:52 PM   Num examples = 1043
04/23 05:17:52 PM   Batch size = 32
04/23 05:17:52 PM ***** Eval results *****
04/23 05:17:52 PM   att_loss = 0.42424729190615446
04/23 05:17:52 PM   cls_loss = 0.0
04/23 05:17:52 PM   global_step = 13699
04/23 05:17:52 PM   loss = 1.1304214444709417
04/23 05:17:52 PM   rep_loss = 0.7061741524302394
04/23 05:17:52 PM ***** Save model *****
04/23 05:18:01 PM ***** Running evaluation *****
04/23 05:18:01 PM   Epoch = 2 iter 13749 step
04/23 05:18:01 PM   Num examples = 1043
04/23 05:18:01 PM   Batch size = 32
04/23 05:18:01 PM ***** Eval results *****
04/23 05:18:01 PM   att_loss = 0.42569987497029876
04/23 05:18:01 PM   cls_loss = 0.0
04/23 05:18:01 PM   global_step = 13749
04/23 05:18:01 PM   loss = 1.1321168124796652
04/23 05:18:01 PM   rep_loss = 0.7064169374489155
04/23 05:18:01 PM ***** Save model *****
04/23 05:18:09 PM ***** Running evaluation *****
04/23 05:18:09 PM   Epoch = 2 iter 13799 step
04/23 05:18:09 PM   Num examples = 1043
04/23 05:18:09 PM   Batch size = 32
04/23 05:18:09 PM ***** Eval results *****
04/23 05:18:09 PM   att_loss = 0.4250040908874069
04/23 05:18:09 PM   cls_loss = 0.0
04/23 05:18:09 PM   global_step = 13799
04/23 05:18:09 PM   loss = 1.1310597175173118
04/23 05:18:09 PM   rep_loss = 0.706055627014097
04/23 05:18:09 PM ***** Save model *****
04/23 05:18:17 PM ***** Running evaluation *****
04/23 05:18:17 PM   Epoch = 2 iter 13849 step
04/23 05:18:17 PM   Num examples = 1043
04/23 05:18:17 PM   Batch size = 32
04/23 05:18:17 PM ***** Eval results *****
04/23 05:18:17 PM   att_loss = 0.425420567921
04/23 05:18:17 PM   cls_loss = 0.0
04/23 05:18:17 PM   global_step = 13849
04/23 05:18:17 PM   loss = 1.1314556144341248
04/23 05:18:17 PM   rep_loss = 0.7060350471162072
04/23 05:18:17 PM ***** Save model *****
04/23 05:18:25 PM ***** Running evaluation *****
04/23 05:18:25 PM   Epoch = 2 iter 13899 step
04/23 05:18:25 PM   Num examples = 1043
04/23 05:18:25 PM   Batch size = 32
04/23 05:18:25 PM ***** Eval results *****
04/23 05:18:25 PM   att_loss = 0.4254354441981664
04/23 05:18:25 PM   cls_loss = 0.0
04/23 05:18:25 PM   global_step = 13899
04/23 05:18:25 PM   loss = 1.131625236471185
04/23 05:18:25 PM   rep_loss = 0.7061897930609494
04/23 05:18:25 PM ***** Save model *****
04/23 05:18:33 PM ***** Running evaluation *****
04/23 05:18:33 PM   Epoch = 2 iter 13949 step
04/23 05:18:33 PM   Num examples = 1043
04/23 05:18:33 PM   Batch size = 32
04/23 05:18:33 PM ***** Eval results *****
04/23 05:18:33 PM   att_loss = 0.4253567095958825
04/23 05:18:33 PM   cls_loss = 0.0
04/23 05:18:33 PM   global_step = 13949
04/23 05:18:33 PM   loss = 1.1315023224763197
04/23 05:18:33 PM   rep_loss = 0.7061456132244754
04/23 05:18:33 PM ***** Save model *****
04/23 05:18:41 PM ***** Running evaluation *****
04/23 05:18:41 PM   Epoch = 2 iter 13999 step
04/23 05:18:41 PM   Num examples = 1043
04/23 05:18:41 PM   Batch size = 32
04/23 05:18:41 PM ***** Eval results *****
04/23 05:18:41 PM   att_loss = 0.42505724706046516
04/23 05:18:41 PM   cls_loss = 0.0
04/23 05:18:41 PM   global_step = 13999
04/23 05:18:41 PM   loss = 1.1310236502142967
04/23 05:18:41 PM   rep_loss = 0.7059664037153827
04/23 05:18:41 PM ***** Save model *****
04/23 05:18:49 PM ***** Running evaluation *****
04/23 05:18:49 PM   Epoch = 2 iter 14049 step
04/23 05:18:49 PM   Num examples = 1043
04/23 05:18:49 PM   Batch size = 32
04/23 05:18:49 PM ***** Eval results *****
04/23 05:18:49 PM   att_loss = 0.4248057393754115
04/23 05:18:49 PM   cls_loss = 0.0
04/23 05:18:49 PM   global_step = 14049
04/23 05:18:49 PM   loss = 1.1306059171092164
04/23 05:18:49 PM   rep_loss = 0.7058001782223676
04/23 05:18:49 PM ***** Save model *****
04/23 05:18:57 PM ***** Running evaluation *****
04/23 05:18:57 PM   Epoch = 2 iter 14099 step
04/23 05:18:57 PM   Num examples = 1043
04/23 05:18:57 PM   Batch size = 32
04/23 05:18:57 PM ***** Eval results *****
04/23 05:18:57 PM   att_loss = 0.424759737855599
04/23 05:18:57 PM   cls_loss = 0.0
04/23 05:18:57 PM   global_step = 14099
04/23 05:18:57 PM   loss = 1.1304771265242588
04/23 05:18:57 PM   rep_loss = 0.7057173887040126
04/23 05:18:57 PM ***** Save model *****
04/23 05:19:06 PM ***** Running evaluation *****
04/23 05:19:06 PM   Epoch = 2 iter 14149 step
04/23 05:19:06 PM   Num examples = 1043
04/23 05:19:06 PM   Batch size = 32
04/23 05:19:06 PM ***** Eval results *****
04/23 05:19:06 PM   att_loss = 0.4246359487196633
04/23 05:19:06 PM   cls_loss = 0.0
04/23 05:19:06 PM   global_step = 14149
04/23 05:19:06 PM   loss = 1.1301981639221295
04/23 05:19:06 PM   rep_loss = 0.7055622155028255
04/23 05:19:06 PM ***** Save model *****
04/23 05:19:14 PM ***** Running evaluation *****
04/23 05:19:14 PM   Epoch = 2 iter 14199 step
04/23 05:19:14 PM   Num examples = 1043
04/23 05:19:14 PM   Batch size = 32
04/23 05:19:14 PM ***** Eval results *****
04/23 05:19:14 PM   att_loss = 0.42470524334452436
04/23 05:19:14 PM   cls_loss = 0.0
04/23 05:19:14 PM   global_step = 14199
04/23 05:19:14 PM   loss = 1.1300561520352976
04/23 05:19:14 PM   rep_loss = 0.7053509094808665
04/23 05:19:14 PM ***** Save model *****
04/23 05:19:22 PM ***** Running evaluation *****
04/23 05:19:22 PM   Epoch = 2 iter 14249 step
04/23 05:19:22 PM   Num examples = 1043
04/23 05:19:22 PM   Batch size = 32
04/23 05:19:22 PM ***** Eval results *****
04/23 05:19:22 PM   att_loss = 0.4243455621351048
04/23 05:19:22 PM   cls_loss = 0.0
04/23 05:19:22 PM   global_step = 14249
04/23 05:19:22 PM   loss = 1.1295100410899366
04/23 05:19:22 PM   rep_loss = 0.7051644796451173
04/23 05:19:22 PM ***** Save model *****
04/23 05:19:30 PM ***** Running evaluation *****
04/23 05:19:30 PM   Epoch = 2 iter 14299 step
04/23 05:19:30 PM   Num examples = 1043
04/23 05:19:30 PM   Batch size = 32
04/23 05:19:30 PM ***** Eval results *****
04/23 05:19:30 PM   att_loss = 0.42465448996707555
04/23 05:19:30 PM   cls_loss = 0.0
04/23 05:19:30 PM   global_step = 14299
04/23 05:19:30 PM   loss = 1.1299765638057018
04/23 05:19:30 PM   rep_loss = 0.7053220744672466
04/23 05:19:30 PM ***** Save model *****
04/23 05:19:38 PM ***** Running evaluation *****
04/23 05:19:38 PM   Epoch = 2 iter 14349 step
04/23 05:19:38 PM   Num examples = 1043
04/23 05:19:38 PM   Batch size = 32
04/23 05:19:38 PM ***** Eval results *****
04/23 05:19:38 PM   att_loss = 0.42468446086877437
04/23 05:19:38 PM   cls_loss = 0.0
04/23 05:19:38 PM   global_step = 14349
04/23 05:19:38 PM   loss = 1.1299908946439527
04/23 05:19:38 PM   rep_loss = 0.7053064344023088
04/23 05:19:38 PM ***** Save model *****
04/23 05:19:46 PM ***** Running evaluation *****
04/23 05:19:46 PM   Epoch = 2 iter 14399 step
04/23 05:19:46 PM   Num examples = 1043
04/23 05:19:46 PM   Batch size = 32
04/23 05:19:46 PM ***** Eval results *****
04/23 05:19:46 PM   att_loss = 0.4250145118849797
04/23 05:19:46 PM   cls_loss = 0.0
04/23 05:19:46 PM   global_step = 14399
04/23 05:19:46 PM   loss = 1.1302695833374719
04/23 05:19:46 PM   rep_loss = 0.7052550720521888
04/23 05:19:46 PM ***** Save model *****
04/23 05:19:54 PM ***** Running evaluation *****
04/23 05:19:54 PM   Epoch = 2 iter 14449 step
04/23 05:19:54 PM   Num examples = 1043
04/23 05:19:54 PM   Batch size = 32
04/23 05:19:54 PM ***** Eval results *****
04/23 05:19:54 PM   att_loss = 0.42497284074641034
04/23 05:19:54 PM   cls_loss = 0.0
04/23 05:19:54 PM   global_step = 14449
04/23 05:19:54 PM   loss = 1.1301777395798394
04/23 05:19:54 PM   rep_loss = 0.7052048996328208
04/23 05:19:54 PM ***** Save model *****
04/23 05:20:02 PM ***** Running evaluation *****
04/23 05:20:02 PM   Epoch = 2 iter 14499 step
04/23 05:20:02 PM   Num examples = 1043
04/23 05:20:02 PM   Batch size = 32
04/23 05:20:02 PM ***** Eval results *****
04/23 05:20:02 PM   att_loss = 0.4248473600859807
04/23 05:20:02 PM   cls_loss = 0.0
04/23 05:20:02 PM   global_step = 14499
04/23 05:20:02 PM   loss = 1.1299569262483862
04/23 05:20:02 PM   rep_loss = 0.7051095668577131
04/23 05:20:02 PM ***** Save model *****
04/23 05:20:11 PM ***** Running evaluation *****
04/23 05:20:11 PM   Epoch = 2 iter 14549 step
04/23 05:20:11 PM   Num examples = 1043
04/23 05:20:11 PM   Batch size = 32
04/23 05:20:11 PM ***** Eval results *****
04/23 05:20:11 PM   att_loss = 0.42494523209467105
04/23 05:20:11 PM   cls_loss = 0.0
04/23 05:20:11 PM   global_step = 14549
04/23 05:20:11 PM   loss = 1.1299378481007138
04/23 05:20:11 PM   rep_loss = 0.704992616720561
04/23 05:20:11 PM ***** Save model *****
04/23 05:20:19 PM ***** Running evaluation *****
04/23 05:20:19 PM   Epoch = 2 iter 14599 step
04/23 05:20:19 PM   Num examples = 1043
04/23 05:20:19 PM   Batch size = 32
04/23 05:20:19 PM ***** Eval results *****
04/23 05:20:19 PM   att_loss = 0.42481411814867165
04/23 05:20:19 PM   cls_loss = 0.0
04/23 05:20:19 PM   global_step = 14599
04/23 05:20:19 PM   loss = 1.1298440737415407
04/23 05:20:19 PM   rep_loss = 0.7050299563251674
04/23 05:20:19 PM ***** Save model *****
04/23 05:20:27 PM ***** Running evaluation *****
04/23 05:20:27 PM   Epoch = 2 iter 14649 step
04/23 05:20:27 PM   Num examples = 1043
04/23 05:20:27 PM   Batch size = 32
04/23 05:20:27 PM ***** Eval results *****
04/23 05:20:27 PM   att_loss = 0.4248679744752294
04/23 05:20:27 PM   cls_loss = 0.0
04/23 05:20:27 PM   global_step = 14649
04/23 05:20:27 PM   loss = 1.1298850061905443
04/23 05:20:27 PM   rep_loss = 0.705017032335751
04/23 05:20:27 PM ***** Save model *****
04/23 05:20:35 PM ***** Running evaluation *****
04/23 05:20:35 PM   Epoch = 2 iter 14699 step
04/23 05:20:35 PM   Num examples = 1043
04/23 05:20:35 PM   Batch size = 32
04/23 05:20:35 PM ***** Eval results *****
04/23 05:20:35 PM   att_loss = 0.42491018739080394
04/23 05:20:35 PM   cls_loss = 0.0
04/23 05:20:35 PM   global_step = 14699
04/23 05:20:35 PM   loss = 1.1298886739125453
04/23 05:20:35 PM   rep_loss = 0.7049784872239444
04/23 05:20:35 PM ***** Save model *****
04/23 05:20:43 PM ***** Running evaluation *****
04/23 05:20:43 PM   Epoch = 2 iter 14749 step
04/23 05:20:43 PM   Num examples = 1043
04/23 05:20:43 PM   Batch size = 32
04/23 05:20:43 PM ***** Eval results *****
04/23 05:20:43 PM   att_loss = 0.4245111182761208
04/23 05:20:43 PM   cls_loss = 0.0
04/23 05:20:43 PM   global_step = 14749
04/23 05:20:43 PM   loss = 1.1291678220891985
04/23 05:20:43 PM   rep_loss = 0.7046567043520345
04/23 05:20:43 PM ***** Save model *****
04/23 05:20:51 PM ***** Running evaluation *****
04/23 05:20:51 PM   Epoch = 2 iter 14799 step
04/23 05:20:51 PM   Num examples = 1043
04/23 05:20:51 PM   Batch size = 32
04/23 05:20:51 PM ***** Eval results *****
04/23 05:20:51 PM   att_loss = 0.42468738837900366
04/23 05:20:51 PM   cls_loss = 0.0
04/23 05:20:51 PM   global_step = 14799
04/23 05:20:51 PM   loss = 1.1292350299931624
04/23 05:20:51 PM   rep_loss = 0.7045476420777074
04/23 05:20:51 PM ***** Save model *****
04/23 05:20:59 PM ***** Running evaluation *****
04/23 05:20:59 PM   Epoch = 2 iter 14849 step
04/23 05:20:59 PM   Num examples = 1043
04/23 05:20:59 PM   Batch size = 32
04/23 05:20:59 PM ***** Eval results *****
04/23 05:20:59 PM   att_loss = 0.4248773087253379
04/23 05:20:59 PM   cls_loss = 0.0
04/23 05:20:59 PM   global_step = 14849
04/23 05:20:59 PM   loss = 1.1293913238989954
04/23 05:20:59 PM   rep_loss = 0.7045140158284481
04/23 05:20:59 PM ***** Save model *****
04/23 05:21:07 PM ***** Running evaluation *****
04/23 05:21:07 PM   Epoch = 2 iter 14899 step
04/23 05:21:07 PM   Num examples = 1043
04/23 05:21:07 PM   Batch size = 32
04/23 05:21:07 PM ***** Eval results *****
04/23 05:21:07 PM   att_loss = 0.4247278407515365
04/23 05:21:07 PM   cls_loss = 0.0
04/23 05:21:07 PM   global_step = 14899
04/23 05:21:07 PM   loss = 1.129075608598845
04/23 05:21:07 PM   rep_loss = 0.7043477684277554
04/23 05:21:07 PM ***** Save model *****
04/23 05:21:15 PM ***** Running evaluation *****
04/23 05:21:15 PM   Epoch = 2 iter 14949 step
04/23 05:21:15 PM   Num examples = 1043
04/23 05:21:15 PM   Batch size = 32
04/23 05:21:15 PM ***** Eval results *****
04/23 05:21:15 PM   att_loss = 0.4247208060735228
04/23 05:21:15 PM   cls_loss = 0.0
04/23 05:21:15 PM   global_step = 14949
04/23 05:21:15 PM   loss = 1.1288777322932524
04/23 05:21:15 PM   rep_loss = 0.7041569271174959
04/23 05:21:15 PM ***** Save model *****
04/23 05:21:24 PM ***** Running evaluation *****
04/23 05:21:24 PM   Epoch = 2 iter 14999 step
04/23 05:21:24 PM   Num examples = 1043
04/23 05:21:24 PM   Batch size = 32
04/23 05:21:24 PM ***** Eval results *****
04/23 05:21:24 PM   att_loss = 0.42476031666368297
04/23 05:21:24 PM   cls_loss = 0.0
04/23 05:21:24 PM   global_step = 14999
04/23 05:21:24 PM   loss = 1.1287988013258217
04/23 05:21:24 PM   rep_loss = 0.7040384855341515
04/23 05:21:24 PM ***** Save model *****
04/23 05:21:32 PM ***** Running evaluation *****
04/23 05:21:32 PM   Epoch = 2 iter 15049 step
04/23 05:21:32 PM   Num examples = 1043
04/23 05:21:32 PM   Batch size = 32
04/23 05:21:32 PM ***** Eval results *****
04/23 05:21:32 PM   att_loss = 0.4247679971345496
04/23 05:21:32 PM   cls_loss = 0.0
04/23 05:21:32 PM   global_step = 15049
04/23 05:21:32 PM   loss = 1.1287920900516117
04/23 05:21:32 PM   rep_loss = 0.7040240935154355
04/23 05:21:32 PM ***** Save model *****
04/23 05:21:40 PM ***** Running evaluation *****
04/23 05:21:40 PM   Epoch = 2 iter 15099 step
04/23 05:21:40 PM   Num examples = 1043
04/23 05:21:40 PM   Batch size = 32
04/23 05:21:40 PM ***** Eval results *****
04/23 05:21:40 PM   att_loss = 0.4247640002472402
04/23 05:21:40 PM   cls_loss = 0.0
04/23 05:21:40 PM   global_step = 15099
04/23 05:21:40 PM   loss = 1.128734685064203
04/23 05:21:40 PM   rep_loss = 0.7039706856740019
04/23 05:21:40 PM ***** Save model *****
04/23 05:21:48 PM ***** Running evaluation *****
04/23 05:21:48 PM   Epoch = 2 iter 15149 step
04/23 05:21:48 PM   Num examples = 1043
04/23 05:21:48 PM   Batch size = 32
04/23 05:21:48 PM ***** Eval results *****
04/23 05:21:48 PM   att_loss = 0.4247599670135087
04/23 05:21:48 PM   cls_loss = 0.0
04/23 05:21:48 PM   global_step = 15149
04/23 05:21:48 PM   loss = 1.1286776812065233
04/23 05:21:48 PM   rep_loss = 0.7039177149486995
04/23 05:21:48 PM ***** Save model *****
04/23 05:21:56 PM ***** Running evaluation *****
04/23 05:21:56 PM   Epoch = 2 iter 15199 step
04/23 05:21:56 PM   Num examples = 1043
04/23 05:21:56 PM   Batch size = 32
04/23 05:21:56 PM ***** Eval results *****
04/23 05:21:56 PM   att_loss = 0.42460918938812986
04/23 05:21:56 PM   cls_loss = 0.0
04/23 05:21:56 PM   global_step = 15199
04/23 05:21:56 PM   loss = 1.1285266111452925
04/23 05:21:56 PM   rep_loss = 0.7039174223706947
04/23 05:21:56 PM ***** Save model *****
04/23 05:22:04 PM ***** Running evaluation *****
04/23 05:22:04 PM   Epoch = 2 iter 15249 step
04/23 05:22:04 PM   Num examples = 1043
04/23 05:22:04 PM   Batch size = 32
04/23 05:22:04 PM ***** Eval results *****
04/23 05:22:04 PM   att_loss = 0.4245141886970953
04/23 05:22:04 PM   cls_loss = 0.0
04/23 05:22:04 PM   global_step = 15249
04/23 05:22:04 PM   loss = 1.1284212136890681
04/23 05:22:04 PM   rep_loss = 0.7039070254405778
04/23 05:22:04 PM ***** Save model *****
04/23 05:22:12 PM ***** Running evaluation *****
04/23 05:22:12 PM   Epoch = 2 iter 15299 step
04/23 05:22:12 PM   Num examples = 1043
04/23 05:22:12 PM   Batch size = 32
04/23 05:22:12 PM ***** Eval results *****
04/23 05:22:12 PM   att_loss = 0.4243779320140359
04/23 05:22:12 PM   cls_loss = 0.0
04/23 05:22:12 PM   global_step = 15299
04/23 05:22:12 PM   loss = 1.12813778184409
04/23 05:22:12 PM   rep_loss = 0.7037598503552053
04/23 05:22:12 PM ***** Save model *****
04/23 05:22:21 PM ***** Running evaluation *****
04/23 05:22:21 PM   Epoch = 2 iter 15349 step
04/23 05:22:21 PM   Num examples = 1043
04/23 05:22:21 PM   Batch size = 32
04/23 05:22:21 PM ***** Eval results *****
04/23 05:22:21 PM   att_loss = 0.4242887879124225
04/23 05:22:21 PM   cls_loss = 0.0
04/23 05:22:21 PM   global_step = 15349
04/23 05:22:21 PM   loss = 1.1279673840916447
04/23 05:22:21 PM   rep_loss = 0.7036785967203059
04/23 05:22:21 PM ***** Save model *****
04/23 05:22:29 PM ***** Running evaluation *****
04/23 05:22:29 PM   Epoch = 2 iter 15399 step
04/23 05:22:29 PM   Num examples = 1043
04/23 05:22:29 PM   Batch size = 32
04/23 05:22:29 PM ***** Eval results *****
04/23 05:22:29 PM   att_loss = 0.4243026361585609
04/23 05:22:29 PM   cls_loss = 0.0
04/23 05:22:29 PM   global_step = 15399
04/23 05:22:29 PM   loss = 1.1279431972278928
04/23 05:22:29 PM   rep_loss = 0.7036405615699776
04/23 05:22:29 PM ***** Save model *****
04/23 05:22:37 PM ***** Running evaluation *****
04/23 05:22:37 PM   Epoch = 2 iter 15449 step
04/23 05:22:37 PM   Num examples = 1043
04/23 05:22:37 PM   Batch size = 32
04/23 05:22:37 PM ***** Eval results *****
04/23 05:22:37 PM   att_loss = 0.42440749990902044
04/23 05:22:37 PM   cls_loss = 0.0
04/23 05:22:37 PM   global_step = 15449
04/23 05:22:37 PM   loss = 1.128001873617133
04/23 05:22:37 PM   rep_loss = 0.7035943739391385
04/23 05:22:37 PM ***** Save model *****
04/23 05:22:45 PM ***** Running evaluation *****
04/23 05:22:45 PM   Epoch = 2 iter 15499 step
04/23 05:22:45 PM   Num examples = 1043
04/23 05:22:45 PM   Batch size = 32
04/23 05:22:45 PM ***** Eval results *****
04/23 05:22:45 PM   att_loss = 0.4242285036424202
04/23 05:22:45 PM   cls_loss = 0.0
04/23 05:22:45 PM   global_step = 15499
04/23 05:22:45 PM   loss = 1.1277131741726127
04/23 05:22:45 PM   rep_loss = 0.7034846709022233
04/23 05:22:45 PM ***** Save model *****
04/23 05:22:53 PM ***** Running evaluation *****
04/23 05:22:53 PM   Epoch = 2 iter 15549 step
04/23 05:22:53 PM   Num examples = 1043
04/23 05:22:53 PM   Batch size = 32
04/23 05:22:53 PM ***** Eval results *****
04/23 05:22:53 PM   att_loss = 0.42391249840300105
04/23 05:22:53 PM   cls_loss = 0.0
04/23 05:22:53 PM   global_step = 15549
04/23 05:22:53 PM   loss = 1.1273454605779218
04/23 05:22:53 PM   rep_loss = 0.7034329626428161
04/23 05:22:53 PM ***** Save model *****
04/23 05:23:01 PM ***** Running evaluation *****
04/23 05:23:01 PM   Epoch = 2 iter 15599 step
04/23 05:23:01 PM   Num examples = 1043
04/23 05:23:01 PM   Batch size = 32
04/23 05:23:01 PM ***** Eval results *****
04/23 05:23:01 PM   att_loss = 0.4237636390197394
04/23 05:23:01 PM   cls_loss = 0.0
04/23 05:23:01 PM   global_step = 15599
04/23 05:23:01 PM   loss = 1.1270955221244936
04/23 05:23:01 PM   rep_loss = 0.7033318836517025
04/23 05:23:01 PM ***** Save model *****
04/23 05:23:09 PM ***** Running evaluation *****
04/23 05:23:09 PM   Epoch = 2 iter 15649 step
04/23 05:23:09 PM   Num examples = 1043
04/23 05:23:09 PM   Batch size = 32
04/23 05:23:09 PM ***** Eval results *****
04/23 05:23:09 PM   att_loss = 0.4237486173356371
04/23 05:23:09 PM   cls_loss = 0.0
04/23 05:23:09 PM   global_step = 15649
04/23 05:23:09 PM   loss = 1.1270356239308088
04/23 05:23:09 PM   rep_loss = 0.7032870071431457
04/23 05:23:09 PM ***** Save model *****
04/23 05:23:17 PM ***** Running evaluation *****
04/23 05:23:17 PM   Epoch = 2 iter 15699 step
04/23 05:23:17 PM   Num examples = 1043
04/23 05:23:17 PM   Batch size = 32
04/23 05:23:17 PM ***** Eval results *****
04/23 05:23:17 PM   att_loss = 0.42383931764461347
04/23 05:23:17 PM   cls_loss = 0.0
04/23 05:23:17 PM   global_step = 15699
04/23 05:23:17 PM   loss = 1.1271355616426644
04/23 05:23:17 PM   rep_loss = 0.7032962444860136
04/23 05:23:17 PM ***** Save model *****
04/23 05:23:25 PM ***** Running evaluation *****
04/23 05:23:25 PM   Epoch = 2 iter 15749 step
04/23 05:23:25 PM   Num examples = 1043
04/23 05:23:25 PM   Batch size = 32
04/23 05:23:25 PM ***** Eval results *****
04/23 05:23:25 PM   att_loss = 0.42370839532340715
04/23 05:23:25 PM   cls_loss = 0.0
04/23 05:23:25 PM   global_step = 15749
04/23 05:23:25 PM   loss = 1.1269375657011982
04/23 05:23:25 PM   rep_loss = 0.7032291706527423
04/23 05:23:25 PM ***** Save model *****
04/23 05:23:34 PM ***** Running evaluation *****
04/23 05:23:34 PM   Epoch = 2 iter 15799 step
04/23 05:23:34 PM   Num examples = 1043
04/23 05:23:34 PM   Batch size = 32
04/23 05:23:34 PM ***** Eval results *****
04/23 05:23:34 PM   att_loss = 0.42380573069350813
04/23 05:23:34 PM   cls_loss = 0.0
04/23 05:23:34 PM   global_step = 15799
04/23 05:23:34 PM   loss = 1.1270027265884348
04/23 05:23:34 PM   rep_loss = 0.7031969962699461
04/23 05:23:34 PM ***** Save model *****
04/23 05:23:42 PM ***** Running evaluation *****
04/23 05:23:42 PM   Epoch = 2 iter 15849 step
04/23 05:23:42 PM   Num examples = 1043
04/23 05:23:42 PM   Batch size = 32
04/23 05:23:42 PM ***** Eval results *****
04/23 05:23:42 PM   att_loss = 0.4237052124069779
04/23 05:23:42 PM   cls_loss = 0.0
04/23 05:23:42 PM   global_step = 15849
04/23 05:23:42 PM   loss = 1.1268269449552881
04/23 05:23:42 PM   rep_loss = 0.7031217329160983
04/23 05:23:42 PM ***** Save model *****
04/23 05:23:50 PM ***** Running evaluation *****
04/23 05:23:50 PM   Epoch = 2 iter 15899 step
04/23 05:23:50 PM   Num examples = 1043
04/23 05:23:50 PM   Batch size = 32
04/23 05:23:50 PM ***** Eval results *****
04/23 05:23:50 PM   att_loss = 0.4235308332917729
04/23 05:23:50 PM   cls_loss = 0.0
04/23 05:23:50 PM   global_step = 15899
04/23 05:23:50 PM   loss = 1.1264754784319195
04/23 05:23:50 PM   rep_loss = 0.7029446456137364
04/23 05:23:50 PM ***** Save model *****
04/23 05:23:58 PM ***** Running evaluation *****
04/23 05:23:58 PM   Epoch = 2 iter 15949 step
04/23 05:23:58 PM   Num examples = 1043
04/23 05:23:58 PM   Batch size = 32
04/23 05:23:58 PM ***** Eval results *****
04/23 05:23:58 PM   att_loss = 0.4234856333468778
04/23 05:23:58 PM   cls_loss = 0.0
04/23 05:23:58 PM   global_step = 15949
04/23 05:23:58 PM   loss = 1.1263852519834967
04/23 05:23:58 PM   rep_loss = 0.7028996193227474
04/23 05:23:58 PM ***** Save model *****
04/23 05:24:06 PM ***** Running evaluation *****
04/23 05:24:06 PM   Epoch = 2 iter 15999 step
04/23 05:24:06 PM   Num examples = 1043
04/23 05:24:06 PM   Batch size = 32
04/23 05:24:06 PM ***** Eval results *****
04/23 05:24:06 PM   att_loss = 0.42352900399024845
04/23 05:24:06 PM   cls_loss = 0.0
04/23 05:24:06 PM   global_step = 15999
04/23 05:24:06 PM   loss = 1.1263984602774488
04/23 05:24:06 PM   rep_loss = 0.7028694568087139
04/23 05:24:06 PM ***** Save model *****
04/23 05:24:14 PM ***** Running evaluation *****
04/23 05:24:14 PM   Epoch = 2 iter 16049 step
04/23 05:24:14 PM   Num examples = 1043
04/23 05:24:14 PM   Batch size = 32
04/23 05:24:14 PM ***** Eval results *****
04/23 05:24:14 PM   att_loss = 0.4235815051909719
04/23 05:24:14 PM   cls_loss = 0.0
04/23 05:24:14 PM   global_step = 16049
04/23 05:24:14 PM   loss = 1.1264750052002055
04/23 05:24:14 PM   rep_loss = 0.702893500404037
04/23 05:24:14 PM ***** Save model *****
04/23 05:24:22 PM ***** Running evaluation *****
04/23 05:24:22 PM   Epoch = 2 iter 16099 step
04/23 05:24:22 PM   Num examples = 1043
04/23 05:24:22 PM   Batch size = 32
04/23 05:24:22 PM ***** Eval results *****
04/23 05:24:22 PM   att_loss = 0.42359241096855177
04/23 05:24:22 PM   cls_loss = 0.0
04/23 05:24:22 PM   global_step = 16099
04/23 05:24:22 PM   loss = 1.1264368101320257
04/23 05:24:22 PM   rep_loss = 0.7028443996142301
04/23 05:24:22 PM ***** Save model *****
04/23 05:24:30 PM ***** Running evaluation *****
04/23 05:24:30 PM   Epoch = 2 iter 16149 step
04/23 05:24:30 PM   Num examples = 1043
04/23 05:24:30 PM   Batch size = 32
04/23 05:24:30 PM ***** Eval results *****
04/23 05:24:30 PM   att_loss = 0.42359710515390164
04/23 05:24:30 PM   cls_loss = 0.0
04/23 05:24:30 PM   global_step = 16149
04/23 05:24:30 PM   loss = 1.126428305525867
04/23 05:24:30 PM   rep_loss = 0.7028312008355342
04/23 05:24:30 PM ***** Save model *****
04/23 05:24:39 PM ***** Running evaluation *****
04/23 05:24:39 PM   Epoch = 2 iter 16199 step
04/23 05:24:39 PM   Num examples = 1043
04/23 05:24:39 PM   Batch size = 32
04/23 05:24:39 PM ***** Eval results *****
04/23 05:24:39 PM   att_loss = 0.42356244543762867
04/23 05:24:39 PM   cls_loss = 0.0
04/23 05:24:39 PM   global_step = 16199
04/23 05:24:39 PM   loss = 1.126278442324646
04/23 05:24:39 PM   rep_loss = 0.7027159972616981
04/23 05:24:39 PM ***** Save model *****
04/23 05:24:47 PM ***** Running evaluation *****
04/23 05:24:47 PM   Epoch = 2 iter 16249 step
04/23 05:24:47 PM   Num examples = 1043
04/23 05:24:47 PM   Batch size = 32
04/23 05:24:47 PM ***** Eval results *****
04/23 05:24:47 PM   att_loss = 0.42373095882444767
04/23 05:24:47 PM   cls_loss = 0.0
04/23 05:24:47 PM   global_step = 16249
04/23 05:24:47 PM   loss = 1.1264367952539576
04/23 05:24:47 PM   rep_loss = 0.7027058366386141
04/23 05:24:47 PM ***** Save model *****
04/23 05:24:55 PM ***** Running evaluation *****
04/23 05:24:55 PM   Epoch = 2 iter 16299 step
04/23 05:24:55 PM   Num examples = 1043
04/23 05:24:55 PM   Batch size = 32
04/23 05:24:55 PM ***** Eval results *****
04/23 05:24:55 PM   att_loss = 0.42373566037136356
04/23 05:24:55 PM   cls_loss = 0.0
04/23 05:24:55 PM   global_step = 16299
04/23 05:24:55 PM   loss = 1.126386414751817
04/23 05:24:55 PM   rep_loss = 0.7026507545959154
04/23 05:24:55 PM ***** Save model *****
04/23 05:25:03 PM ***** Running evaluation *****
04/23 05:25:03 PM   Epoch = 2 iter 16349 step
04/23 05:25:03 PM   Num examples = 1043
04/23 05:25:03 PM   Batch size = 32
04/23 05:25:03 PM ***** Eval results *****
04/23 05:25:03 PM   att_loss = 0.42369551111146386
04/23 05:25:03 PM   cls_loss = 0.0
04/23 05:25:03 PM   global_step = 16349
04/23 05:25:03 PM   loss = 1.1262453505609786
04/23 05:25:03 PM   rep_loss = 0.7025498396518582
04/23 05:25:03 PM ***** Save model *****
04/23 05:25:11 PM ***** Running evaluation *****
04/23 05:25:11 PM   Epoch = 2 iter 16399 step
04/23 05:25:11 PM   Num examples = 1043
04/23 05:25:11 PM   Batch size = 32
04/23 05:25:11 PM ***** Eval results *****
04/23 05:25:11 PM   att_loss = 0.42343466180621764
04/23 05:25:11 PM   cls_loss = 0.0
04/23 05:25:11 PM   global_step = 16399
04/23 05:25:11 PM   loss = 1.1258284256900528
04/23 05:25:11 PM   rep_loss = 0.7023937639976208
04/23 05:25:11 PM ***** Save model *****
04/23 05:25:19 PM ***** Running evaluation *****
04/23 05:25:19 PM   Epoch = 2 iter 16449 step
04/23 05:25:19 PM   Num examples = 1043
04/23 05:25:19 PM   Batch size = 32
04/23 05:25:19 PM ***** Eval results *****
04/23 05:25:19 PM   att_loss = 0.42348258656989507
04/23 05:25:19 PM   cls_loss = 0.0
04/23 05:25:19 PM   global_step = 16449
04/23 05:25:19 PM   loss = 1.1258442882568604
04/23 05:25:19 PM   rep_loss = 0.7023617017056327
04/23 05:25:19 PM ***** Save model *****
04/23 05:25:27 PM ***** Running evaluation *****
04/23 05:25:27 PM   Epoch = 2 iter 16499 step
04/23 05:25:27 PM   Num examples = 1043
04/23 05:25:27 PM   Batch size = 32
04/23 05:25:27 PM ***** Eval results *****
04/23 05:25:27 PM   att_loss = 0.4233424788799839
04/23 05:25:27 PM   cls_loss = 0.0
04/23 05:25:27 PM   global_step = 16499
04/23 05:25:27 PM   loss = 1.1255546580521074
04/23 05:25:27 PM   rep_loss = 0.7022121792915902
04/23 05:25:27 PM ***** Save model *****
04/23 05:25:35 PM ***** Running evaluation *****
04/23 05:25:35 PM   Epoch = 2 iter 16549 step
04/23 05:25:35 PM   Num examples = 1043
04/23 05:25:35 PM   Batch size = 32
04/23 05:25:35 PM ***** Eval results *****
04/23 05:25:35 PM   att_loss = 0.4231558224729879
04/23 05:25:35 PM   cls_loss = 0.0
04/23 05:25:35 PM   global_step = 16549
04/23 05:25:35 PM   loss = 1.1253068427202588
04/23 05:25:35 PM   rep_loss = 0.7021510204644758
04/23 05:25:35 PM ***** Save model *****
04/23 05:25:44 PM ***** Running evaluation *****
04/23 05:25:44 PM   Epoch = 2 iter 16599 step
04/23 05:25:44 PM   Num examples = 1043
04/23 05:25:44 PM   Batch size = 32
04/23 05:25:44 PM ***** Eval results *****
04/23 05:25:44 PM   att_loss = 0.4232706608456336
04/23 05:25:44 PM   cls_loss = 0.0
04/23 05:25:44 PM   global_step = 16599
04/23 05:25:44 PM   loss = 1.1254205333591043
04/23 05:25:44 PM   rep_loss = 0.7021498727898308
04/23 05:25:44 PM ***** Save model *****
04/23 05:25:52 PM ***** Running evaluation *****
04/23 05:25:52 PM   Epoch = 2 iter 16649 step
04/23 05:25:52 PM   Num examples = 1043
04/23 05:25:52 PM   Batch size = 32
04/23 05:25:52 PM ***** Eval results *****
04/23 05:25:52 PM   att_loss = 0.4233092310380837
04/23 05:25:52 PM   cls_loss = 0.0
04/23 05:25:52 PM   global_step = 16649
04/23 05:25:52 PM   loss = 1.1254224215079436
04/23 05:25:52 PM   rep_loss = 0.7021131908826831
04/23 05:25:52 PM ***** Save model *****
04/23 05:26:00 PM ***** Running evaluation *****
04/23 05:26:00 PM   Epoch = 2 iter 16699 step
04/23 05:26:00 PM   Num examples = 1043
04/23 05:26:00 PM   Batch size = 32
04/23 05:26:00 PM ***** Eval results *****
04/23 05:26:00 PM   att_loss = 0.4234418787133579
04/23 05:26:00 PM   cls_loss = 0.0
04/23 05:26:00 PM   global_step = 16699
04/23 05:26:00 PM   loss = 1.1255227440566196
04/23 05:26:00 PM   rep_loss = 0.7020808656721865
04/23 05:26:00 PM ***** Save model *****
04/23 05:26:08 PM ***** Running evaluation *****
04/23 05:26:08 PM   Epoch = 2 iter 16749 step
04/23 05:26:08 PM   Num examples = 1043
04/23 05:26:08 PM   Batch size = 32
04/23 05:26:08 PM ***** Eval results *****
04/23 05:26:08 PM   att_loss = 0.42340103545162966
04/23 05:26:08 PM   cls_loss = 0.0
04/23 05:26:08 PM   global_step = 16749
04/23 05:26:08 PM   loss = 1.1253936513938434
04/23 05:26:08 PM   rep_loss = 0.7019926163688144
04/23 05:26:08 PM ***** Save model *****
04/23 05:26:16 PM ***** Running evaluation *****
04/23 05:26:16 PM   Epoch = 2 iter 16799 step
04/23 05:26:16 PM   Num examples = 1043
04/23 05:26:16 PM   Batch size = 32
04/23 05:26:16 PM ***** Eval results *****
04/23 05:26:16 PM   att_loss = 0.4233906262091853
04/23 05:26:16 PM   cls_loss = 0.0
04/23 05:26:16 PM   global_step = 16799
04/23 05:26:16 PM   loss = 1.1252979774647367
04/23 05:26:16 PM   rep_loss = 0.7019073516004273
04/23 05:26:16 PM ***** Save model *****
04/23 05:26:24 PM ***** Running evaluation *****
04/23 05:26:24 PM   Epoch = 2 iter 16849 step
04/23 05:26:24 PM   Num examples = 1043
04/23 05:26:24 PM   Batch size = 32
04/23 05:26:24 PM ***** Eval results *****
04/23 05:26:24 PM   att_loss = 0.42345841971739
04/23 05:26:24 PM   cls_loss = 0.0
04/23 05:26:24 PM   global_step = 16849
04/23 05:26:24 PM   loss = 1.1253317661216389
04/23 05:26:24 PM   rep_loss = 0.701873346901922
04/23 05:26:24 PM ***** Save model *****
04/23 05:26:32 PM ***** Running evaluation *****
04/23 05:26:32 PM   Epoch = 2 iter 16899 step
04/23 05:26:32 PM   Num examples = 1043
04/23 05:26:32 PM   Batch size = 32
04/23 05:26:32 PM ***** Eval results *****
04/23 05:26:32 PM   att_loss = 0.42342900914083037
04/23 05:26:32 PM   cls_loss = 0.0
04/23 05:26:32 PM   global_step = 16899
04/23 05:26:32 PM   loss = 1.1252254332090321
04/23 05:26:32 PM   rep_loss = 0.7017964246244899
04/23 05:26:32 PM ***** Save model *****
04/23 05:26:40 PM ***** Running evaluation *****
04/23 05:26:40 PM   Epoch = 2 iter 16949 step
04/23 05:26:40 PM   Num examples = 1043
04/23 05:26:40 PM   Batch size = 32
04/23 05:26:40 PM ***** Eval results *****
04/23 05:26:40 PM   att_loss = 0.4234371963891433
04/23 05:26:40 PM   cls_loss = 0.0
04/23 05:26:40 PM   global_step = 16949
04/23 05:26:40 PM   loss = 1.1251767446702325
04/23 05:26:40 PM   rep_loss = 0.7017395488944055
04/23 05:26:40 PM ***** Save model *****
04/23 05:26:48 PM ***** Running evaluation *****
04/23 05:26:48 PM   Epoch = 2 iter 16999 step
04/23 05:26:48 PM   Num examples = 1043
04/23 05:26:48 PM   Batch size = 32
04/23 05:26:48 PM ***** Eval results *****
04/23 05:26:48 PM   att_loss = 0.42342227274582345
04/23 05:26:48 PM   cls_loss = 0.0
04/23 05:26:48 PM   global_step = 16999
04/23 05:26:48 PM   loss = 1.125080804215884
04/23 05:26:48 PM   rep_loss = 0.7016585319716759
04/23 05:26:48 PM ***** Save model *****
04/23 05:26:57 PM ***** Running evaluation *****
04/23 05:26:57 PM   Epoch = 2 iter 17049 step
04/23 05:26:57 PM   Num examples = 1043
04/23 05:26:57 PM   Batch size = 32
04/23 05:26:57 PM ***** Eval results *****
04/23 05:26:57 PM   att_loss = 0.42341419425074794
04/23 05:26:57 PM   cls_loss = 0.0
04/23 05:26:57 PM   global_step = 17049
04/23 05:26:57 PM   loss = 1.1249870591763296
04/23 05:26:57 PM   rep_loss = 0.7015728655070137
04/23 05:26:57 PM ***** Save model *****
04/23 05:27:05 PM ***** Running evaluation *****
04/23 05:27:05 PM   Epoch = 2 iter 17099 step
04/23 05:27:05 PM   Num examples = 1043
04/23 05:27:05 PM   Batch size = 32
04/23 05:27:05 PM ***** Eval results *****
04/23 05:27:05 PM   att_loss = 0.423406009434599
04/23 05:27:05 PM   cls_loss = 0.0
04/23 05:27:05 PM   global_step = 17099
04/23 05:27:05 PM   loss = 1.1249206029838366
04/23 05:27:05 PM   rep_loss = 0.7015145941541246
04/23 05:27:05 PM ***** Save model *****
04/23 05:27:13 PM ***** Running evaluation *****
04/23 05:27:13 PM   Epoch = 2 iter 17149 step
04/23 05:27:13 PM   Num examples = 1043
04/23 05:27:13 PM   Batch size = 32
04/23 05:27:13 PM ***** Eval results *****
04/23 05:27:13 PM   att_loss = 0.42342752870483263
04/23 05:27:13 PM   cls_loss = 0.0
04/23 05:27:13 PM   global_step = 17149
04/23 05:27:13 PM   loss = 1.1249319540636722
04/23 05:27:13 PM   rep_loss = 0.7015044259100257
04/23 05:27:13 PM ***** Save model *****
04/23 05:27:21 PM ***** Running evaluation *****
04/23 05:27:21 PM   Epoch = 2 iter 17199 step
04/23 05:27:21 PM   Num examples = 1043
04/23 05:27:21 PM   Batch size = 32
04/23 05:27:21 PM ***** Eval results *****
04/23 05:27:21 PM   att_loss = 0.42350522782667743
04/23 05:27:21 PM   cls_loss = 0.0
04/23 05:27:21 PM   global_step = 17199
04/23 05:27:21 PM   loss = 1.124951490616998
04/23 05:27:21 PM   rep_loss = 0.7014462633118422
04/23 05:27:21 PM ***** Save model *****
04/23 05:27:29 PM ***** Running evaluation *****
04/23 05:27:29 PM   Epoch = 2 iter 17249 step
04/23 05:27:29 PM   Num examples = 1043
04/23 05:27:29 PM   Batch size = 32
04/23 05:27:29 PM ***** Eval results *****
04/23 05:27:29 PM   att_loss = 0.42351582379171554
04/23 05:27:29 PM   cls_loss = 0.0
04/23 05:27:29 PM   global_step = 17249
04/23 05:27:29 PM   loss = 1.124950993487986
04/23 05:27:29 PM   rep_loss = 0.7014351701664799
04/23 05:27:29 PM ***** Save model *****
04/23 05:27:37 PM ***** Running evaluation *****
04/23 05:27:37 PM   Epoch = 2 iter 17299 step
04/23 05:27:37 PM   Num examples = 1043
04/23 05:27:37 PM   Batch size = 32
04/23 05:27:37 PM ***** Eval results *****
04/23 05:27:37 PM   att_loss = 0.4234850089826591
04/23 05:27:37 PM   cls_loss = 0.0
04/23 05:27:37 PM   global_step = 17299
04/23 05:27:37 PM   loss = 1.1248600441956031
04/23 05:27:37 PM   rep_loss = 0.7013750355962536
04/23 05:27:37 PM ***** Save model *****
04/23 05:27:45 PM ***** Running evaluation *****
04/23 05:27:45 PM   Epoch = 2 iter 17349 step
04/23 05:27:45 PM   Num examples = 1043
04/23 05:27:45 PM   Batch size = 32
04/23 05:27:45 PM ***** Eval results *****
04/23 05:27:45 PM   att_loss = 0.42339943540495295
04/23 05:27:45 PM   cls_loss = 0.0
04/23 05:27:45 PM   global_step = 17349
04/23 05:27:45 PM   loss = 1.1247485187273285
04/23 05:27:45 PM   rep_loss = 0.7013490837592529
04/23 05:27:45 PM ***** Save model *****
04/23 05:27:53 PM ***** Running evaluation *****
04/23 05:27:53 PM   Epoch = 2 iter 17399 step
04/23 05:27:53 PM   Num examples = 1043
04/23 05:27:53 PM   Batch size = 32
04/23 05:27:53 PM ***** Eval results *****
04/23 05:27:53 PM   att_loss = 0.4234081752168479
04/23 05:27:53 PM   cls_loss = 0.0
04/23 05:27:53 PM   global_step = 17399
04/23 05:27:53 PM   loss = 1.1247057245170728
04/23 05:27:53 PM   rep_loss = 0.7012975497462166
04/23 05:27:53 PM ***** Save model *****
04/23 05:28:02 PM ***** Running evaluation *****
04/23 05:28:02 PM   Epoch = 2 iter 17449 step
04/23 05:28:02 PM   Num examples = 1043
04/23 05:28:02 PM   Batch size = 32
04/23 05:28:02 PM ***** Eval results *****
04/23 05:28:02 PM   att_loss = 0.42338470467485106
04/23 05:28:02 PM   cls_loss = 0.0
04/23 05:28:02 PM   global_step = 17449
04/23 05:28:02 PM   loss = 1.124630640862581
04/23 05:28:02 PM   rep_loss = 0.7012459365502195
04/23 05:28:02 PM ***** Save model *****
04/23 05:28:10 PM ***** Running evaluation *****
04/23 05:28:10 PM   Epoch = 2 iter 17499 step
04/23 05:28:10 PM   Num examples = 1043
04/23 05:28:10 PM   Batch size = 32
04/23 05:28:10 PM ***** Eval results *****
04/23 05:28:10 PM   att_loss = 0.4234117427061617
04/23 05:28:10 PM   cls_loss = 0.0
04/23 05:28:10 PM   global_step = 17499
04/23 05:28:10 PM   loss = 1.124611894420765
04/23 05:28:10 PM   rep_loss = 0.7012001521290121
04/23 05:28:10 PM ***** Save model *****
04/23 05:28:18 PM ***** Running evaluation *****
04/23 05:28:18 PM   Epoch = 2 iter 17549 step
04/23 05:28:18 PM   Num examples = 1043
04/23 05:28:18 PM   Batch size = 32
04/23 05:28:18 PM ***** Eval results *****
04/23 05:28:18 PM   att_loss = 0.4233937267029227
04/23 05:28:18 PM   cls_loss = 0.0
04/23 05:28:18 PM   global_step = 17549
04/23 05:28:18 PM   loss = 1.1245792485771828
04/23 05:28:18 PM   rep_loss = 0.7011855223254949
04/23 05:28:18 PM ***** Save model *****
04/23 05:28:26 PM ***** Running evaluation *****
04/23 05:28:26 PM   Epoch = 2 iter 17599 step
04/23 05:28:26 PM   Num examples = 1043
04/23 05:28:26 PM   Batch size = 32
04/23 05:28:26 PM ***** Eval results *****
04/23 05:28:26 PM   att_loss = 0.4234413593328139
04/23 05:28:26 PM   cls_loss = 0.0
04/23 05:28:26 PM   global_step = 17599
04/23 05:28:26 PM   loss = 1.1245976173463241
04/23 05:28:26 PM   rep_loss = 0.7011562584046529
04/23 05:28:26 PM ***** Save model *****
04/23 05:28:34 PM ***** Running evaluation *****
04/23 05:28:34 PM   Epoch = 2 iter 17649 step
04/23 05:28:34 PM   Num examples = 1043
04/23 05:28:34 PM   Batch size = 32
04/23 05:28:34 PM ***** Eval results *****
04/23 05:28:34 PM   att_loss = 0.42342010573919664
04/23 05:28:34 PM   cls_loss = 0.0
04/23 05:28:34 PM   global_step = 17649
04/23 05:28:34 PM   loss = 1.1244950333570745
04/23 05:28:34 PM   rep_loss = 0.701074927929944
04/23 05:28:34 PM ***** Save model *****
04/23 05:28:42 PM ***** Running evaluation *****
04/23 05:28:42 PM   Epoch = 2 iter 17699 step
04/23 05:28:42 PM   Num examples = 1043
04/23 05:28:42 PM   Batch size = 32
04/23 05:28:42 PM ***** Eval results *****
04/23 05:28:42 PM   att_loss = 0.42342637413905165
04/23 05:28:42 PM   cls_loss = 0.0
04/23 05:28:42 PM   global_step = 17699
04/23 05:28:42 PM   loss = 1.1244473344110406
04/23 05:28:42 PM   rep_loss = 0.7010209605738357
04/23 05:28:42 PM ***** Save model *****
04/23 05:28:50 PM ***** Running evaluation *****
04/23 05:28:50 PM   Epoch = 2 iter 17749 step
04/23 05:28:50 PM   Num examples = 1043
04/23 05:28:50 PM   Batch size = 32
04/23 05:28:50 PM ***** Eval results *****
04/23 05:28:50 PM   att_loss = 0.42341016091351624
04/23 05:28:50 PM   cls_loss = 0.0
04/23 05:28:50 PM   global_step = 17749
04/23 05:28:50 PM   loss = 1.1243782671209488
04/23 05:28:50 PM   rep_loss = 0.7009681063002954
04/23 05:28:50 PM ***** Save model *****
04/23 05:28:58 PM ***** Running evaluation *****
04/23 05:28:58 PM   Epoch = 2 iter 17799 step
04/23 05:28:58 PM   Num examples = 1043
04/23 05:28:58 PM   Batch size = 32
04/23 05:28:58 PM ***** Eval results *****
04/23 05:28:58 PM   att_loss = 0.4233941231665043
04/23 05:28:58 PM   cls_loss = 0.0
04/23 05:28:58 PM   global_step = 17799
04/23 05:28:58 PM   loss = 1.1243260621027409
04/23 05:28:58 PM   rep_loss = 0.7009319390543174
04/23 05:28:58 PM ***** Save model *****
04/23 05:29:06 PM ***** Running evaluation *****
04/23 05:29:06 PM   Epoch = 2 iter 17849 step
04/23 05:29:06 PM   Num examples = 1043
04/23 05:29:06 PM   Batch size = 32
04/23 05:29:06 PM ***** Eval results *****
04/23 05:29:06 PM   att_loss = 0.42342855394756046
04/23 05:29:06 PM   cls_loss = 0.0
04/23 05:29:06 PM   global_step = 17849
04/23 05:29:06 PM   loss = 1.1242770146057026
04/23 05:29:06 PM   rep_loss = 0.7008484607554718
04/23 05:29:06 PM ***** Save model *****
04/23 05:29:15 PM ***** Running evaluation *****
04/23 05:29:15 PM   Epoch = 2 iter 17899 step
04/23 05:29:15 PM   Num examples = 1043
04/23 05:29:15 PM   Batch size = 32
04/23 05:29:15 PM ***** Eval results *****
04/23 05:29:15 PM   att_loss = 0.42332383952417074
04/23 05:29:15 PM   cls_loss = 0.0
04/23 05:29:15 PM   global_step = 17899
04/23 05:29:15 PM   loss = 1.124132017906488
04/23 05:29:15 PM   rep_loss = 0.7008081785492052
04/23 05:29:15 PM ***** Save model *****
04/23 05:29:23 PM ***** Running evaluation *****
04/23 05:29:23 PM   Epoch = 2 iter 17949 step
04/23 05:29:23 PM   Num examples = 1043
04/23 05:29:23 PM   Batch size = 32
04/23 05:29:23 PM ***** Eval results *****
04/23 05:29:23 PM   att_loss = 0.42338876387800156
04/23 05:29:23 PM   cls_loss = 0.0
04/23 05:29:23 PM   global_step = 17949
04/23 05:29:23 PM   loss = 1.1241525060048927
04/23 05:29:23 PM   rep_loss = 0.7007637423237529
04/23 05:29:23 PM ***** Save model *****
04/23 05:29:31 PM ***** Running evaluation *****
04/23 05:29:31 PM   Epoch = 2 iter 17999 step
04/23 05:29:31 PM   Num examples = 1043
04/23 05:29:31 PM   Batch size = 32
04/23 05:29:31 PM ***** Eval results *****
04/23 05:29:31 PM   att_loss = 0.4233804040698595
04/23 05:29:31 PM   cls_loss = 0.0
04/23 05:29:31 PM   global_step = 17999
04/23 05:29:31 PM   loss = 1.1241149675134816
04/23 05:29:31 PM   rep_loss = 0.7007345636258416
04/23 05:29:31 PM ***** Save model *****
04/23 05:29:39 PM ***** Running evaluation *****
04/23 05:29:39 PM   Epoch = 2 iter 18049 step
04/23 05:29:39 PM   Num examples = 1043
04/23 05:29:39 PM   Batch size = 32
04/23 05:29:39 PM ***** Eval results *****
04/23 05:29:39 PM   att_loss = 0.42343756329558124
04/23 05:29:39 PM   cls_loss = 0.0
04/23 05:29:39 PM   global_step = 18049
04/23 05:29:39 PM   loss = 1.1241509651257304
04/23 05:29:39 PM   rep_loss = 0.7007134019420711
04/23 05:29:39 PM ***** Save model *****
04/23 05:29:47 PM ***** Running evaluation *****
04/23 05:29:47 PM   Epoch = 2 iter 18099 step
04/23 05:29:47 PM   Num examples = 1043
04/23 05:29:47 PM   Batch size = 32
04/23 05:29:47 PM ***** Eval results *****
04/23 05:29:47 PM   att_loss = 0.42341022178970683
04/23 05:29:47 PM   cls_loss = 0.0
04/23 05:29:47 PM   global_step = 18099
04/23 05:29:47 PM   loss = 1.1240695974144
04/23 05:29:47 PM   rep_loss = 0.7006593757662279
04/23 05:29:47 PM ***** Save model *****
04/23 05:29:55 PM ***** Running evaluation *****
04/23 05:29:55 PM   Epoch = 2 iter 18149 step
04/23 05:29:55 PM   Num examples = 1043
04/23 05:29:55 PM   Batch size = 32
04/23 05:29:55 PM ***** Eval results *****
04/23 05:29:55 PM   att_loss = 0.42335437444390245
04/23 05:29:55 PM   cls_loss = 0.0
04/23 05:29:55 PM   global_step = 18149
04/23 05:29:55 PM   loss = 1.123941297597396
04/23 05:29:55 PM   rep_loss = 0.7005869233118545
04/23 05:29:55 PM ***** Save model *****
04/23 05:30:03 PM ***** Running evaluation *****
04/23 05:30:03 PM   Epoch = 2 iter 18199 step
04/23 05:30:03 PM   Num examples = 1043
04/23 05:30:03 PM   Batch size = 32
04/23 05:30:03 PM ***** Eval results *****
04/23 05:30:03 PM   att_loss = 0.4234041197626016
04/23 05:30:03 PM   cls_loss = 0.0
04/23 05:30:03 PM   global_step = 18199
04/23 05:30:03 PM   loss = 1.1239606121785963
04/23 05:30:03 PM   rep_loss = 0.7005564925064328
04/23 05:30:03 PM ***** Save model *****
04/23 05:30:11 PM ***** Running evaluation *****
04/23 05:30:11 PM   Epoch = 2 iter 18249 step
04/23 05:30:11 PM   Num examples = 1043
04/23 05:30:11 PM   Batch size = 32
04/23 05:30:11 PM ***** Eval results *****
04/23 05:30:11 PM   att_loss = 0.4234778136641665
04/23 05:30:11 PM   cls_loss = 0.0
04/23 05:30:11 PM   global_step = 18249
04/23 05:30:11 PM   loss = 1.124050187797172
04/23 05:30:11 PM   rep_loss = 0.7005723741926938
04/23 05:30:11 PM ***** Save model *****
04/23 05:30:20 PM ***** Running evaluation *****
04/23 05:30:20 PM   Epoch = 2 iter 18299 step
04/23 05:30:20 PM   Num examples = 1043
04/23 05:30:20 PM   Batch size = 32
04/23 05:30:20 PM ***** Eval results *****
04/23 05:30:20 PM   att_loss = 0.42350273622942664
04/23 05:30:20 PM   cls_loss = 0.0
04/23 05:30:20 PM   global_step = 18299
04/23 05:30:20 PM   loss = 1.1240404012206526
04/23 05:30:20 PM   rep_loss = 0.7005376649498585
04/23 05:30:20 PM ***** Save model *****
04/23 05:30:28 PM ***** Running evaluation *****
04/23 05:30:28 PM   Epoch = 2 iter 18349 step
04/23 05:30:28 PM   Num examples = 1043
04/23 05:30:28 PM   Batch size = 32
04/23 05:30:28 PM ***** Eval results *****
04/23 05:30:28 PM   att_loss = 0.42346279140237786
04/23 05:30:28 PM   cls_loss = 0.0
04/23 05:30:28 PM   global_step = 18349
04/23 05:30:28 PM   loss = 1.1239060312363247
04/23 05:30:28 PM   rep_loss = 0.7004432398163919
04/23 05:30:28 PM ***** Save model *****
04/23 05:30:36 PM ***** Running evaluation *****
04/23 05:30:36 PM   Epoch = 2 iter 18399 step
04/23 05:30:36 PM   Num examples = 1043
04/23 05:30:36 PM   Batch size = 32
04/23 05:30:36 PM ***** Eval results *****
04/23 05:30:36 PM   att_loss = 0.4234012052599336
04/23 05:30:36 PM   cls_loss = 0.0
04/23 05:30:36 PM   global_step = 18399
04/23 05:30:36 PM   loss = 1.1238118536667487
04/23 05:30:36 PM   rep_loss = 0.700410648366252
04/23 05:30:36 PM ***** Save model *****
04/23 05:30:44 PM ***** Running evaluation *****
04/23 05:30:44 PM   Epoch = 2 iter 18449 step
04/23 05:30:44 PM   Num examples = 1043
04/23 05:30:44 PM   Batch size = 32
04/23 05:30:44 PM ***** Eval results *****
04/23 05:30:44 PM   att_loss = 0.42341069254759484
04/23 05:30:44 PM   cls_loss = 0.0
04/23 05:30:44 PM   global_step = 18449
04/23 05:30:44 PM   loss = 1.1237651765312093
04/23 05:30:44 PM   rep_loss = 0.700354483840141
04/23 05:30:44 PM ***** Save model *****
04/23 05:30:52 PM ***** Running evaluation *****
04/23 05:30:52 PM   Epoch = 2 iter 18499 step
04/23 05:30:52 PM   Num examples = 1043
04/23 05:30:52 PM   Batch size = 32
04/23 05:30:52 PM ***** Eval results *****
04/23 05:30:52 PM   att_loss = 0.4234056003319269
04/23 05:30:52 PM   cls_loss = 0.0
04/23 05:30:52 PM   global_step = 18499
04/23 05:30:52 PM   loss = 1.1236970413511045
04/23 05:30:52 PM   rep_loss = 0.7002914407861248
04/23 05:30:52 PM ***** Save model *****
04/23 05:31:00 PM ***** Running evaluation *****
04/23 05:31:00 PM   Epoch = 2 iter 18549 step
04/23 05:31:00 PM   Num examples = 1043
04/23 05:31:00 PM   Batch size = 32
04/23 05:31:00 PM ***** Eval results *****
04/23 05:31:00 PM   att_loss = 0.4233462945761357
04/23 05:31:00 PM   cls_loss = 0.0
04/23 05:31:00 PM   global_step = 18549
04/23 05:31:00 PM   loss = 1.1235808360425732
04/23 05:31:00 PM   rep_loss = 0.7002345412412169
04/23 05:31:00 PM ***** Save model *****
04/23 05:31:08 PM ***** Running evaluation *****
04/23 05:31:08 PM   Epoch = 2 iter 18599 step
04/23 05:31:08 PM   Num examples = 1043
04/23 05:31:08 PM   Batch size = 32
04/23 05:31:08 PM ***** Eval results *****
04/23 05:31:08 PM   att_loss = 0.4233297550363664
04/23 05:31:08 PM   cls_loss = 0.0
04/23 05:31:08 PM   global_step = 18599
04/23 05:31:08 PM   loss = 1.1235299947309556
04/23 05:31:08 PM   rep_loss = 0.7002002394380092
04/23 05:31:08 PM ***** Save model *****
04/23 05:31:16 PM ***** Running evaluation *****
04/23 05:31:16 PM   Epoch = 2 iter 18649 step
04/23 05:31:16 PM   Num examples = 1043
04/23 05:31:16 PM   Batch size = 32
04/23 05:31:16 PM ***** Eval results *****
04/23 05:31:16 PM   att_loss = 0.4232726471114198
04/23 05:31:16 PM   cls_loss = 0.0
04/23 05:31:16 PM   global_step = 18649
04/23 05:31:16 PM   loss = 1.1234225785822898
04/23 05:31:16 PM   rep_loss = 0.7001499312719299
04/23 05:31:16 PM ***** Save model *****
04/23 05:31:24 PM ***** Running evaluation *****
04/23 05:31:24 PM   Epoch = 2 iter 18699 step
04/23 05:31:24 PM   Num examples = 1043
04/23 05:31:24 PM   Batch size = 32
04/23 05:31:24 PM ***** Eval results *****
04/23 05:31:24 PM   att_loss = 0.42326617027914704
04/23 05:31:24 PM   cls_loss = 0.0
04/23 05:31:24 PM   global_step = 18699
04/23 05:31:24 PM   loss = 1.1233568998485195
04/23 05:31:24 PM   rep_loss = 0.7000907293886861
04/23 05:31:24 PM ***** Save model *****
04/23 05:31:33 PM ***** Running evaluation *****
04/23 05:31:33 PM   Epoch = 2 iter 18749 step
04/23 05:31:33 PM   Num examples = 1043
04/23 05:31:33 PM   Batch size = 32
04/23 05:31:33 PM ***** Eval results *****
04/23 05:31:33 PM   att_loss = 0.4232856086883392
04/23 05:31:33 PM   cls_loss = 0.0
04/23 05:31:33 PM   global_step = 18749
04/23 05:31:33 PM   loss = 1.1233612260661359
04/23 05:31:33 PM   rep_loss = 0.7000756172367334
04/23 05:31:33 PM ***** Save model *****
04/23 05:31:41 PM ***** Running evaluation *****
04/23 05:31:41 PM   Epoch = 2 iter 18799 step
04/23 05:31:41 PM   Num examples = 1043
04/23 05:31:41 PM   Batch size = 32
04/23 05:31:41 PM ***** Eval results *****
04/23 05:31:41 PM   att_loss = 0.42332806439148524
04/23 05:31:41 PM   cls_loss = 0.0
04/23 05:31:41 PM   global_step = 18799
04/23 05:31:41 PM   loss = 1.123357476072795
04/23 05:31:41 PM   rep_loss = 0.700029411589908
04/23 05:31:41 PM ***** Save model *****
04/23 05:31:49 PM ***** Running evaluation *****
04/23 05:31:49 PM   Epoch = 2 iter 18849 step
04/23 05:31:49 PM   Num examples = 1043
04/23 05:31:49 PM   Batch size = 32
04/23 05:31:49 PM ***** Eval results *****
04/23 05:31:49 PM   att_loss = 0.4232966777742517
04/23 05:31:49 PM   cls_loss = 0.0
04/23 05:31:49 PM   global_step = 18849
04/23 05:31:49 PM   loss = 1.123305131268804
04/23 05:31:49 PM   rep_loss = 0.7000084533666682
04/23 05:31:49 PM ***** Save model *****
04/23 05:31:57 PM ***** Running evaluation *****
04/23 05:31:57 PM   Epoch = 2 iter 18899 step
04/23 05:31:57 PM   Num examples = 1043
04/23 05:31:57 PM   Batch size = 32
04/23 05:31:57 PM ***** Eval results *****
04/23 05:31:57 PM   att_loss = 0.4232500936309856
04/23 05:31:57 PM   cls_loss = 0.0
04/23 05:31:57 PM   global_step = 18899
04/23 05:31:57 PM   loss = 1.1231904686733105
04/23 05:31:57 PM   rep_loss = 0.6999403748891676
04/23 05:31:57 PM ***** Save model *****
04/23 05:32:05 PM ***** Running evaluation *****
04/23 05:32:05 PM   Epoch = 2 iter 18949 step
04/23 05:32:05 PM   Num examples = 1043
04/23 05:32:05 PM   Batch size = 32
04/23 05:32:05 PM ***** Eval results *****
04/23 05:32:05 PM   att_loss = 0.42320986770272734
04/23 05:32:05 PM   cls_loss = 0.0
04/23 05:32:05 PM   global_step = 18949
04/23 05:32:05 PM   loss = 1.1230874069855625
04/23 05:32:05 PM   rep_loss = 0.6998775390943784
04/23 05:32:05 PM ***** Save model *****
04/23 05:32:13 PM ***** Running evaluation *****
04/23 05:32:13 PM   Epoch = 2 iter 18999 step
04/23 05:32:13 PM   Num examples = 1043
04/23 05:32:13 PM   Batch size = 32
04/23 05:32:13 PM ***** Eval results *****
04/23 05:32:13 PM   att_loss = 0.42317802714965247
04/23 05:32:13 PM   cls_loss = 0.0
04/23 05:32:13 PM   global_step = 18999
04/23 05:32:13 PM   loss = 1.1229912775662558
04/23 05:32:13 PM   rep_loss = 0.6998132502038409
04/23 05:32:13 PM ***** Save model *****
04/23 05:32:21 PM ***** Running evaluation *****
04/23 05:32:21 PM   Epoch = 2 iter 19049 step
04/23 05:32:21 PM   Num examples = 1043
04/23 05:32:21 PM   Batch size = 32
04/23 05:32:21 PM ***** Eval results *****
04/23 05:32:21 PM   att_loss = 0.4231550270476408
04/23 05:32:21 PM   cls_loss = 0.0
04/23 05:32:21 PM   global_step = 19049
04/23 05:32:21 PM   loss = 1.1229042408792709
04/23 05:32:21 PM   rep_loss = 0.6997492136824384
04/23 05:32:21 PM ***** Save model *****
04/23 05:32:29 PM ***** Running evaluation *****
04/23 05:32:29 PM   Epoch = 2 iter 19099 step
04/23 05:32:29 PM   Num examples = 1043
04/23 05:32:29 PM   Batch size = 32
04/23 05:32:29 PM ***** Eval results *****
04/23 05:32:29 PM   att_loss = 0.42319089279851335
04/23 05:32:29 PM   cls_loss = 0.0
04/23 05:32:29 PM   global_step = 19099
04/23 05:32:29 PM   loss = 1.1228938475774002
04/23 05:32:29 PM   rep_loss = 0.6997029546717759
04/23 05:32:29 PM ***** Save model *****
04/23 05:32:38 PM ***** Running evaluation *****
04/23 05:32:38 PM   Epoch = 2 iter 19149 step
04/23 05:32:38 PM   Num examples = 1043
04/23 05:32:38 PM   Batch size = 32
04/23 05:32:38 PM ***** Eval results *****
04/23 05:32:38 PM   att_loss = 0.4231617307796475
04/23 05:32:38 PM   cls_loss = 0.0
04/23 05:32:38 PM   global_step = 19149
04/23 05:32:38 PM   loss = 1.122841256524152
04/23 05:32:38 PM   rep_loss = 0.6996795256635885
04/23 05:32:38 PM ***** Save model *****
04/23 05:32:46 PM ***** Running evaluation *****
04/23 05:32:46 PM   Epoch = 2 iter 19199 step
04/23 05:32:46 PM   Num examples = 1043
04/23 05:32:46 PM   Batch size = 32
04/23 05:32:46 PM ***** Eval results *****
04/23 05:32:46 PM   att_loss = 0.4231324585553634
04/23 05:32:46 PM   cls_loss = 0.0
04/23 05:32:46 PM   global_step = 19199
04/23 05:32:46 PM   loss = 1.122793374780892
04/23 05:32:46 PM   rep_loss = 0.6996609161302495
04/23 05:32:46 PM ***** Save model *****
04/23 05:32:54 PM ***** Running evaluation *****
04/23 05:32:54 PM   Epoch = 2 iter 19249 step
04/23 05:32:54 PM   Num examples = 1043
04/23 05:32:54 PM   Batch size = 32
04/23 05:32:54 PM ***** Eval results *****
04/23 05:32:54 PM   att_loss = 0.4231334149728091
04/23 05:32:54 PM   cls_loss = 0.0
04/23 05:32:54 PM   global_step = 19249
04/23 05:32:54 PM   loss = 1.1227423781825887
04/23 05:32:54 PM   rep_loss = 0.6996089631302138
04/23 05:32:54 PM ***** Save model *****
04/23 05:33:02 PM ***** Running evaluation *****
04/23 05:33:02 PM   Epoch = 2 iter 19299 step
04/23 05:33:02 PM   Num examples = 1043
04/23 05:33:02 PM   Batch size = 32
04/23 05:33:02 PM ***** Eval results *****
04/23 05:33:02 PM   att_loss = 0.4230978011729878
04/23 05:33:02 PM   cls_loss = 0.0
04/23 05:33:02 PM   global_step = 19299
04/23 05:33:02 PM   loss = 1.1226545983881384
04/23 05:33:02 PM   rep_loss = 0.6995567971658336
04/23 05:33:02 PM ***** Save model *****
04/23 05:33:10 PM ***** Running evaluation *****
04/23 05:33:10 PM   Epoch = 2 iter 19349 step
04/23 05:33:10 PM   Num examples = 1043
04/23 05:33:10 PM   Batch size = 32
04/23 05:33:10 PM ***** Eval results *****
04/23 05:33:10 PM   att_loss = 0.42307075799421273
04/23 05:33:10 PM   cls_loss = 0.0
04/23 05:33:10 PM   global_step = 19349
04/23 05:33:10 PM   loss = 1.1225738664008353
04/23 05:33:10 PM   rep_loss = 0.699503108313689
04/23 05:33:10 PM ***** Save model *****
04/23 05:33:18 PM ***** Running evaluation *****
04/23 05:33:18 PM   Epoch = 2 iter 19399 step
04/23 05:33:18 PM   Num examples = 1043
04/23 05:33:18 PM   Batch size = 32
04/23 05:33:18 PM ***** Eval results *****
04/23 05:33:18 PM   att_loss = 0.4230444395549907
04/23 05:33:18 PM   cls_loss = 0.0
04/23 05:33:18 PM   global_step = 19399
04/23 05:33:18 PM   loss = 1.122504024586731
04/23 05:33:18 PM   rep_loss = 0.6994595850074833
04/23 05:33:18 PM ***** Save model *****
04/23 05:33:26 PM ***** Running evaluation *****
04/23 05:33:26 PM   Epoch = 2 iter 19449 step
04/23 05:33:26 PM   Num examples = 1043
04/23 05:33:26 PM   Batch size = 32
04/23 05:33:26 PM ***** Eval results *****
04/23 05:33:26 PM   att_loss = 0.42300371946723364
04/23 05:33:26 PM   cls_loss = 0.0
04/23 05:33:26 PM   global_step = 19449
04/23 05:33:26 PM   loss = 1.1224299107482587
04/23 05:33:26 PM   rep_loss = 0.6994261912665882
04/23 05:33:26 PM ***** Save model *****
04/23 05:33:34 PM ***** Running evaluation *****
04/23 05:33:34 PM   Epoch = 2 iter 19499 step
04/23 05:33:34 PM   Num examples = 1043
04/23 05:33:34 PM   Batch size = 32
04/23 05:33:34 PM ***** Eval results *****
04/23 05:33:34 PM   att_loss = 0.42296784158110445
04/23 05:33:34 PM   cls_loss = 0.0
04/23 05:33:34 PM   global_step = 19499
04/23 05:33:34 PM   loss = 1.122345723528024
04/23 05:33:34 PM   rep_loss = 0.6993778819516934
04/23 05:33:34 PM ***** Save model *****
04/23 05:33:42 PM ***** Running evaluation *****
04/23 05:33:42 PM   Epoch = 2 iter 19549 step
04/23 05:33:42 PM   Num examples = 1043
04/23 05:33:42 PM   Batch size = 32
04/23 05:33:42 PM ***** Eval results *****
04/23 05:33:42 PM   att_loss = 0.422937989556958
04/23 05:33:42 PM   cls_loss = 0.0
04/23 05:33:42 PM   global_step = 19549
04/23 05:33:42 PM   loss = 1.1222871672400567
04/23 05:33:42 PM   rep_loss = 0.6993491776925703
04/23 05:33:42 PM ***** Save model *****
04/23 05:33:51 PM ***** Running evaluation *****
04/23 05:33:51 PM   Epoch = 2 iter 19599 step
04/23 05:33:51 PM   Num examples = 1043
04/23 05:33:51 PM   Batch size = 32
04/23 05:33:51 PM ***** Eval results *****
04/23 05:33:51 PM   att_loss = 0.422934557184819
04/23 05:33:51 PM   cls_loss = 0.0
04/23 05:33:51 PM   global_step = 19599
04/23 05:33:51 PM   loss = 1.122253052456868
04/23 05:33:51 PM   rep_loss = 0.6993184952579536
04/23 05:33:51 PM ***** Save model *****
04/23 05:33:59 PM ***** Running evaluation *****
04/23 05:33:59 PM   Epoch = 2 iter 19649 step
04/23 05:33:59 PM   Num examples = 1043
04/23 05:33:59 PM   Batch size = 32
04/23 05:33:59 PM ***** Eval results *****
04/23 05:33:59 PM   att_loss = 0.42295617117822853
04/23 05:33:59 PM   cls_loss = 0.0
04/23 05:33:59 PM   global_step = 19649
04/23 05:33:59 PM   loss = 1.1222343987167749
04/23 05:33:59 PM   rep_loss = 0.6992782275571932
04/23 05:33:59 PM ***** Save model *****
04/23 05:34:07 PM ***** Running evaluation *****
04/23 05:34:07 PM   Epoch = 2 iter 19699 step
04/23 05:34:07 PM   Num examples = 1043
04/23 05:34:07 PM   Batch size = 32
04/23 05:34:07 PM ***** Eval results *****
04/23 05:34:07 PM   att_loss = 0.42298147374662615
04/23 05:34:07 PM   cls_loss = 0.0
04/23 05:34:07 PM   global_step = 19699
04/23 05:34:07 PM   loss = 1.122224353779996
04/23 05:34:07 PM   rep_loss = 0.6992428800564976
04/23 05:34:07 PM ***** Save model *****
04/23 05:34:15 PM ***** Running evaluation *****
04/23 05:34:15 PM   Epoch = 2 iter 19749 step
04/23 05:34:15 PM   Num examples = 1043
04/23 05:34:15 PM   Batch size = 32
04/23 05:34:15 PM ***** Eval results *****
04/23 05:34:15 PM   att_loss = 0.4229819453563085
04/23 05:34:15 PM   cls_loss = 0.0
04/23 05:34:15 PM   global_step = 19749
04/23 05:34:15 PM   loss = 1.1222084485179156
04/23 05:34:15 PM   rep_loss = 0.6992265032120961
04/23 05:34:15 PM ***** Save model *****
04/23 05:34:23 PM ***** Running evaluation *****
04/23 05:34:23 PM   Epoch = 2 iter 19799 step
04/23 05:34:23 PM   Num examples = 1043
04/23 05:34:23 PM   Batch size = 32
04/23 05:34:23 PM ***** Eval results *****
04/23 05:34:23 PM   att_loss = 0.4229868700175261
04/23 05:34:23 PM   cls_loss = 0.0
04/23 05:34:23 PM   global_step = 19799
04/23 05:34:23 PM   loss = 1.122204379324481
04/23 05:34:23 PM   rep_loss = 0.6992175093616129
04/23 05:34:23 PM ***** Save model *****
04/23 05:34:31 PM ***** Running evaluation *****
04/23 05:34:31 PM   Epoch = 2 iter 19849 step
04/23 05:34:31 PM   Num examples = 1043
04/23 05:34:31 PM   Batch size = 32
04/23 05:34:31 PM ***** Eval results *****
04/23 05:34:31 PM   att_loss = 0.422981977620979
04/23 05:34:31 PM   cls_loss = 0.0
04/23 05:34:31 PM   global_step = 19849
04/23 05:34:31 PM   loss = 1.1221831266442108
04/23 05:34:31 PM   rep_loss = 0.699201149054874
04/23 05:34:31 PM ***** Save model *****
